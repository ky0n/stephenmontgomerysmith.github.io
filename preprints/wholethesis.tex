%\magnification=\magstep1
%\hoffset =0.5 true in
%\hsize =5.75 true in
%\vsize =9.65 true in
%\baselineskip =5.5mm
%\lineskiplimit =1.0mm
%\lineskip =1.0mm
%\input mssymb
 
\font\title=cmr10 at 16pt
\font\titleit=cmti10 at 16pt
\font\name=cmr10 at 12pt
\def \dt {\it}
\def \Bbb{\bf}
 
\def \sqr {\vcenter {\hrule height.3mm
           \hbox {\vrule width.3mm height 2mm \kern2mm
           \vrule width.3mm } \hrule height.3mm }}
 
\def \medskipunlikelybreak {
     \ifdim\lastskip<\medskipamount \removelastskip\penalty55\medskip\fi}
\def \smallskipunlikelybreak {
     \ifdim\lastskip<\smallskipamount \removelastskip\penalty55\smallskip\fi}
\def \nl {\par\noindent}
\def \moreproclaim {\par}
\def \endit {\par}
\def \Proof {\medskipunlikelybreak\noindent{\bf Proof:}\ }
\def \proof #1: {\medskipunlikelybreak\noindent{\bf Proof\ #1:}\
}
\def \endproof {\nobreak\hfill\hfill$\sqr$\medskip\goodbreak}
\def \Step#1{\smallskipunlikelybreak\noindent{\bf Step\ #1:}\ }
\def \tstep #1: #2\par{\goodbreak\medskipunlikelybreak\noindent
      {\bf Step #1: #2}\par\medskipunlikelybreak\nobreak\noindent}
\def \tpreludetostep #1: #2\par{\goodbreak\medskipunlikelybreak\noindent
      {\bf Prelude to Step #1: #2}\par\medskipunlikelybreak\nobreak\noindent}
\def \ditem#1$#2${\item{#1} $\displaystyle{#2}$}
\def \cditem#1 $$#2$${%
     \vskip 0cm
     \item{#1} \hfil{$\displaystyle{#2}$}\hfil
     \vskip 0cm}
\def \labelledapprox#1{\buildrel{#1}\over\approx}
\def \pmod#1{\,({\rm mod}\,#1)}
\def \ds#1{{\displaystyle{#1}}}
\def \ts#1{{\textstyle{#1}}}
\def \contents#1{\medskip\halign{##\hfil\ &##\hfil&\hbox to 4in{\
\ ##}\cr
                 #1}\vfill\eject}
\def \nm{\vbox{\kern 6.5mm}}
\def \ns{}
 
\def \R {{\Bbb R}}
\def \C {{\Bbb C}}
\def \Z {{\Bbb Z}}
\def \N {{\Bbb N}}
\def \E {{\Bbb E}}
\def \A {{\cal A}}
\def \F {{\cal F}}
\def \cS {{\cal S}}
\def \cN {{\cal N}}
 
\def \w {\wedge}
\def \v {\vee}
 
\def \half {{1\over2}}
\def \smallhalf{{\textstyle {1\over2}}}
\def \quarter {{1\over4}}
\def \smallquarter {{\textstyle {1\over4}}}
 
\def \invc {c^{-1}}
\def \invexpexplp {{1\over \exp(e^{l'}-1)}}
\def \invp {{1\over p}}
\def \pp {{p'}}
\def \invpp {{1\over p'}}
\def \invsqrtp {{1\over\sqrt{p}}}
\def \potwo {{p\over 2}}
\def \ppotwo {{p'\over 2}}
\def \qop {{q\over p}}
\def \poq {{p\over q}}
\def \qops#1{{q_{#1}\over p}}
\def \poqs#1{{p\over q_{#1}}}
\def \qotwo {{q\over2}}
\def \twooq {{2\over q}}
\def \qk {{q_k}}
\def \invqk {{1\over\qk}}
\def \qkotwo {{\qk\over 2}}
\def \invq {{1\over q}}
\def \invqs#1{{1\over q_{#1}}}
\def \invsqrtq {{1\over\sqrt q}}
\def \ominvqk {\left(1-\invqk\right)}
\def \omqkotwo {\left(1-\qkotwo\right)}
\def \invqkmhalf {\left(\invqk-\half\right)}
\def \invr {{1\over r}}
\def \invk {{1\over k}}
\def \invsqrtk {{1\over\sqrt{k}}}
\def \logk {\lm k}
\def \sqrtlogk {\sqrt{\logk}}
\def \invsqrtlogk {{1\over\sqrtlogk}}
\def \klogk {k\logk}
\def \invklogk {{1\over \klogk}}
\def \kosqrtlogk {{k\over\sqrtlogk}}
\def \kotwo {{k\over2}}
\def \invkinvp {{1\over k^\invp}}
\def \invsqrtK {{1\over\sqrt{K}}}
\def \logK {\lm K}
\def \invsqrtn {{1\over\sqrt{n}}}
\def \invn {{1\over n}}
\def \invnqkotwo {{1\over n^\qkotwo}}
\def \invsqrtnlogNon {{1\over\sqrt n(\lm(N/n))}}
\def \invN {{1\over N}}
\def \sqrtloglogN {\sqrt{\lm\lm N}}
\def \invloglogN {{1\over \lm\lm N}}
\def \invsqrtloglogN {{1\over \sqrt{\lm\lm N}}}
\def \invsqrtN {{1\over\sqrt{N}}}
\def \invsqrtlogN {{1\over\sqrt{\lm N}}}
\def \intNok {\lfloor N/k\rfloor}
\def \koN {{k\over N}}
\def \koNmNk {\koN \mNk}
\def \invkoNmNk {{1\over \koNmNk}}
\def \logNon {\lm(N/n)}
\def \logNonwK {\lm\left({N\over n}\wedge K\right)}
\def \sqrtpi {\sqrt{\pi_s(n)}}
\def \invsqrtpi {{1\over\sqrtpi}}
\def \invpi {{1\over \pi_s(n)}}
\def \invsqrtpin {{1\over\sqrt{\pi(n)}}}
\def \logNopi {\lm(N/\pi_s(n))}
\def \tbmo {2\beta-1}
\def \invtbmo {{1\over\tbmo}}
\def \sqrttbmo {\sqrt{2\beta-1}}
\def \invsqrttbmo {{1\over\sqrttbmo}}
\def \ovstbmo {1\vee(\sqrttbmo)}
\def \invovstbmo {{1\over\ovstbmo}}
\def \invbeta {{1\over\beta}}
\def \invsqrtS {{1\over\sqrt S}}
\def \invustwo {{1\over u_s^2}}
\def \invt {{1\over t}}
\def \invust {1/u_s^2}
\def \invepsilon {{1\over\epsilon}}
\def \logNonwinvust {\lm((N/n)\w(\invust))}
\def \logNopiwinvust {\lm((N/\pi_s(n))\w(\invust))}
\def \logkologNon {\left({\logk \over \logNon}\right)}
\def \logkologNopi {\left({\logk \over \logNopi}\right)}
\def \logkologNonwinvust {\left({\logk \over \logNonwinvust}\right)}
\def \logkologNopiwinvust {\left({\logk \over \logNopiwinvust}\right)}
\def \sqrtlogNe {\sqrt{\log \cN(\epsilon)}}
\def \alphatn {\alpha_t(n)}
\def \modalphatn {\modo{\alphatn}}
\def \mItoN {{\modo{I_t}\over N}}
\def \logt {\lm t}
\def \sqrtlogt {\sqrt{\logt}}
\def \invsqrtlogt {{1\over\sqrtlogt}}
\def \invlogt {{1\over\logt}}
\def \nutologt {{\nu_t \over \logt}}
\def \invnut {{1\over\nu_t}}
\def \tY {\tilde Y}
\def \ty {\tilde y}
\def \tx {\tilde x}
 
\def \em {\mathop{\rm em}\nolimits}
\def \lm {\mathop{\rm lm}\nolimits}
\def \sign {\mathop{\rm sign}}
\def \supp {\mathop{\rm supp}}
\def \esssup {\mathop{\rm ess\,sup}}
\def \Id {\mathord{\rm Id}}
\def \Pr {\mathop{\rm Pr}\nolimits}
\def \widecdot {\kern0.8pt\cdot\kern0.8pt}
 
\def \sumuptosigmat {\sum_{u=1}^{\sigma(t)} i_{\sigma^{-1}(u)}}
\def \itoversumuptosigmat {{i_t^2 \over \sumuptosigmat}}
\def \tonamed#1{\mathrel{\mathop\to^#1}}
\def \xsigmann {x_{\sigma_n}(n)}
\def \xsigmanunn {x_{\sigma_n(\nu)}(n)}
\def \wnusigmanunn {w^\nu_{\sigma_n(\nu)}(n)}
\def \normwnusigmanunn {\lnorm \wnusigmanunn \rnorm}
\def \mxsn {\lmod x_s(n) \rmod}
\def \asubNok {a\big|_{[N/k]}}
\def \asubNotwo {a\big|_{[N/2]}}
\def \asubNoktwo {\lnorm \asubNok \rnorm_2}
\def \asubbetam {a\big|_{\beta_m}}
\def \emhtt {e^{-\half t^2}}
\def \emctt {e^{-c t^2}}
\def \normxs {\lnorm x_s \rnorm}
\def \norma {\lnorm a \rnorm}
\def \normdot {\lnorm \widecdot \rnorm}
\def \moddot {\lmod \widecdot \rmod}
\def \normf {\lnorm f \rnorm}
\def \modf {\lmod f \rmod}
\def \normo#1{\lnorm #1 \rnorm}
\def \modo#1{\lmod#1\rmod}
\def \modfo#1{\lmod f(#1) \rmod}
\def \bigangleo#1{\left\langle#1\right\rangle}
\def \noneatwo {,\normdot_1,\normdot_2}
\def \ninfatwo {,\normdot_\infty,\normdot_2}
\def \normKnLpk {\lnorm (K_n)_{n=1}^k \rnorm_{L_p^k}}
\def \Kkmsqrtk {K_{k-\sqrt k}}
 
\def \TtlmTt {{T^2\lm T,2}}
\def \LTtlmTt {{L_\TtlmTt^N}}
\def \Lto {{L_{2,1}^N}}
\def \TlmTo {{T\lm T,1}}
\def \LTlmTo {{L_\TlmTo^N}}
 
\def \xS {x_1$, $x_2,\ldots,$\ $x_S}
\def \uS {u_1$, $u_2,\ldots,$\ $u_S}
\def \piS {\pi_1$, $\pi_2,\ldots,$\ $\pi_S}
\def \sigmaS {\sigma_1$, $\sigma_2,\ldots,$\ $\sigma_S}
\def \gammalist {\gamma_1$, $\gamma_2,\ldots}
\def \epsilonlist {\varepsilon_1$, $\varepsilon_2,\ldots}
\def \thetalist {\theta_1$, $\theta_2,\ldots}
\def \GammaN {\Gamma_1$, $\Gamma_2,\ldots,$\ $\Gamma_N}
\def \Gammaproc {(\,\Gamma_n:n\in[N])}
\def \EN {E_1$, $E_2,\ldots,$\ $E_N}
\def \Eproc {(\,E_n:n\in[N])}
\def \ThetaN {\Theta_1$, $\Theta_2,\ldots,$\ $\Theta_N}
\def \Thetaproc {(\,\Theta_n:n\in[N])}
\def \ThetasigmaN {\Theta^\sigma_1$, $\Theta^\sigma_2,\ldots,$\
                   $\Theta^\sigma_N}
\def \Thetasigmaproc {(\,\Theta^\sigma_n:n\in[N])}
\def \sigmaN {\sigma_1$, $\sigma_2,\ldots,$\ $\sigma_N}
\def \sigmatuple {(\,\sigma_n:n\in[N])}
\def \nk {n_1$, $n_2,\ldots,$\ $n_k}
\def \betaM {\beta_1$, $\beta_2,\ldots,$\ $\beta_M}
\def \AS {A_1$, $A_2,\ldots,$\ $A_S}
\def \BS {B_1$, $B_2,\ldots,$\ $B_S}
\def \IT {I_1$, $I_2,\ldots,$\ $I_T}
\def \iT {i_1$, $i_2,\ldots,$\ $i_T}
\def \nuT {\nu_1$, $\nu_2,\ldots,$\ $\nu_T}
\def \JS {J_1$, $J_2,\ldots,$\ $J_S}
\def \alphaT {\alpha_1$, $\alpha_2,\ldots,$\ $\alpha_T}
 
\def \sumss#1#2{\sum_{\scriptstyle{#1}\atop\scriptstyle{#2}}}
\def \sumsslimits#1#2{\sum\limits_{\scriptstyle{#1}\atop\scriptstyle{#2}}}
\def \sumS {\sum_{s=1}^S}
\def \sumN {\sum_{n=1}^N}
\def \sumM {\sum_{m=1}^M}
\def \sumninfty {\sum_{n=1}^\infty}
\def \sumkN {\sum_{k=1}^{N/3}}
\def \sumkNwS {\sum_{k=1}^{N\w S}}
\def \sumNok {\sum_{n=1}^{N/k}}
\def \sumkNon {\sum_{k=1}^{N/n}}
\def \sumkNopi {\sum_{k=1}^{N/\pi_s(n)}}
\def \sumpis {\sum_{\{s\colon\pi_s(n)\le N/k\}}}
\def \sumNk {\sum_{\nu\in\Nk}}
\def \sumM {\sum_{m=1}^M}
\def \sumnk {\sum_{n=1}^k}
\def \sumlloglogN {\sum_{l=1}^{\log(1+\log(1+{N\over3}))}}
\def \sumT {\sum_{t=1}^T}
\def \sumnii {\sum_{n=-\infty}^\infty}
 
\def \AvN {\invN \sumN}
\def \AvNk {{1\over \mNk} \sumNk}
\def \AvokN {\invk \sumN}
 
\def \supS {\sup_{s\in[S]}}
\def \supN {\sup_{n\in[N]}}
\def \supkN {\sup_{k\in[N/3]}}
\def \supNk {\sup_{\nu\in\Nk}}
 
\def \prodN {\prod_{n=1}^N}
\def \prodM {\prod_{m=1}^M}
 
\def \cupS {\bigcup_{s=1}^S}
\def \cupNk {\bigcup_{\nu\in\Nk}}
 
\def \Nk {[N]^{(k)}}
\def \mNk {\ts{\lmod\Nk\rmod}}
\def \CNS {(\C^N)^S}
\def \PonetwoM {P_{1,2}(M)}
\def \PpqM {{P_{p,q}(M)}}
\def \measspace {(\Omega,\F,\mu)}
\def \TXY {T\colon X\to Y}
\def \TCKY {T\colon C(K)\to Y}
\def \TliNY {T\colon l_\infty^N\to Y}
\def \CKtLtoKm {C(K)\hookrightarrow L_{2,1}(K,\mu)}
 
\def \linftyN {l_\infty^N}
\def \LtwooneN {L_{2,1}^N}
\def \Phiq {{\Phi,q}}
\def \emTtwo {{\em(T^2)}}
 
\def \lbrack {\left(}
\def \rbrack {\right)}
\def \lbrace {\left\{}
\def \rbrace {\right\}}
\def \lmod {\left|}
\def \rmod {\right|}
\def \lnorm {\left\|}
\def \rnorm {\right\|}
\def \rnorminfty {\rnorm_\infty}
\def \rnormtwoone {\rnorm_{2,1}}
\def \rnormLtwooneN {\rnorm_{\LtwooneN}}
\def \rnormLtwoltwoN {\rnorm_{L_{T^2\lm T,2}^N}}
\def \rnormGamma {\rnorm_\Gamma}
\def \rnormGammadual {\rnorm_\Gamma^*}
\def \rnormE {\rnorm_E}
\def \rnormEdual {\rnorm_E^*}
 
\def \mnuinsigma {\lmod\{\,\nu\in\Nk:s\in\sigma_n(\nu)\}\rmod}
 
\def \rmsxs {\left(\sumS \modo{x_s}^2\right)^\half}
\def \normxS {\lnorm (x_s) \rnorm}
\def \rmsxsLtwoone {\lbrack \sumS \lnorm x_s \rnormLtwooneN^2
                    \rbrack^\half}
\def \rmsxstwoone {\left( \sumS \lnorm x_s \rnormtwoone^2 \right)^\half}
\def \pthmpnormTxs {\left( \sumS \normo{T(x_s)}^p \right)^\invp}
\def \qthmqnormxs {\left( \sumS \normo{x_s}^q \right)^\invq}
 
\def \Gausswalkx {\lnorm \sumS \gamma_s x_s \rnorm}
\def \GausswalkTx {\lnorm \sumS \gamma_s T(x_s) \rnorm}
\def \Bernwalkx {\lnorm \sumS \varepsilon_s x_s \rnorm}
\def \BernwalkTx {\lnorm \sumS \varepsilon_s T(x_s) \rnorm}
\def \Gausswalk {\lnorm \sumS \gamma_s x_s \rnorminfty}
\def \Bernwalk  {\lnorm \sumS \varepsilon_s x_s \rnorminfty}
\def \supGauss {\supN | \Gamma_n |}
\def \supGaussx {\supN | \Gamma_n(x) |}
\def \supGausssigma {\supN | \Gamma^\sigma_n |}
\def \supGausssigmax {\supN | \Gamma^\sigma_n(x) |}
\def \supGausssigmakx {\supN | \Gamma^{\sigma(k)}_n(x) |}
\def \supGausssigmanu {\supN | \Gamma^{\sigma(\nu)}_n |}
\def \supGausssigmanux {\supN | \Gamma^{\sigma(\nu)}_n(x) |}
\def \supBern {\supN \lmod E_n \rmod}
\def \supBernsigmakx {\supN | E_n^{\sigma(k)}(x) |}
\def \supTheta {\supN \lmod \Theta_n \rmod}
\def \supThetasigma {\supN | \Theta^\sigma_n |}
\def \supThetasigmak {\supN | \Theta^{\sigma(k)}_n |}
 
\def \sumtheta {\sumS \theta_s x_s}
\def \modsumtheta {\modo{\sumtheta}}
\def \normsumtheta {\normo{\sumtheta}}
\def \sumgamma {\sumS \gamma_s x_s}
\def \modsumgamma {\modo{\sumgamma}}
\def \normsumgamma {\normo{\sumgamma}}
\def \sumepsilon {\sumS \varepsilon_s x_s}
\def \modsumepsilon {\modo{\sumepsilon}}
\def \normsumepsilon {\normo{\sumepsilon}}
 
\def \nqOf {normal quasi-Orlicz function}
\def \blobBs {bounded linear operator between Banach spaces}
\def \blo {bounded linear operator}
\def \blotaBs {bounded linear operator to a Banach space}
\def \blofCK {bounded linear operator from $C(K)$}
\def \blofCKtaBs {bounded linear operator from $C(K)$\ to a Banach
space}
 
\def \newline {\par\noindent}
 
\def \Lhalign #1
{\tolerance=10000\medskip\par
\halign{\nobreak
\vtop{\hsize=1.3 true in\parindent=0pt\hangindent=0pt
\strut##\strut\medskip}
&\vtop{\hsize=3 true in\parindent=0pt\hangindent=0pt
\strut##\strut\medskip}
&\quad\vtop{\hsize=1.5 true in\parindent=0pt\hangindent=0pt
\strut##\strut\medskip}
\cr
#1}
\tolerance=200\medskip\goodbreak}
 
\def \fiverbrace{
\vtop{\hsize=0.2 true in\parindent=0pt\hangindent=0pt
\strut
\newline\newline$\left.\matrix{\cr\cr\cr\cr\cr}\right\}$\newline
\strut}}
 
\def \fiveL#1{\vtop{\hsize=1.2 true in\parindent=0pt\hangindent=0pt
\strut
\nulldelimiterspace=0pt
$\left.\matrix{
L_{#1}\measspace \hfill\cr
L_{#1}(\Omega,\mu) \hfill\cr
L_{#1}(\Omega) \hfill\cr
L_{#1}(\mu) \hfill\cr
L_{#1} \hfill\cr
}\right\}$
\nulldelimiterspace=1.2pt
\strut}}
 
\nopagenumbers
 
\phantom{----------------------------------------------------------}
\vskip 1.2 true in
 
\centerline{\title
The Cotype of Operators from {\titleit C\/}({\titleit K\/})}
 
\vskip 1.7 true in
 
\centerline{\name Stephen John Montgomery-Smith}
\centerline{\name St.~John's College, Cambridge}
 
\vskip 1.5 true in
\vfill
 
\centerline{\sevenrm
{\rm D}ISSERTATION{\rm\ S}UBMITTED{\rm\ T}OWARDS{\rm\ P}H{\rm.D.}{\rm\
D}EGREE}
\centerline{\sevenrm
AT{\rm\ C}AMBRIDGE{\rm\ U}NIVERSITY}
 
\vskip 0.6 true in
 
\centerline{August 1988}
 
\vskip 1.2 true in
 
\eject
 
\phantom{----------------------------------------------------}
\vskip 1.6 true in
 
\centerline{\sl
Dedicated to the Glory of God, by whom this was inspired.}
 
\vfill
\eject
 
\beginsection Acknowledgements
 
I would like to thank Dr.~D.J.H.~Garling, my research supervisor,
for all the
help he has given me. I would also like to thank Dr.~G.J.O.~Jameson.
It was at
a seminar he gave that I was introduced to the problem tackled in
this thesis.
He also showed a great interest in my work, giving me much encouragement,
and
some helpful suggestions.
 
I would also like to mention my friends in the Pure Mathematics Department
in
Cambridge, particularly Graham Brightwell, Fr\'ed\'eric Gourdeau
and Julie
Haviland, who all gave me advice on style, and who proofread this
thesis. Of
course, they bear no responsibility for the final product.
 
Finally, I would like to thank the Science and Engineering Research
Council for
financing my studies.
 
\beginsection Statement of Originality
 
All work contained in this thesis is the result of my own work carried
out
between October 1985 and August 1988. No part of this thesis contains
work done
in collaboration with any other person. No part of this thesis has
been
submitted for a degree or diploma at any other University.
 
\bigskip
\bigskip
\hfill\vbox{\halign{\hfill#\cr
S.~J.~Montgomery-Smith\cr
St.~John's College\cr
}}
 
\vfill
\eject
 
\footline={\hss\tenrm\folio\hss}
\pageno = 1
 
\beginsection The Cotype of Operators from $C(K)$
 
\beginsection Contents
 
\contents{%
&          & Acknowledgements                                 \hfill
     \cr
&          & Statement of Originality                         \hfill
     \cr
&          & Introduction                                     \dotfill
2 \cr
\nm
Part&1     & Introducing the Problems                         \dotfill
3 \cr
\ns
Chapter&1A & Preliminaries                                    \dotfill
5 \cr
Chapter&1B & Properties of $(p,q)$-Summing Operators from $C(K)$
                                                              \dotfill
18 \cr
Chapter&1C & Random Walks and Cotype                          \dotfill
22 \cr
Chapter&1D & Miscellaneous Results                            \dotfill
34 \cr
\nm
Part&2     & Lower Bounds for Random Walks in $l_\infty^N$    \dotfill
43 \cr
\ns
Chapter&2A & The Problem of Cotype $2$                        \dotfill
45 \cr
Chapter&2B & A Discussion of the Methods of Chapter~2A        \dotfill
74 \cr
Chapter&2C & Applications of Talagrand's Theorem              \dotfill
79 \cr
Chapter&2D & Comparison of Gaussian and Rademacher Cotype     \dotfill
88 \cr
\nm
Part&3     & Generalized Lorentz Spaces                       \dotfill
90 \cr
\ns
Chapter&3A & Definitions and Elementary Properties            \dotfill
92 \cr
Chapter&3B & Inequalities                                     \dotfill
106 \cr
Chapter&3C & Boyd Indices of Generalized Lorentz Spaces       \dotfill
113 \cr
\nm
&          & References                                       \dotfill
119 \cr
}
 
\beginsection Introduction
 
In 1987, Jameson [J1] studied the relationship between the $(2,1)$-summing
norm
and the $2$-summing norm for operators from $l_\infty^N$. He showed
that, in
general, these norms are not equivalent. At the end of his paper,
he observed
that the Rademacher cotype $2$\ constant of operators from $l_\infty^N$\
lay
between these two summing norms, and he asked whether it was indeed
equivalent
to one of them.
 
Answering this question proved to be very hard. By delicate averaging
arguments, I managed to prove that the Rademacher cotype $2$\ constant
for an
operator from $l_\infty^N$\ is very close to its $(2,1)$-summing
norm; they
are within about $\log\log N$\ of each other, and hence, in general,
the
cotype $2$\ constant and the $2$-summing norms are inequivalent.
The
techniques used also enabled me to compare the Rademacher and Gaussian
cotype
$p$\
constants for many operators from $l_\infty^N$, deducing that these
are not
the same.
 
Studying this problem also led me to consider quite a different subject.
I
defined new spaces which are a common generalization of the Lorentz
$L_{p,q}$\
and the Orlicz $L_\Phi$\ spaces. As well as rederiving results of
Bennett and
Rudnick, I sought to calculate the Boyd indices of these new spaces.
 
\beginsection The Structure of the Thesis
 
The thesis is split up into three parts, and each part is split up
into three
or four chapters. The first two parts are about the cotype of operators
from
$C(K)$, and the third is on the generalized Lorentz spaces.
 
The purpose of Part~1 is to introduce the problems that are solved
in Part~2.
Part~1 starts in Chapter~1A, which introduces the notation and preliminary
results to be used. Chapter~1B studies $(p,q)$-summing operators
from $C(K)$,
and includes the result that reduces the study of $(p,1)$-summing
operators to
consideration of the formal identity maps $l_\infty^N \to L_{p,1}^N$.
Chapter~1C describes random walks and cotype, and in doing so, motivates
the
main problems of this thesis. It culminates in Section~5, where the
main
results to be proved are stated. Last, and least, Chapter~1D discusses
other
miscellaneous results.
 
Part~2 is devoted to proving the results of Section~1C:5. Chapter~2A
proves the
most difficult result of this thesis, that is, showing that the Rademacher
cotype $2$\ constant of an operator from $l_\infty^N$\ is no more
than $\log\log
N$\ times its $(2,1)$-summing norm. The techniques used are discussed
in
Chapter~2B, and then Chapter~2C proves the second major result, showing
that
the Gaussian cotype $2$\ of an operator from $l_\infty^N$\ is no
more than
$\sqrt{\log\log N}$\ times its $(2,1)$-summing norm. Finally, Chapter~2D
shows
that the Gaussian and Rademacher cotype $p$\ constants of many operators
from
$l_\infty^N$\ differ by $\sqrt{\log N}$.
 
Part~3 is in many ways an appendix, and it proves some of the results
about
Orlicz and Lorentz spaces needed in Parts~1 and~2.  It gives new
proofs and
extensions of known results. It also discusses the problem of calculating
Boyd
indices of the generalized Lorentz spaces.
 
\vfill
\eject
 
\beginsection Part 1 --- Introducing the Problems
 
\beginsection Contents
 
\contents{%
Chapter&1A & Preliminaries                               \dotfill
5 \cr
\ns
Section&1  & Basic Notation                              \dotfill
5 \cr
&1.1       & Constants and the Letter `$c$'              \dotfill
5 \cr
&1.2       & Notation involving Integers                 \dotfill
5 \cr
&1.3       & Notation involving Real and Complex Numbers \dotfill
6 \cr
&1.4       & Notation involving Sets and Functions       \dotfill
8 \cr
&1.5       & Notation involving Probability              \dotfill
8 \cr
Section&2  & Notation involving Quasi-Banach Spaces      \dotfill
9 \cr
&2.1       & The $C(K)$, $L_\infty$\ and $l_\infty$\ Spaces
                                                         \dotfill
9 \cr
&2.2       & The $L_p$\ and $l_p$\ Spaces                \dotfill
10 \cr
&2.3       & Orlicz Spaces                               \dotfill
10 \cr
&2.4       & Lorentz Spaces                              \dotfill
11 \cr
&2.5       & Interpolation Norms                         \dotfill
14 \cr
&2.6       & Spanning Points of $C(K,l_1)$               \dotfill
15 \cr
Section&3  & Notation involving Ideals                   \dotfill
16 \cr
&3.1       & Operators that Factor through Hilbert Space \dotfill
16 \cr
&3.2       & The $(p,q)$-Summing Operators               \dotfill
16 \cr
&3.3       & Type and Cotype of Operators                \dotfill
17 \cr
&3.4       & The $(\Phi,\Psi)$-Summing Operators         \dotfill
17 \cr
\nm
Chapter&1B & Properties of $(p,q)$-Summing Operators from $C(K)$
                                                         \dotfill
18 \cr
\ns
Section&1  & The $p$-Summing Operators                   \dotfill
18 \cr
Section&2  & The $(p,q)$-Summing Operators               \dotfill
19 \cr
Section&3  & A Finite Dimensional Version of Pisier's Result
                                                         \dotfill
21 \cr
\nm
Chapter&1C & Random Walks and Cotype                     \dotfill
22 \cr
\ns
Section&1  & Random Walks in Banach Spaces               \dotfill
22 \cr
&1.1       & Scalar Valued Random Walks                  \dotfill
22 \cr
&1.2       & Banach Space Valued Random Walks            \dotfill
23 \cr
&1.3       & Random Walks in $l_\infty^N$                \dotfill
25 \cr
Section&2  & Type and Cotype of Operators and Banach Spaces
                                                         \dotfill
26 \cr
&2.1       & Kwapien's Result                            \dotfill
26 \cr
&2.2       & Grothendieck's Theorem                      \dotfill
27 \cr
&2.3       & Cotype $p$\ of Operators from $C(K)$\ for $p>2$
                                                         \dotfill
27 \cr
Section&3  & The Problem of Cotype $2$                   \dotfill
28 \cr
Section&4  & Comparison of Gaussian and Rademacher Cotype
                                                         \dotfill
31 \cr
&4.1       & Comparison of Gaussian and Bernoulli Random Walks
                                                         \dotfill
31 \cr
&4.2       & Comparison of Gaussian and Rademacher Cotype
                                                         \dotfill
32 \cr
Section&5  & The Solutions                               \dotfill
33 \cr
&5.1       & The Problem of Cotype $2$                   \dotfill
33 \cr
&5.2       & Comparison of Gaussian and Rademacher Cotype
                                                         \dotfill
33 \cr
\nm
Chapter&1D & Miscellaneous Results                       \dotfill
34 \cr
\ns
Section&1  & The $p^\invp$\ in Pisier's Result           \dotfill
34 \cr
Section&2  & The Space $L_{2,1}$\ is not $(2,1)$-Summing \dotfill
37 \cr
Section&3  & A Proof of Grothendieck's Theorem via Pisier's Result
                                                         \dotfill
38 \cr
Section&4  & The $(\Phi,1)$-Summing Norm                 \dotfill
40 \cr
}
 
\beginsection Introduction to Part 1
 
The first part of my thesis consists of four chapters. The purpose
of this part
is to set the scene for Part~2, where I prove the main results.
 
Chapter~1A contains most of the definitions and many of the preliminary
results
required for Parts~1 and~2.
Some of the material is standard, and is presented only to avoid
any possible
misunderstanding, but I also present some new ideas.
 
Chapter~1B is a discussion about summing operators. It contains results
due to
Pietsch, Maurey and Pisier. It also gives a finite dimensional version
of
Pisier's theorem, which is of importance later on.
 
After this comes Chapter~1C, which gives an introduction to random
walks
and cotype, and culminates in Section~5, where the main results of
the thesis
are stated.
 
Finally, Chapter~1D gives some results which are of some interest,
but of no
great importance to the main arguments in this thesis. First it discusses
the
constants that appear in Pisier's theorem on $(p,1)$-summing operators.
Then it
shows that $L_{2,1}$\ is not a $(2,1)$-summing space. After this,
it presents a
proof of Grothendieck's Theorem. Finally it gives a result like Pisier's
theorem
for $(\Phi,1)$-summing operators.
 
Throughout Part~1, the familiar and the unfamiliar are presented
side by side,
to aid the flow of the arguments.
 
\vfill
\eject
 
\beginsection Chapter 1A --- Preliminaries
 
In this chapter we give definitions and preliminary results.
Section~1 merely gives the most elementary notation. Section~2 gives
the
notation about Banach spaces. It includes an elementary introduction
to Orlicz
functions and spaces, and also gives a definition of Lorentz spaces
that
extends the usual definition (so that, for example, it includes the
Zygmund--Lorentz spaces (see [B--R])). It also contains results about
the so
called $J$\ and $K$\ interpolation functors. Section~3 gives the
notation for
ideals, and is standard with the single exception that we define
the
$(\Phi,\Psi)$-summing norm.
 
\beginsection 1) Basic Notation
 
\beginsection 1.1) Constants and the Letter `$c$'
 
Much of the time, particularly in Part~2, we will be using numerical
constants
in whose precise values we are not interested. For this reason we
will reserve
the lower case letter $c$\ to mean `a numerical constant'. This numerical
constant will not depend on any parameters, that is, it will be a
universal
constant, but different occurrences of the letter $c$\ may represent
different
constants. The constants so represented are to be thought of as large;
a small
numerical constant will be represented by $\invc$.
 
Given a number $C<\infty$, and functions $X$\ and $Y$, we say that
{\dt $X$\ is
approximately equal to $Y$, with constant of approximation $C$}\
(in symbols $X
\labelledapprox C Y$), if $X\le CY$\ and $Y\le CX$. If the constant
of
approximation is a universal constant, then we simply say that $X$\
is {\dt
approximately equal to} $Y$\ (in symbols, $X\approx Y$). If we have
$X\le cY$,
then we say that $X$\ is {\dt approximately less than} $Y$, or that
$Y$\ is
{\dt approximately greater than} $X$.
 
\beginsection 1.2) Notation involving Integers
 
We write $\{\,j\in\Z:m\le j\le n\}$\ as $[m,n]$, and $[1,n]$\ as
$[n]$. It
should be clear from the context as to whether $[m,n]$\ means $\{\,j\in\Z:m\le
j\le n\}$\ or $\{\,t\in\R:m\le t\le n\}$. We write $\N$\ for the
natural
numbers, $\{\,j\in\Z:j\ge1\}$.
 
If $x$\ is a real number, we write $\lfloor x \rfloor$\ for the {\dt
integer
part} of $x$, that is, the greatest integer not exceeding $x$. We
write $\lceil
x \rceil$\ for $-\lfloor -x \rfloor$. Often we use a real number
where an
integer is to be expected, for example, in the limits of a sum; this
should be
understood as meaning the integer part of the number. Occasionally
we make
implicit use of the inequality
$$ \lfloor x \rfloor \ge \invc x \quad \hbox{for $x\ge1$.} $$
If $m$, $m'$\ and $n$\ are integers with $n>0$, then we write
$$m\equiv m'\pmod n $$
if $m-m'$\ is divisible by $n$.
If $m$\ and $n$\ are integers with $n>0$, then we write $m\bmod n$\
for the
integer $m'\in[1,n]$\ such that $m\equiv m'\pmod n$, that is,
$$ m\bmod n = m - n\lfloor\ts{m-1\over n}\rfloor .$$
 
\beginsection 1.3) Notation involving Real and Complex Numbers
 
If $x$\ and $y$\ are real numbers, we write $x\v y$\ for $\max\{x,y\}$\
and
$x\w y$\ for $\min\{x,y\}$. If $x=re^{i\theta}$\ is a complex number
(with
$r\ge0$\ and $\theta\in[0,2\pi)$), then we set $\modo x=r$, and
$\sign(x)=e^{i\theta}$\ if $r\ne0$, and $\sign(0)=0$.
We write $\R_+$\ for $\{\,t\in\R:t\ge0\}$. If $t\in\R_+$, then we
write $\log^+
t = 0\v\log t$.
 
We define the {\dt modified logarithm} and {\dt modified exponential}
functions
for $t>0$:
$$ \eqalignno{
   \lm(t) &= \cases{
     1+\log t                &for $t\ge1$\cr
                             &           \cr
     \ds {1\over1+\log\invt} &for $t\le1$;\cr} \cr
   \em(t) = \lm^{-1}(t) &= \cases{
     e^{t-1}      &for $t\ge1$\cr
                  &            \cr
     e^{-\invt+1} &for $t\le1$.\cr} \cr }$$
 
The function $\lm$\ is designed to behave very much like the function
$\log$
for large values, but modified so that it behaves well around $1$,
and so that
$\lm \invt = {1\over \lm t}$. Similarly, $\em$\ is just a modified
version of
$\exp$.
 
We have the following elementary result about $\lm$.
 
\proclaim Proposition 1.1. If $0<p<\infty$, and $\alpha\in\R$, then
there is a
number $C<\infty$, depending on $p$\ and $\alpha$\ only, such that
if
$$ s=t^p(\lm t)^\alpha ,$$
then
$$ t \labelledapprox C \big(s/(\lm s)^\alpha\big)^\invp .$$
 
\Proof It is easy to see that for some $C<\infty$, we have
$\lm s \labelledapprox C \lm t$, and the result follows.
\endproof
 
We also have the following elementary results about summing various
series.
These results will be heavily used throughout the thesis, especially
in Part~2.
 
\proclaim Proposition 1.2. Let $0<p<\infty$, and $\alpha\in\R$.
\item{i)} If $p<1$, then there is a number $C<\infty$, depending
on $\alpha$\
only, such that
$$ \eqalignno{
   C^{-1} N^{1-p} (\lm N)^\alpha
   &\le \sumN n^{-p} (\lm n)^\alpha \cr
   &\le C {1\over 1-p} N^{1-p} (\lm N)^\alpha ,\cr}$$
$$ \eqalignno{
   C^{-1} N^{1-p} (\lm (N/N_1))^\alpha
   &\le \sum_{n=1}^{N_1} n^{-p} (\lm(N/n))^\alpha \cr
   &\le C {1\over 1-p} N^{1-p} (\lm (N/N_1))^\alpha .\cr}$$
\item{ii)} If $p>1$, then there is a number $C<\infty$, depending
on $\alpha$\
only, such that
$$ \sumN n^{-p} (\lm n)^\alpha
   \le C \left(1\v{1\over p-1}\right) ,$$
$$ \sumN n^{-p} (\lm(N/n))^\alpha
   \le C \left(1\v{1\over p-1}\right) (\lm N)^\alpha .$$
\item{iii)} If $\alpha>-1$, then
$$ \eqalignno{
   \invc \left(1\w{1\over1+\alpha}\right) (\lm N)^{1+\alpha}
   &\le \sumN n^{-1} (\lm n)^\alpha \cr
   &\le c \left(1\v{1\over1+\alpha}\right) (\lm N)^{1+\alpha} ,\cr}$$
$$ \eqalignno{
   \invc \left(1\w{1\over1+\alpha}\right) (\lm N)^{1+\alpha}
   &\le \sumN n^{-1} (\lm(N/n))^\alpha \cr
   &\le c \left(1\v{1\over1+\alpha}\right) (\lm N)^{1+\alpha} .\cr}$$
\item{iv)} If $\alpha<-1$, then
$$ \sumN n^{-1} (\lm n)^\alpha
   \le c \left(1\v{-1\over1+\alpha}\right) ,$$
$$ \sumN n^{-1} (\lm(N/n))^\alpha
   \le c \left(1\v{-1\over1+\alpha}\right) (\lm N)^\alpha.$$
\item{v)}
$$ \sumN n^{-1} (\lm n)^{-1} \approx \lm\lm N ,$$
$$ \sumN n^{-1} (\lm(N/n))^{-1} \approx \lm\lm N .$$
 
\Proof All these results come from approximating sums by integrals.
For example, with (v), we have
$$ \eqalignno{
   \sumN n^{-1} (\lm n)^{-1}
   \le 1+ \int_1^N \ts{1\over t(1+\log t)} \,dt
   &= 1+\log(1+\log n) \cr
   &= \lm\lm N ,\cr} $$
and
$$ \sumN n^{-1} (\lm n)^{-1}
   \ge \int_1^N \ts{1\over t(1+\log t)} \,dt
   = -1+\lm\lm N . $$
\endproof
 
\beginsection 1.4) Notation involving Sets and Functions
 
Let $A$\ be a set. We write $\lmod A \rmod$\ for the number of elements
in
$A$, and $A^{(k)}$\ for the collection of $k$-subsets (that is, subsets
of size
$k$) of $A$.
 
If $a\colon X\to\C$\ is a function and $A\subseteq X$, then the symbol
$a\big|_A$\ denotes the function $X\to\C$\ defined by
$$ a\big|_A(x) = \cases{ a(x) & if $x\in A$ \cr
                         0    & if $x\in X\setminus A$. \cr }$$
If $A\subseteq X$, then the characteristic function of $A$\ in $X$,
$\chi_A^X=\chi_A$, is defined by
$$ \chi_A(x) = \cases{ 1 & if $x\in A$ \cr
                       0 & if $x\in X\setminus A$. \cr }$$
If $X$\ is any set, then the identity function on $X$\ is denoted
by $\Id_X$.
If $a\colon X\to Y$\ and $b\colon Y\to Z$\ are functions, then the
composite,
$b\circ a\colon X\to Z$, is the function $ b\circ a (x) = b(a(x))
$.
 
If $N\in\N$, then we write $S_N$\ for the symmetry group on $[N]$,
that is, the
set of permutations $\pi\colon[N]\to[N]$, with function composition
as the
group operation.
 
\beginsection 1.5) Notation involving Probability
 
With very few exceptions, we desire to treat random variables in
a naive
fashion. For this reason, we make the following conventions throughout
the
thesis.
We assume the existence of an underlying
probability space with measure $\Pr$. As usual, measurable functions
from the
probability space are called random variables, and for any integrable
random variable $X$, we write $\E X$\ for $\int X \,d\Pr$. We suppose
that
there are independent random variables $\gammalist,$\ $\epsilonlist$\
such that
for each $n\in\N$, $\gamma_n$\ is normalised Gaussian, that is,
$$ \Pr (\gamma_n > t )
   = {1\over\sqrt{2\pi}} \int_{-\infty}^t e^{-\half s^2}\,ds ,$$
and $\varepsilon_n$\ is Bernoulli, that is,
$$ \Pr (\varepsilon_n=1)=\Pr(\varepsilon_n=-1)=\half.$$
 
\vfill
\eject
 
\beginsection 2) Notation involving Quasi-Banach Spaces
 
The notation for Banach spaces and
quasi-Banach spaces is fairly standard, and
is loosely based on that used in [L--T1] and [L--T2]. We never worry as to
whether the spaces are real or complex.
If $X$\ is any Banach space, than its
dual is denoted $X^*$. The action of $\xi\in X^*$\ on $x\in X$\ is denoted
by
$\langle \xi,x \rangle$. Note, we do {\it not}\/ use $x^*$\ to represent a
typical element of $X^*$. If $\TXY$\ is
a \blobBs, then we denote its dual map
by $T^*\colon Y^*\to X^*$. We denote the unit ball of a quasi-Banach space
by $B_X$.
 
The notation for Banach lattices is also
standard, and we follow [L--T2]. In
particular, we have the functional calculus
(see [L--T2 Thm.1.d.1]), so that if
$f$, $g$, $f_1$, $f_2,\ldots,$\ $f_S$\
are elements of a lattice $X$, then so
are $f\v g$, $f\w g$, $\modo f$\ and
$\left(\sumS\modo{f_s}^q\right)^\invq$\
(where $0<q<\infty$).
 
\proclaim Definition. If $X$\ is a
Banach lattice, then we say that $X$\ is
{\dt $q$-concave} if there is a number
$C<\infty$\ such that for all $f_1$,
$f_2,\ldots,$\ $f_S\in X$\ we have
$$ \left(\sumS\normo{f_s}_X^q\right)^\invq
\le C \normo{\left(\sumS\modo{f_s}^q
   \right)^\invq}_X .$$
 
Practically all the quasi-Banach spaces
we refer to are rearrangement invariant
function spaces or $1$-symmetric sequence spaces, which we introduce here.
 
\beginsection 2.1) The $C(K)$, $L_\infty$\ and $l_\infty$\ Spaces
 
I shall assume that the reader is familiar
with the elementary properties of
the $L_\infty$\ spaces, which we define here.
 
\Lhalign{
Symbol&Vectors&Norm\cr
$C(K)$ &
Continuous functions on a compact Hausdorff space $K$ &
$\ds{\normf_\infty = \sup_{x\in K} \modfo{x}}$ \cr
\fiveL{\infty}&
Essentially bounded functions on measure space $\measspace$ &
$\normf_\infty = $\nl$\ds{ \esssup_{w\in\Omega} \modfo w }$\cr
$l_\infty$ &
Bounded functions from $\N$ &
$\ds{\normf_\infty = \sup_{n\in\N} \modfo n }$\cr
$l_\infty^N$ &
Functions from $[N]$ &
$\ds{\normf_\infty = \supN \modfo n}$ \cr
}
 
\beginsection 2.2) The $L_p$\ and $l_p$\ Spaces
 
Here we define the $L_p$\ spaces for
$0<p<\infty$. The reader will recall that
$L_p$\ is a normed space for $p\ge1$, otherwise it is only a quasi-normed
space.
 
\Lhalign{
Symbol&Vectors&\hbox{Quasi-norm}\cr
\fiveL{p}&
Measurable functions on measure space $\measspace$\ such that
$\int \modf^p\,d\mu < \infty$ &
$\normf_{L_p}=\normf_p = $\nl$ \left(\int\modf^p\,d\mu \right)^\invp$ \cr
$l_p$&
Functions from $\N$\ such that
\newline
$\sumninfty \modfo n^p <\infty$&
$\normf_p= $\nl$ \left(\sumninfty\modfo n^p\right)^\invp$ \cr
$l_p^N$&
Functions from $[N]$&
$\normf_{l_p^N}=\normf_p=$\nl$ \left(\sumN\modfo n^p\right)^\invp$ \cr
$L_p^N$&
Functions from $[N]$&
$\normf_{L_p^N}= $\nl$ \left(\invN\sumN\modfo n^p\right)^\invp$ \cr
}
 
Note the difference between $l_p^N$\ and $L_p^N$. Both spaces consist of
functions from $[N]$, but in the first
case, $l_p^N$, the measure on $[N]$\ is
$\moddot$, whereas with $L_p^N$, the measure is the probability measure
$\invN\moddot$.
 
\beginsection 2.3) Orlicz Spaces
 
These spaces will also be discussed in
Part~3, where we will prove many of the
results quoted here. The definitions here are slight extensions of those
usually given (see, for example, [B--S Ch.4], [K--R], [L--T1 Ch.4], [L--T2
p120] or [Mu]).
 
\proclaim Definition. A {\dt \nqOf} is a function
$\Phi\colon[0,\infty)\to[0,\infty)$\ satisfying the following.
\item{i)} $\Phi(0)=0$, and $\Phi(t)\to\infty$\ as $t\to\infty$.
\item{ii)} $\Phi$\ is continuous and strictly increasing.
\item{iii)} The {\dt $\half$-dilatory
constant} of $\Phi$, $\sup_{x\in\R_+}
\Phi^{-1}(2 x)/\Phi^{-1}(x)$, is finite.
\moreproclaim\noindent
If $\Phi$\ is a \nqOf, we write $\tilde\Phi$\ for the
\nqOf
$$\tilde\Phi(x)=1/\Phi(\ts{1\over x}) .$$
 
We often label a function by its effect on $T$, for example the function
$\Phi\colon x\mapsto x^2$\ is called $T^2$.
Typical \nqOf s include $T^p(\lm T)^\alpha$\ and
$\em(T^p)$, where $0<p<\infty$\ and $\alpha\in\R$.
Where no confusion can arise, we write $p$\ for the function $T^p$. Thus
$L_p=L_{T^p}$.
 
Practically all the \nqOf s that we will consider will satisfy
$\tilde\Phi=\Phi$.
 
\proclaim Definition. A \nqOf\ $\Phi$\ is said to satisfy the {\dt
$\Delta_2$-condition} if\/ $\sup_{x\in\R_+} \Phi(2x)/\Phi(x)$\ is finite.
 
\proclaim Proposition 2.1. Let $\Phi$\
be a convex \nqOf\ that satisfies the
$\Delta_2$-condition. Then there are
numbers $0<q<\infty$, $C<\infty$, and a
\nqOf\ $\Psi$\ such that
\item{i)} $\Psi^{-1} \labelledapprox C \Phi^{-1} $;
\item{ii)} $\Psi$\ is convex;
\item{iii)} $\Psi\circ T^{\invq}$\ is concave.
 
\Proof See Proposition~3A:2.9.
\endproof
 
\proclaim Definition. Let $\Phi$\ be a
\nqOf, and $\measspace$\ be any measure
space. Then for any measurable $f\colon\Omega\to\C$, we define its
{\dt $\Phi$-quasi-Orlicz norm} to be
$$ \normf_\Phi = \inf\left\{\,\lambda:\int_\Omega
                 \Phi\left(\ts{\modfo w \over\lambda}\right)
                 \,d\mu(w) \le 1 \right\}.$$
 
\proclaim Proposition 2.2. Let $\Phi$\
be a \nqOf. Then $\normdot_\Phi$\ is a
quasi-norm. If $\Phi$\ convex, then $\normdot_\Phi$\ is a norm.
 
\Proof See Proposition~3A:3.5, or any of the above references.
\endproof
 
If $\Phi$\ is a \nqOf, then we form the {\dt Orlicz spaces}.
 
\Lhalign{
Symbol&Vectors&Quasi-norm\cr
\fiveL{\Phi}&
Measurable functions on measure space $\measspace$\ such that
$\normf_\Phi < \infty$ &
$\normf_{L_\Phi}=\normf_\Phi $\cr
$l_\Phi$&
$L_\Phi(\N)$&
$\normf_\Phi $\cr
$l_\Phi^N$&
$L_\Phi([N],\moddot)$&
$\normf_\Phi $\cr
$L_\Phi^N$&
$L_\Phi([N],\invN\moddot)$&
$\normf_{L_\Phi^N} $\cr
}
 
For comparing quasi-Orlicz norms, we have the following result.
 
\proclaim Proposition 2.3. Let $\Phi$\ and $\Psi$\ be \nqOf s, and let
$0<C<\infty$.
\item{i)} If $\tilde\Phi^{-1}(t)\le C\tilde\Psi^{-1}(t)$\ for all
$t\in[0,\infty)$, then $\normdot_\Phi\le C\normdot_\Psi$.
\item{ii)} There is a constant $C'$, depending on the $\half$-dilatory
constant of $\Phi$\ only, such that the following holds. Let
$\measspace$\ be a measure space, and set\/ $ \mu_{\min} =
\inf\{\,\mu(A):\mu(A)>0\}$.
If\/
$ \tilde\Phi^{-1}(t)\le C\tilde\Psi^{-1}(t)
   \quad\hbox{for}\quad
   \mu_{\min}\le t \le \mu(\Omega) $,
then\/
$ \normdot_{L_\Phi(\mu)}\le CC'\normdot_{L_\Psi(\mu)} $.
\endit
 
\Proof See Propositions~3A:3.6 and~3B:3.1
(see also [K--R Thm.8.1] or [L--T1
4.a.5]).
\endproof
 
\beginsection 2.4) Lorentz Spaces
 
These spaces are discussed in greater detail in Part~3.
 
\proclaim Definition. Let $\measspace$\ be any measure space, and
$f\colon\Omega\to\C$\ be a measurable function. Then the {\dt decreasing
rearrangement of $\modf$} is
$$ f^*(t) = \sup \{\, s: \mu\{\modf\ge s\}\ge t \}, $$
that is, $f^*\colon[0,\infty)\to[0,\infty)$\
is the left continuous inverse of the function
$s\mapsto\mu\{\modo f\ge s\}$.
Thus, for example, if we have
$f\colon[N]\to\C$\ (where $[N]$\ is given the
counting measure), then $(\,f^*(n):n\in[N])$\ is the sequence of numbers
$(\,\modfo n :n\in[N])$\ rearranged in decreasing order.
 
\proclaim Definition. Let $\Phi$\ be a \nqOf, $\measspace$\ be any measure
space, and $0<q\le\infty$. Then for any
measurable $f\colon\Omega\to\C$, we
define its {\dt $L_\Phiq$\ quasi-norm} to be
$$ \eqalignno{
   \normf_\Phiq &= \left( \int_0^\infty \left( f^*(\tilde\Phi(t^\invq))
                   \right)^q \,dt \right)^\invq \cr
                &= \left( \int_0^\infty \bigl( f^*(t) \bigr)
                   \,d\bigl(\tilde\Phi^{-1}(t)\bigr)^q \right)^\invq
                   \qquad \hbox{if $q<\infty$} ,\cr
   \normf_{\Phi,\infty} &= \sup_{t\in\R_+}
\tilde\Phi^{-1}(t) f^*(t) .\cr}$$
 
\proclaim Proposition 2.4. Let $\Phi$\
be a \nqOf, and $0<q\le \infty$. Then
$\normdot_\Phiq$\ is a quasi-norm.
 
\Proof See Proposition~3A:5.3 and~3A:5.5.
\endproof
 
If $\Phi$\ is a \nqOf, and $0<q\le\infty$, then we form the {\dt Lorentz
spaces}.
 
\Lhalign{
Symbol&Vectors&Quasi-norm\cr
\fiveL{\Phiq}&
Measurable functions on measure space $\measspace$\ such that
$\normf_\Phiq < \infty$ &
$\normf_{L_\Phiq}=\normf_\Phiq $\cr
$l_\Phiq$&
$L_\Phiq(\N)$&
$\normf_\Phiq $\cr
$l_\Phiq^N$&
$L_\Phiq([N],\moddot)$&
$\normf_\Phiq $\cr
$L_\Phiq^N$&
$L_\Phiq([N],\invN\moddot)$&
$\normf_{L_\Phiq^N} $\cr
}
 
If $\Phi=T^p$, then $L_\Phiq = L_{p,q}$,
the familiar Lorentz quasi-norm. If
$\Phi = T^p(\lm T)^\alpha$, then the $L_\Phiq$\ spaces are the same as the
Lorentz--Zygmund spaces described in [B--R] or [B--S Ch.4 \S6].
 
The properties of the $L_{p,q}$\ norm are well documented (see for example
[B--L], [B--S], [H], [L--T2] or [Lo]). If $p=q$\ then
$\normdot_{p,q}=\normdot_p$, and if $1\le q\le p <\infty$\ then
$\normdot_{p,q}$\ is a norm. We also have the following comparison result.
 
\proclaim Proposition 2.5. Let $0<p<\infty$\ and $0<q_1\le q_2\le\infty$.
\ditem{i)} $\normdot_{p,q_1}\ge\normdot_{p,q_2} $.
\ditem{ii)} $\normdot_{l_{p,q_1}^N} \le \left(1+c\left(\ts\invp\log
N\right)^{\invqs1-\invqs2}\right) \normdot_{l_{p,q_2}^N} $.
 
\proof of i): This is well known. See the above references (see also
Theorem~3B:2.1).
\endproof
 
\proof of ii): If $f\in\C^N$, then
$$ \eqalignno{
   &\normo f_{p,q_1}
   = \left(\ts{\qops1} \int_0^N t^{\qops1-1}(f^*(t))^{q_1}\,dt
   \right)^{\invqs1} \cr
   &\le (2^{\invqs1}\v1) \left(f^*(1) +
   \left(\ts{\qops1} \int_1^N
t^{\qops1-1}(f^*(t))^{q_1}\,dt \right)^{\invqs1} \right)
   \cr
   &\le \normo f_{p,q_2} + \left(\ts{\qops1}\right)^{\invqs1}
   \left(\ts{\poqs2}\right)^{\invqs2}
   \left(\int_1^N t^{-1}\,dt\right)^{\invqs1-\invqs2}
   \left(\ts{\qops2} \int_1^N
t^{\qops2-1}(f^*(t))^{q_2}\,dt \right)^{\invqs2} \cr
   &\le \left(1+c\left(\ts{\invp} \log N\right)^{\invqs1-\invqs2} \right)
   \normo f_{p,q_2} .\cr}$$
\endproof
 
Now, we will give some elementary results
on calculating $L_\Phiq$\ norms for
spaces of functions from $[N]$.
 
\proclaim Definition. Let $N\in\N$, and $f\colon[N]\to\C$\ be a
function. A bijection $\pi\colon[N]\to[N]$\ is called an {\dt ordering
permutation} for $f$\ if for all $m,n\in[N]$\ we have
$$ \modfo m \ge \modfo n \Leftrightarrow \pi(m) \le \pi(n) .$$
Thus $f^*(\pi(n)) = f(n)$.
 
\proclaim Proposition 2.6. Let $f\in\C^N$, $\pi\colon[N]\to[N]$\ be an
ordering permutation for $f$, $0<p,q<\infty$, and $\alpha\in\R$.
\item{i)} If $q\le p$\ then
$$ \left( \qop \sumN \bigl(\pi(n)\bigr)^{\qop-1} \modfo n^q \right)^\invq
   \le \normo f_{p,q}
   \le \left( \sumN \bigl(\pi(n)\bigr)^{\qop-1}
\modfo n^q \right)^\invq ,$$
and if $p\le q$\ then
$$ \left( \sumN \bigl(\pi(n)\bigr)^{\qop-1} \modfo n^q \right)^\invq
   \le \normo f_{p,q}
   \le \left( \qop \sumN \bigl(\pi(n)\bigr)^{\qop-1}
\modfo n^q \right)^\invq .$$
In both cases, $\normo f_{L_{p,q}^N} = N^{_\invp} \normo f_{p,q}$.
\item{ii)} There is a number $C<\infty$,
depending on $p$, $q$\ and $\alpha$\
only, such that
$$ \eqalignno{
   \normo f_{T^p(\lm T)^\alpha,q}
   &\labelledapprox C
   \left( \sumN \bigl(\pi(n)\bigr)^{\qop-1}
\bigl(\lm \pi(n)\bigr)^{-\alpha\qop} \modfo n^q
   \right)^\invq , \cr
   \normo f_{L_{T^p(\lm T)^\alpha,q}^N}
   &\labelledapprox C N^{-\invp}
   \left( \sumN \bigl(\pi(n)\bigr)^{\qop-1}
\bigl(\lm(N/\pi(n))\bigr)^{\alpha\qop} \modfo n^q
   \right)^\invq . \cr }$$
 
\proof of i): Clearly
$$ N^\qop \normo f_{L_{p,q}^N}^q = \normo f_{p,q}^q
   = \sumN \Bigl(\bigl(\pi(n)\bigr)^\qop-\bigl(\pi(n)-1\bigr)^\qop\Bigr)
\modfo n^q ,$$
and the result follows easily.
\endproof
 
\proof of ii): Let $\Phi=\tilde\Phi=T^p(\lm
T)^\alpha$. By Proposition~1.1,
there is a number $C<\infty$, such that $\Phi^{-1} = \tilde\Phi^{-1}
\labelledapprox{C^{\alpha\over p}} (T/(\lm T)^\alpha)^\invp $. So
$$ \eqalignno{
   \normo f_\Phiq^q
   &= \int_0^\infty (f^*(t))^q \,d(\tilde\Phi^{-1}(t))^q \cr
   &\labelledapprox{C^{\alpha \qop}}
   \sumN \left(
\left({\pi(n)\over\bigl(\lm\pi(n)\bigr)^\alpha}\right)^\qop
   - \left({\pi(n)-1\over\bigl(\lm(\pi(n)-1)\bigr)^\alpha}\right)^\qop
\right)
   \modfo n^q \cr
   &\labelledapprox{C_1}
   \sumN {\bigl(\pi(n)\bigr)^{\qop-1}
\over \bigl(\lm\pi(n)\bigr)^{\alpha\qop}}
   \modfo n^q .\cr}$$
for some number $C_1<\infty$. The argument for $\normo f_{L_\Phiq^N}$\ is
similar.
\endproof
 
We also have the following result, that provides
some comparison between the Orlicz and Lorentz
quasi-norms.
 
\proclaim Theorem 2.7. (Bennett and Rudnick)
Let $0<p<\infty$, and $\alpha\in\R$.
\item{i)} There is a number $C<\infty$,
depending on $p$\ and $\alpha$, such that
$$ \normdot_{T^p(\lm T)^\alpha} \labelledapprox C
   \normdot_{T^p(\lm T)^\alpha ,p} .$$
\item{ii)} There is a number $C<\infty$,
depending on $\alpha$\ only, such that
$$ \normdot_{\em(T^p)} \labelledapprox C
   \normdot_{\em(T^p), \infty} .$$
 
\Proof See Theorem~3B:2.7. (See also [B--R] and [B--S Ch.4 \S6].)
\endproof
 
Finally, we introduce notation for the natural embedding map.
 
\proclaim Definition. Let $\measspace$\ be a measure space, and $L_A$,
$L_B$\ be any of the spaces described in Sections~2.1 to~2.4 such that
for some number $C<\infty$, we have
$\normdot_{L_A} \ge C^{-1} \normdot_{L_B}$.
Then we denote the natural
embedding $f\mapsto f$, from $L_A$\ to
$L_B$, by $L_A \hookrightarrow L_B$.
 
Examples are $C(K) \hookrightarrow L_\Phiq(K,\mu)$\ and
$L_{\Phi_1,q_1}^N \hookrightarrow L_{\Phi_2,q_2}^N$.
 
\beginsection 2.5) Interpolation Norms
 
These norms are well known, see for example, [B--L] or [B--S].
 
\proclaim Definition. Let $\normdot_A$\ and $\normdot_B$\ be two norms on
$\C^N$. If $0\le t<\infty$\ then
\item{i)} the {\dt $K$-interpolation norm} on $\C^N$\ is defined by
$$ K(a,t,\normdot_A,\normdot_B) = \inf
\{\,\lnorm a' \rnorm_A + t \lnorm a''
   \rnorm_B: a'+a''=a\};$$
\item{ii)} the {\dt $J$-interpolation norm} on $\C^N$\ is defined by
$$ J(a,t,\normdot_A,\normdot_B) = \max \{\norma_A,t\norma_B\}.$$
 
\proclaim Proposition 2.8. Let $\normdot_A$\
and $\normdot_B$\ be two norms on
$\C^N$, and let $\normdot_A^*$\ and $\normdot_B^*$\ be their dual norms
respectively, with respect to the standard
duality, $\langle \xi,x \rangle =
\sumN \xi(n) x(n)$. If $0<t<\infty$, then the
norms $K(\widecdot,t,\normdot_A,\normdot_B)$\ and
$J(\widecdot,\invt,\normdot_A\normdot_B)$\ are also dual to one another.
 
\Proof This is elementary. See [B--L Thm.2.71].
\endproof
 
We also define a norm which we will use
once in Chapter~2A. As far as I know,
this norm, and the proposition following, are new.
 
\proclaim Definition. Let $M,N\in\N$. An {\dt $M$-partition} of $[N]$ is a
collection of $M$\ disjoint subsets of $[N]$, $\{\betaM\}$, such that
$\bigcup_{m=1}^M \beta_m = [N]$. If $0<p<q<\infty$, then the
{\dt $(p,q)$-$M$-partition norm} on $\C^N$\ is defined by
$$ \norma_\PpqM = \sup \left\{ \left( \sumM \lnorm \asubbetam \rnorm_q^p
                  \right)^\invp \right\},$$
where the supremum is over all $M$-partitions of\/ $[N]$.
 
\proclaim Proposition 2.9. If $M\in\N$,
and $0<p<q<\infty$, then there is a
number $C<\infty$\ depending on $p$\ and $q$\ only, such that
$$ K(\widecdot,M^{\invp-\invq},\normdot_p,\normdot_q) \labelledapprox C
   \normdot_\PpqM .$$
 
\Proof First we show that $\normdot_\PpqM \le C
K(\widecdot,M^{\invp-\invq},\normdot_p,\normdot_q)$.
For it is easy to see that
$\normdot_\PpqM \le \normdot_p$\ and
that $\normdot_\PpqM \le M^{\invp-\invq}
\normdot_q$. Hence, if $a\in\C^N$, then
$$ \eqalignno{
   K(a,M^{\invp-\invq},\normdot_p,\normdot_q)
   &= \inf\{\, \normo{a'}_p +
M^{\invp-\invq}\normo{a''}_q : a=a'+a'' \} \cr
   &\ge \inf\{\, \normo{a'}_\PpqM + \normo{a''}_\PpqM : a=a'+a'' \} \cr
   &\ge C^{-1} \normo a_\PpqM ,\cr}$$
where the last inequality follows as $\normdot_\PpqM$\ is a quasi-norm.
 
For the converse inequality, suppose that
$K(a,M^{\invp-\invq},\normdot_p,\normdot_q)\ge1$.
We will let $b=\modo a^p$, so that
$K(b,M^\invr,\normdot_1,\normdot_\qop)
\ge 1$, where $\invr + \poq = 1$. By the
duality given in Proposition~2.8, there is a $\zeta\in\C^N$\ such that
$J(\zeta,M^{-\invr},\normdot_\infty,\normdot_r)=1$\
and $\sumN \zeta(n)b(n) \ge
1$.
 
Since $\supN \modo{\zeta(n)} \le 1$\ and
$\sumN \modo{\zeta(n)}^r \le M$, we can
choose a $M$-partition of $[N]$,
$\{\betaM\}$, such that $\sum_{n\in\beta_m}
\modo{\zeta(n)}^r \le 2$\ for each $m\in[M]$. Hence
$$
   \normo b_{P_{1,\qop}(M)}
   \ge \sumM \normo{b\big|_{\beta_m}}_\qop
   \ge 2^{-\invr} \sumM \sum_{n\in\beta_m} \zeta(n) b(n)
   \ge 2^{-\invr} .$$
Hence $\normo a_\PpqM \ge \normo
b_{P_{1,\qop}(M)}^\invp \ge 2^{\invq-\invp}$.
\endproof
 
\beginsection 2.6) Spanning Points of $C(K,l_1)$
 
As the last result of this section, we give a result due to Maurey.
 
\proclaim Definition. Let $K$\ be a compact Hausdorff space and $1\le p
<\infty$. Then the Banach space $C(K,l_p)$\ is the space of sequences
$a=\bigl(\,(a_s)_{s=1}^\infty:a_s\in C(K)\bigr)$\ such that
$$ \norma_{C(K,l_p)} = \lnorm \left( \sum_{s=1}^\infty \lmod a_s \rmod^p
                       \right)^\invp \rnorm_\infty < \infty.$$
 
\proclaim Proposition 2.10. Let $T\colon
C(K,l_1)\to Y$\ be a linear operator
to a normed space $Y$. Then $\normo T$\ is equal to the supremum of
$\normo{T\bigl((a_1,a_2,\ldots,a_S,0,0,\ldots)\bigr)}$,
over all continuous functions $a_1$, $a_2,\ldots,$\ $a_S$\ from $K$\ with
disjoint support and $\normo{a_s}_\infty\le1$.
 
\Proof See [Ma2 Lem.4] or [J2 Prop.14.4].
\endproof
 
\vfill
\eject
 
\beginsection 3) Notation involving Ideals
 
The notion of an operator ideal is introduced in [Pt].
Our definition is essentially the same, but for ease we define the
norm first.
 
\proclaim Definition. A {\dt quasi-ideal norm} is a function, $\alpha$,
from
the class of all bounded linear operators between Banach spaces,
to
$[0,\infty]$, such that the following hold.
\item{i)} If $T$\ is a finite rank operator, then $\alpha(T)<\infty$.
\item{ii)} There is a number $C<\infty$\ such that for bounded linear
operators $S,\,T\colon X\to Y$, we have $\alpha(S+T)\le C\big(
\alpha(S)+\alpha(T)\big)$.
\item{iii)} If $S$\ is a bounded linear operator, and $\lambda\in\C$,
then
$\alpha(\lambda S)=\lmod\lambda\rmod\alpha(S)$.
\item{iv)} If $R\colon X\to Y$, $S\colon Y\to Z$, $T\colon Z\to W$\
are bounded
linear operators, then $\alpha(T\circ S\circ R)\le \lnorm
T\rnorm\alpha(S)\lnorm R\rnorm$.
\moreproclaim
The {\dt ideal} defined by $\alpha$\ is the class of operators $T$\
such that
$\alpha(T)<\infty$. If in (ii) we have $C=1$, then we say that $\alpha$\
is an
{\dt ideal norm}. If $X$\ is any Banach space, we write $\alpha(X)$\
for
$\alpha(\Id_X)$.
 
All the ideals we will use we introduce here. They are all standard
(and can be
found in [Pt]) except for the $(\Phi,\Psi)$-summing norm.
 
\beginsection 3.1) Operators that Factor through Hilbert Space
 
This is one of the most elementary ideals. All the work in the first
two parts
of this thesis can be thought of as having stemmed from studying
this
particular ideal. Its definition is very simple.
 
\proclaim Definition. The {\dt Hilbert space factorization norm}
is defined by
$$ \gamma(T\colon X\to Y) = \inf\{\,\normo R \normo S:T=S\circ R,\,
   R\colon X\to H,\,S\colon H\to Y \},$$
where $H$\ is a Hilbert space.
 
We note that if $X$\ is a Banach space, then $\gamma(X)$\ is the
Banach--Mazur
distance of $X$\ from Hilbert space.
 
\beginsection 3.2) The $(p,q)$-Summing Operators
 
\proclaim Definition. Suppose $0<q\le p<\infty$. The {\dt $(p,q)$-summing
norm} of
a bounded linear operator $T\colon X\to Y$, denoted by $\pi_{p,q}(T)$,
is the
least number $C$\ such that for all $\xS\in X$\ we have
$$ \pthmpnormTxs \le
   C \sup \left\{\, \left( \sumS \lmod \langle \xi,x_s \rangle \rmod^q
   \right)^\invq : \xi\in B_{X^*} \right\}. $$
The $(p,p)$-summing norm of $T$ is simply called the {\dt $p$-summing
norm} of
$T$\ and is denoted by $\pi_p(T)$. We say an operator is {\dt $(p,q)$-summing}
({\dt $p$-summing}) if its $(p,q)$-summing norm ($p$-summing norm)
is finite.
 
We give the following well known identities.
 
\proclaim Proposition 3.1. Let $X$\ be a Banach space, and $\xS\in
C(K)$.
\cditem{i)}
$$ \sup \left\{\, \sumS \lmod \langle \xi,x_s \rangle \rmod
   : \xi\in B_{X^*} \right\}
   = \sup \left\{\, \normo{\sumS \zeta_s x_s }
   : \zeta_s=\pm1 \right\} .$$
\item{ii)} If $X=C(K)$\ and $1\le q<\infty$, then
$$ \sup \left\{\, \left( \sumS \lmod \langle \xi,x_s \rangle \rmod^q
   \right)^\invq : \xi\in B_{C(K)^*} \right\}
   = \lnorm \left( \sumS \lmod x_s\rmod^q \right)^\invq \rnorm_\infty
.$$
 
\beginsection 3.3) Type and Cotype of Operators
 
\proclaim Definition. Suppose $1\le p\le2\le q<\infty$. We say that
a bounded
linear operator $T\colon X\to Y$\ has
\item{i)} {\dt Rademacher} (or {\dt Bernoulli}) {\dt type $p$} if
for all
$\xS\in X$\ we have
$$ \pthmpnormTxs \le C \E \Bernwalkx; \eqno (3.1) $$
\item{ii)} {\dt Rademacher} (or {\dt Bernoulli}) {\dt cotype $q$}
if for all
$\xS\in X$\ we have
$$ \E \BernwalkTx \le C \qthmqnormxs; \eqno (3.2) $$
\item{iii)} {\dt Gaussian type $p$} if for all $\xS\in X$\ we have
$$ \pthmpnormTxs \le C \E \Gausswalkx; \eqno (3.3) $$
\item{iv)} {\dt Gaussian cotype $q$} if for all $\xS\in X$\ we have
$$ \E \GausswalkTx \le C \qthmqnormxs; \eqno (3.4) $$
\moreproclaim\noindent
where $C<\infty$.
The {\dt Rademacher type $p$\ constant}, {\dt Rademacher cotype $q$\
constant}, {\dt Gaussian type $p$\ constant} and {\dt Gaussian cotype
$q$\
constant} of the operator $T\colon X\to Y$ is the least number $C$
in
$(3.1)$, $(3.2)$, $(3.3)$\ and $(3.4)$\ respectively, and they are
denoted by
$R_p(T)$, $R^q(T)$, $G_p(T)$\ and $G^q(T)$\ respectively.
 
\beginsection 3.4) The $(\Phi,\Psi)$-Summing Operators
 
\proclaim Definition. Suppose $\Phi$\ and $\Psi$\ are \nqOf s. The
{\dt $(\Phi,\Psi)$-summing norm} of a bounded linear operator $T\colon
X\to Y$,
denoted by $\pi_{\Phi,\Psi}(T)$, is the least number $C$\ such that
for all
$\xS\in X$\ we have
$$ \normo{(\normo{T(x_s)})_{s=1}^S}_\Phi \le
   C \sup \left\{\, \normo{ (\modo{\langle \xi,x_s \rangle})_{s=1}^S
}_\Psi
   : \xi\in B_{X^*} \right\}. $$
We say an operator is {\dt $(\Phi,\Psi)$-summing} if its $(\Phi,\Psi)$-summing
norm is finite.
 
We will work only with the $(\Phi,1)$-summing norm.
 
\vfill
\eject
 
\beginsection Chapter 1B --- Properties of $(p,q)$-Summing Operators
from
$C(K)$
 
In this chapter, we discuss how $(p,q)$-summing operators factorize
through
certain operators and spaces. First we deal with $p$-summing operators,
for
which the theory is well known. Then we deal with the $(p,q)$-summing
operators
for $q<p$, presenting a recent result due to Pisier, and some old
work due to
Maurey. Finally, in Section~3, we give a finite dimensional version
of Pisier's
result that will be important later on.
 
\beginsection 1) The $p$-Summing Operators
 
The following result is basic to the theory of $p$-summing operators,
and is
due to Pietsch.
 
\proclaim Theorem 1.1. (See [P1 Thm.1.3 Rem.1.4], [Pt 17.3.2] or
[J2
5.2].)
Let $\TXY$\ be a \blobBs, and let $K$\ be a
subset of $X^*$\ that is norming ($\normo x_X = \sup_{\xi\in K}\langle
\xi,x
\rangle$\ for all $x\in X$), and closed (and hence compact) with
respect to the
weak * topology. Then for $1\le p<\infty$\ and $C<\infty$\ the following
are
equivalent.
\item{i)} $T$\ is $p$-summing with $\pi_p(T)\le C$.
\item{ii)} There is a Radon probability measure $\mu$\ on $K$ such
that we have
the following factorization:
$$ T\colon X\tonamed E Z \tonamed U X,$$
where $E\colon X\to C(K)$\ is the map $E(x)=(\xi\mapsto\langle
\xi,x \rangle)$, $Z$\ is the closure of $E(X)$\ in $L_p(K,\mu)$,
and
$\normo U \le C$.
\endit
 
\proclaim Corollary 1.1a. (See [P1 Cor.1.5] or [Pt 17.3.3].)
If $\TCKY$\ is a bounded linear operator, then, for
$1\le p<\infty$\ and $C<\infty$, the following are equivalent.
\item{i)} $T$\ is $p$-summing with $\pi_p(T)\le\infty$.
\item{ii)} There is a Radon probability measure $\mu$\ on $K$\ such
that we
have the following factorization with $\normo U\le C$:
$$ T\colon C(K) \hookrightarrow L_p(\mu) \tonamed U Y.$$
 
\proclaim Corollary 1.1b. (See [P1 Cor.1.8] or [Pt 17.3.7].)
If $\TXY$\ is $2$-summing, then it factors through
a Hilbert space, with $\gamma(T)\le \pi_2(T)$.
 
For maps from $C(K)$\ we have a converse to Corollary~1.1b.
 
\proclaim Theorem 1.2. (See [P1 Thm.5.4 and Remark following].)
If $\TCKY$\ factors through Hilbert space, then it is
$2$-summing, with $\pi_2(T)\le 2\pi^{-\half} \gamma(T)$. (The constant
is
$\sqrt{\pi\over 2}$\ if scalars are real.)
 
\vfill
\eject
 
\beginsection 2) The $(p,q)$-Summing Operators, with $p>q$
 
The analogue of Pietsch's result for $(p,q)$-summing operators with
$p>q$,
is a theorem due to Pisier, which we state here.
 
\proclaim Theorem 2.1. (See [J2 14.1], [P3] or [P4].)
Let $\TCKY$\ be a \blotaBs, and $1\le q<p<\infty$. Then
the following are equivalent.
\item{i)} $T$\ is $(p,q)$-summing.
\item{ii)} There is a Radon probability measure $\mu$\ on $K$\ and
a number
$C<\infty$\ such that for all $x\in C(K)$\ we have
$$ \normo{T(x)} \le C \normo x_{L_q(K,\mu)}^\qop \normo x_\infty^{1-\qop}
.
   \eqno (2.1) $$
\item{iii)} There is a Radon probability measure $\mu$\ on $K$\ and
the
factorization
$$ T\colon C(K)\hookrightarrow L_{p,1}(K,\mu) \tonamed U X \eqno
(2.2) $$
where $U$\ is a \blo.
\moreproclaim \noindent
If we let $C_1=\inf\{\,C:(2.1)$\ holds for some $\mu\}$\ and
$C_2=\inf\{\,\normo U:(2.2)$\ holds for some $\mu\}$, then
$$ \pi_{p,1}(T) \le C_1 \le p^\invp \pi_{p,1}(T)
   \quad\hbox{and}\quad
   C_2 \le C_1 \le
   q^{-\invp} \left(\ts{p-1\over p-q}\right)^{1-\invp} C_2.$$
 
\Proof For (i)$\Rightarrow$(ii), see the above references,
or follow the methods of
the proof of Theorem~1D:4.1. The implication (ii)$\Rightarrow$(i)
is easy. For
(ii)$\Rightarrow$(iii), use Lemma~1D:4.2.
 
We show (iii)$\Rightarrow$(ii). Suppose that $\normo x_\infty \le
1$. Then
$$ \eqalignno{
   \normo{Tx}
   &\le C\normo x_{L_{p,1}(K,\mu)} \cr
   &= \int_0^1 (\mu\{\modo{x}\ge s\})^\invp \,ds \cr
   &\le \left( q^{-{1\over p-1}} \int_0^1 s^{-{q-1\over p-1}} \,ds
   \right)^{1-\invp} \left( q \int_0^1 s^{q-1} \mu\{\modo{x}\ge s\}
\,ds
   \right)^\invp \cr
   &\le q^{-\invp} \left(\ts{p-1\over p-q}\right)^{1-\invp}
   \normo x_{L_q(K,\mu)}^\qop .\cr}$$
\endproof
 
From this we may easily deduce the following result of Maurey.
 
\proclaim Corollary 2.1a. (See [Ma2 Prop.3].)
If $\TCKY$\ is a \blotaBs, and $1\le q<p<\infty$, then
$T$\ is $(p,q)$-summing if and only if it is $(p,1)$-summing, with
$$ \pi_{p,1}(T) \le \pi_{p,q}(T)
   \le  \left(\ts\poq\right)^\invp
   \left(\ts{p-1\over p-q}\right)^{1-\invp} \pi_{p,1}(T).$$
 
However this result cannot be extended to say that the $(p,1)$-summing
norm is
equivalent to the $p$-summing norm for operators from $C(K)$.
 
\proclaim Proposition 2.2. (See also [J1].)
Let $T$\ be the map $l_\infty\hookrightarrow
L_{p,1}^N$. Then $\pi_{p,1}(T)=1$, whereas $\pi_p(T)\approx1+\left(\invp\log
N\right)^{1-\invp}$.
 
\Proof That $\pi_{p,1}(T)=1$\ follows straight away from Theorem~2.1.
To show that
$\pi_p(T)\le 1+c\left(\invp\log N\right)^{1-\invp}$, notice that
we have the
factorization
$$ l_\infty \hookrightarrow L_p^N \hookrightarrow L_{p,1}^N ,$$
where by Proposition~1A:2.5(ii) we have that
$$ \normo{L_p^N \hookrightarrow L_{p,1}^N}
   \le 1+c\left(\ts\invp\log N\right)^{1-\invp} .$$
The result then follows by Theorem~2.1.
 
To show the converse inequality, let $x_1$, $x_2,\ldots,$\ $x_N$\
be the
vectors
$$ x_1 = \left(\matrix{
         1^{-\invp} \cr 2^{-\invp} \cr \vdots \cr N^{-\invp} \cr
         }\right) ,\quad
   x_2 = \left(\matrix{
         2^{-\invp} \cr 3^{-\invp} \cr \vdots \cr 1^{-\invp} \cr
         }\right) ,\ldots,\quad
   x_N = \left(\matrix{
         N^{-\invp} \cr 1^{-\invp} \cr \vdots \cr (N-1)^{-\invp}
\cr
         }\right) .$$
Then
$$\left(\sum_{s=1}^N \normo{x_s}_{L_{p,1}^N}^p \right)^\invp
   \approx 1 + \ts\invp\log N,$$
whereas
$$ \normo{\left(\sum_{s=1}^N \modo{x_s}^p\right)^\invp}_\infty
   \approx \left(1+\log N\right)^\invp .$$
The result follows (note that $p^\invp \approx 1$).
\endproof
 
Calculating the $(p,1)$-summing norm of a \blofCKtaBs\ is made easier
by
Proposition~1A:2.10.
 
\proclaim Proposition 2.3. (See [Ma2 Cor. to Lem.4] or [J2 Prop.14.4].)
Let $\TCKY$\ be a \blotaBs. Then
$$ \pi_{p,1}(T) = \sup\left\{
   \left(\sumS\normo{T(x_s)}^p \right)^\invp \right\} ,$$
where the supremum is over all $\xS\in C(K)$\ with disjoint supports
and
$\normo {x_s}_\infty\le1$.
 
\vfill
\eject
 
\beginsection 3) A Finite Dimensional Version of Pisier's Result
 
The following result, which I believe to be original, shows that
if we are
dealing with \blo s from $l_\infty^N$\ rather than from $C(K)$, then
we need
only consider one particular probability measure on $K=[N]$, the
measure $\invN
\moddot$. This result also works for Pietsch's Theorem. Its weakness
is that it
does not extend to deal with all rank $N$\ operators from $C(K)$.
 
\proclaim Theorem 3.1. \rm\footnote*{\sevenrm I would like to acknowledge
a helpful suggestion made to me by G.J.O.~Jameson.}\sl
Let $\alpha$\ be an ideal quasi-norm, and
define the sequence of positive real numbers $(\alpha_N)_{N=1}^\infty$\
by
$$ \alpha_N = \alpha(l_\infty^N \hookrightarrow L_{p,1}^N).$$
Then for any \blo\ $\TliNY$\ we have
$$ \alpha(T) \le (2p)^\invp\,\alpha_{2N}\,\pi_{p,1}(T).$$
 
\Proof
Suppose that the \blo\ $\TliNY$\ satisfies $\pi_{p,1}(T)=C$. Then
by Theorem~2.1, $T$\ factors as
$$ T\colon l_\infty^N \hookrightarrow L_{p,1}([N],\mu) \tonamed U
X,$$
where $\normo U \le p^\invp C$\ and $\mu$\ is a probability measure
on $[N]$.
Define a new probability measure, $\nu$, on $[N]$; let
$\nu'(\{t\})=\mu(\{t\})$\ rounded up to the nearest multiple of ${1\over2N}$,
and let $\nu={1\over\nu'([N])} \nu'$. It is easy to see that $\nu
\ge
\smallhalf \mu$, and so the map $ L_{p,1}(\nu)\hookrightarrow L_{p,1}(\mu)$\
has norm bounded by $2^\invp$.
 
Now define the maps
$$ I\colon l_\infty^N \to l_\infty^{2N}
   \quad\hbox{and}\quad
   Q\colon L_{p,1}^{2N} \to L_{p,1}(\nu)$$
in the obvious fashion: let
$$ I(e_n)=\sum_{m\epsilon A_n} e_m ,$$
where
$$ A_n = \left\{\,m: \nu([1,n-1]) < \textstyle{m\over2N}
   \le \nu([1,n])\right\},$$
and let $Q$\ be the formal dual of $I$. It is easy to see that both
$I$\ and
$Q$\ are norm decreasing maps.
 
Then the following factorization of $T$\ gives the result.
$$T\colon l_\infty^N \tonamed I l_\infty^{2N} \hookrightarrow
  L_{p,1}^{2N} \tonamed Q L_{p,1}(\nu) \hookrightarrow
  L_{p,1}(\mu) \tonamed U X.$$
\endproof
 
\proclaim Corollary 3.1a. Let $\TliNY$\ be a \blo, and $p\ge 1$.
Then
$$\pi_p(T) \le c\cdot\left(1+\left(\ts\invp\log N\right)^{1-\invp}\right)
\cdot\pi_{p,1}(T).$$
 
\Proof Use Proposition~2.2 and Theorem~3.1.
\endproof
 
\bigskip
 
This extends a result given in [J1] to $p\ne2$. However, the result
in
[J1] also extends to all rank $N$\ operators from $C(K)$, which the
above
result does not.
 
\vfill
\eject
 
\beginsection Chapter 1C --- Random Walks and Cotype
 
This chapter comes in five sections. The first two sections give
a general
introduction to random walks in Banach spaces and cotype of operators.
Section~3 motivates the main problem of this thesis, that of the
cotype $2$\ of
operators from $C(K)$. It shows that the problem explores
the `edge' of established results. Section~4 looks at the comparison
between
Rademacher and Gaussian cotype, setting the second problem of this
thesis.
Finally, Section~5 presents solutions to these problems, deferring
their proofs
until Part~2.
 
\beginsection 1) Random Walks in Banach Spaces
 
\proclaim Definition. A {\dt (finite) random walk} in a Banach space
$X$\ is a
random variable, $U=\sumtheta$, where $S\in\N$, $\xS\in X$, and $\thetalist$\
is either $\gammalist$\ (in which case $U$\ is call a {\dt Gaussian
random walk})
or $\epsilonlist$\ (in which case $U$\ is called a {\dt Bernoulli
random
walk}).
 
Our definition of a random walk differs from that usually given,
in that we
define it as a random variable and not as a sequence of random variables.
 
\beginsection 1.1) Scalar Valued Random Walks
 
First of all, we consider random walks in $\C$. The Gaussian case
is easy,
because $\sumgamma$\ is itself a Gaussian random variable with mean
$0$\ and
standard deviation $\normxS_2 = \rmsxs$. Thus we get the following
simple results.
 
\proclaim Proposition 1.1. Let $\xS\in\C$\ and $1\le p<\infty$. Then
\cditem{i)}
$$ \Pr \left( \modsumgamma \ge t \normxS_2 \right) = {1\over\sqrt{2\pi}}
   \int_{-\infty}^t e^{-\half s^2} \,ds ;$$
\cditem{ii)}
$$ \left(\E\modsumgamma^p\right)^\invp \approx \sqrt p \normxS_2
.$$
 
For Bernoulli random walks, we have similar results.
 
\proclaim Proposition 1.2. \rm\footnote*{\sevenrm It may interest
the reader to
know that this result has applications to computer network design.}\sl
Let $\xS\in\C$\ and $1\le p<\infty$. Then
\cditem{i)}
$$ \Pr \left( \modsumepsilon \ge t \normxS_2 \right) \le c e^{-\invc
t^2} ;$$
\cditem{ii)}
$$ \invc \normxS_2 \le \left(\E\modsumepsilon^p\right)^\invp
   \le \sqrt p \normxS_2 .$$
 
\Proof See for example [Me Ch.II \S59].
\endproof
 
\proclaim Corollary 1.2a. (Khinchine's inequality.) Let $\xS\in\C$.
\item{i)} If\/ $1\le p\le2$\ then we have
$$ \left(\E\modsumepsilon^p\right)^\invp \ge \invc \normxS_p .$$
\item{ii)} If\/ $2\le p<\infty$\ then we have
$$ \left(\E\modsumepsilon^p\right)^\invp \le c \sqrt p \normxS_p
.$$
 
\beginsection 1.2) Banach Space Valued Random Walks
 
More generally, Gaussian and Bernoulli random walks have two properties.
Firstly,
the important quantities tend to be root mean squares. For example,
we have the
following.
 
\proclaim Proposition 1.3. Let $X$\ be a Banach lattice, and $\xS\in
X$.
\ditem{i)} $\E\normsumtheta \ge \invc\normo{\rmsxs} $.
\item{ii)} If $X$\ is $q$-concave for some $q<\infty$, then there
is a number
$C<\infty$\ such that
$$ \left(\E\normsumtheta^q\right)^\invq \le C \normo{\rmsxs}.$$
 
\Proof See [L--T2 Thm.1.e.13].
\endproof
 
This result (with Corollary~1.5b) completely describes the expectation
of random walks in $q$-concave
lattices. The second property is the concentration of measure phenomenon,
that
is, as a function of $t$, $\Pr\left(\normsumtheta \ge t \right)$\
has a very
fast decay rate. From this one deduces that
$\left(\E\normsumtheta^p\right)^\invp$\ has essentially the same
value for all
$1\le p<\infty$, and that this value is the same as its median. First,
for Bernoulli
random walks, we have the following results.
 
\proclaim Theorem 1.4. Let $X$\ be a Banach space, and $\xS\in X$.
Then
$$ \normo{\normsumepsilon}_{L_{\em(T^2)}(\Pr)} \le c \,\E \normsumepsilon
.$$
 
\Proof
See [Ka Ch.2 Thm.7].
\endproof
 
\proclaim Corollary 1.4a. Let $X$\ be a Banach space, $\xS\in X$,
and $t>0$. Then
$$ \Pr\left(\normsumtheta \ge t\E\normsumtheta\right) \le c e^{-\invc
t^2}.$$
 
\Proof Use Theorem~1A:2.7(ii).
\endproof
 
For Gaussian random walks we have similar results.
 
\proclaim Theorem 1.5. Let $X$\ be a Banach space, and $\xS\in X$.
Define
$$ \mu=\E\normsumgamma \quad\hbox{and}\quad
   \sigma = \sup\left\{\, \E\lmod\left\langle\xi,\sumgamma\right\rangle\rmod^2
            : \xi\in B_{X^*} \right\} .$$
Then for all $t>0$\ we have
\cditem{i)}
$$ \Pr\left( \lmod \normsumgamma - \mu \rmod \ge t\sigma \right)
   \le c e^{-\invc t^2} ;$$
\cditem{ii)}
$$ \Pr\left( \normsumgamma \ge \invc \mu + t\sigma \right)
   \ge \invc e^{-ct^2} .$$
 
Part~(i) of this result is better than its Bernoulli counterpart,
Corollary~1.4a, because we have that $\sigma\le c\mu$\ (see below).
It is a deep result due
to C.~Borel. Part~(ii) shows that we cannot improve (i).
 
\Proof For (i), see [Bo] or [P2 Thm.2.1]. For (ii), we first show
that $\sigma\le c\mu$. For if
$\xi\in B_{X^*}$, then by Proposition~1.1(ii), we have
$$ \eqalignno{
   \left(\E\modo{\bigangleo{\xi,\normsumgamma}}^2\right)^\half
   &\approx \left( \sumS \modo{\langle \xi,x_s \rangle}^2 \right)^\half
\cr
   &\approx \E\modo{\bigangleo{\xi,\normsumgamma}} \cr
   &\le  \E\normsumgamma .\cr}$$
 
Now we show that there is a universal constant $0<\alpha<1$\ such
that
$$ \Pr \left(\normsumgamma \ge \ts\half\mu \right) \ge \alpha ,$$
This is because if $\alpha' = \Pr \left(\normsumgamma \ge \half\mu
\right)$, then
$$ \eqalignno{
   \mu
   &= \E\normsumgamma \cr
   &= \int_{\left(\normsumgamma \ge \half\mu\right)} \normsumgamma
\,d\Pr
   + \int_{\left(\normsumgamma < \half\mu\right)} \normsumgamma \,d\Pr
\cr
\noalign{\hbox{which, as $\sigma\le c\mu$, and by part (i) is}} \cr
   &\le \int_0^{\alpha'} \bigl(\mu+c\mu\sqrt{\log^+c/t}\bigr) \,dt
+ \ts\half\mu. \cr}$$
But there is a universal constant $\alpha > 0$\ such that for $\alpha'<\alpha$,
we have
$$ \int_0^{\alpha'} \bigl(1+c\sqrt{\log^+c/t}\bigr) \,dt \le \ts{1\over6}
,$$
and we are done.
 
Finally we prove part (ii). If $t\sigma\le \quarter\mu$, then by
the above
$$ \Pr\left(\normsumgamma \ge \ts\quarter\mu+t\sigma\right)
   \ge \alpha \ge \invc e^{-c t^2} .$$
If $t\sigma>\quarter\mu$, then
$$  \Pr\left(\normsumgamma \ge \ts\quarter\mu+t\sigma\right)
    \ge  \Pr\left(\bigangleo{\xi,\sumgamma} \ge \ts\half t\sigma\right)
,$$
where $\xi\in B_{X^*}$\ is such that $\E\modo{\bigangleo{\xi,\sumgamma}}^2
=
\sigma^2$, and this dominates $\invc e^{-ct^2}$\ by Proposition~1.1(i).
\endproof
 
\proclaim Corollary 1.5a. Let $X$\ be a Banach space, and $\xS\in
X$. Then
$$ \normo{\normsumgamma}_{L_{\em(T^2)}(\Pr)} \le c \E \normsumgamma
.$$
 
\Proof Use Theorem~1A:2.7(ii).
\endproof
 
Thus we derive the following results for both Bernoulli and Gaussian
random
walks.
 
\proclaim Corollary 1.5b. Let $X$\ be a Banach space, $\xS\in X$,
and
$1\le p<\infty$. Then
$$ \E\normsumtheta \le \left(\E\normsumtheta^p\right)^\invp
   \le c \, \sqrt p \, \E\normsumtheta .$$
 
\Proof This follows by Theorem~1.4 or Corollary~1.5a, and
Proposition~1A:2.3(i), as for
all $t\le1$\ we have $\sqrt{\lm t} \le c\sqrt p t^\invp$.
\endproof
 
\proclaim Definition. Let $U$\ be a real valued random variable,
and
$0<\alpha<1$. Define the {\dt upper $\alpha$-tile}\ of $U$, $M_\alpha(U)$,
to
be a number $M$\ such that $\Pr(U\le M)\ge1-\alpha$\ and $\Pr(U\ge
M)\ge \alpha$. Define the {\dt median} to be $M_\half(U)$.
 
\proclaim Corollary 1.5c. Given $0<\alpha<1$, there is a number $C<\infty$\
such
that for all Banach spaces $X$, and $\xS\in X$, we have
$$ \alpha M_\alpha\left(\normsumtheta\right)
   \le \E\normsumtheta
   \le C M_\alpha\left(\normsumtheta\right).$$
 
\Proof This follows straight away from Corollary~1.4a or Theorem~1.5.
\endproof
 
\beginsection 1.3) Random Walks in $l_\infty^N$
 
The space $l_\infty^N$\ is not $q$-concave, and hence we cannot apply
Proposition~1.3(ii). However, we do have the following simple results.
 
\proclaim Proposition 1.6. Let $\xS\in l_\infty^N$. Then
\cditem{i)}
$$ \E\normsumtheta_\infty \le c \sqrt{\lm N} \normo{\rmsxs}_\infty
;$$
\cditem{ii)}
$$ \E\normsumepsilon_\infty \le \normo{\sumS\modo{x_s}}_\infty .$$
 
\Proof Part (i) follows from Proposition~1.1(i) or Proposition~1.2(i)
(See also [Ka Ch.6 Thm.1]). Part (ii) is trivial.
\endproof
 
These results are the best possible. For example, in part (i), if
$N=2^S$, let
$$ x_s = \left(\sign\cos\left(2^s\pi\ts{n-1\over N-1}\right)\right)_{n=1}^N
   \quad\hbox{for $1\le s\le S$.}$$
Then $\normsumepsilon_\infty=S$, whereas $\rmsxs = \sqrt S$.
 
\vfill
\eject
 
\beginsection 2) Type and Cotype of Operators and Banach Spaces
 
If $X$\ is isomorphic to Hilbert space, then we have the
well known parallelogram law: for some number $C<\infty$\ and
for all $\xS\in X$\ we have
$$ C^{-1} \left(\sumS\normxs_X^2\right)^\half
   \le \E\normsumepsilon_X
   \le C \left(\sumS\normxs_X^2\right)^\half . $$
The type and cotype measure to what extent a space or operator deviates
from
this law. For example, the $L_p$\ spaces obey laws weaker than the
parallelogram
law, as can easily be deduced from Khinchine's inequality: for all
$\xS\in
L_p$\ we have
$$ \invc \left(\sumS\normxs_p^2\right)^\half
     \le \E\normsumepsilon_p
       \le c \left(\sumS\normxs_p^p\right)^\invp,
         \quad 1\le p\le2, $$
$$ \invc \invsqrtp \left(\sumS\normxs_p^p\right)^\invp
     \le \E\normsumepsilon_p
       \le c \sqrt p \left(\sumS\normxs_p^2\right)^\half,
         \quad 2\le p<\infty. $$
Thus $L_p$\ has type $p$\ and cotype $2$\ for $1\le p\le 2$, and
type $2$\ and
cotype $p$\ for $2\le p<\infty$. Looking at the unit vectors in $L_p$\
shows
that these results are the best we can do. Indeed we have the following
famous
result due to Maurey and Pisier.
 
\proclaim Theorem 2.1. (See [Ma--P] or [Mi--Sr].) Let $X$\ be a Banach
space. Let
$$ p_X=\sup\{\,p:R_p(X)<\infty\} \quad\hbox{,}\quad
   q_X=\inf\{\,q:R^q(X)<\infty\},$$
and
$$ S=\{\,p\in[1,\infty]:\hbox{$X$\ contains uniformly isomorphic
copies of
   $l_p^N$}\}.$$
Then
$$ [p_X,2]\cup\{q_X\} \subseteq S \subseteq [p_X,q_X]. $$
 
As the names suggest, type and cotype are in some sense dual to one
another. If
$\TXY$\ is a \blo, and $\invp+\invpp=1$\ where $1<p\le2$, then $R^\pp(T^*)\le
R_p(T)$\ and $G^\pp(T^*)\le G_p(T)$. However, this duality lies only
in one
direction: one cannot deduce that if $T$\ has cotype $\pp$, then
$T^*$\ has
type $p$. Consider, for example $C(K)$. It has no type or cotype,
indeed
$$ \eqalignno{
   R^p(l_\infty^N) &\ge N^\invp \quad (p\ge2) ,\cr
   R_p(l_\infty^N) &\approx (\lm N)^{1-\invp} \quad (p\le2) .\cr
}$$
However, its dual, whose finite dimensional structure is like $l_1$,
has cotype
$2$.
 
\beginsection 2.1) Kwapien's Result
 
The parallelogram law given above (which states that $X$\ has type
$2$\ and
cotype $2$) characterizes Hilbert space. This famous result is due
to Kwapien,
and we state it in more generality below.
 
\proclaim Theorem 2.2. Let $S\colon X\to Y$\ and $T\colon Y\to Z$\
be \blobBs.
If $S$\ has Rademacher type $2$, and $T$\ has Rademacher cotype $2$,
then
$T\circ S$\ factors through a Hilbert space, with $\gamma(T\circ
S)\le R_2(S)
R^2(T)$.
 
We can now deduce results about operators from $L_p$\ for $2\le p<\infty$.
 
\proclaim Corollary 2.2a. Let $2\le p<\infty$, and $T\colon L_p\to
Y$\ be a
\blotaBs. If $T$\ has cotype $2$, then it factors through a Hilbert
space.
 
This suggests similar results for \blo s from $C(K)$.
 
\beginsection 2.2) Grothendieck's Theorem
 
The space $C(K)$\ does not have type $2$, but it almost does ---
its dual has
cotype $2$, and indeed the type $2$\ constant of $l_\infty^N$\ is
not very big
($\sqrt{\lm N}$). Correspondingly, there is a slightly weaker result
then
Corollary~2.2a.
 
\proclaim Theorem 2.3. (See [P1 Thm.4.1].) Let $X$\ and $Y$\ be Banach
spaces such that $X^*$\ and
$Y$\ have cotype $2$. Then if $\TXY$\ is a \blo\ with the approximation
property (see, for example, [P1 Ch.0] or [Pt 1.3] for the definition
of the approximation
property; all \blo s from $C(K)$\ have this property), then $T$\
factors
through a Hilbert space.
 
\proclaim Corollary 2.3a. Let $\TCKY$\ be a \blotaBs. If\/ $T$\ factors
through
a space with cotype $2$,
then $T$\ factors through a Hilbert space (or, equivalently, is $2$-summing).
 
Indeed one can show that $\gamma(T) \le c R^2(Y) \sqrt{\lm R^2(Y)}$,
as we will
show in Theorem~1D:3.1
 
\beginsection 2.3) Cotype $p$\ of Operators from $C(K)$\ for $p>2$
 
In this section, we present work due to Maurey, which establishes
equivalent conditions for an operator from $C(K)$\ to have cotype
$p$\ for
$p>2$. First, it is easy to relate the cotype $p$\
of such an operator to its $(p,1)$-summing and $(p,2)$-summing norms
as
follows.
 
\proclaim Proposition 2.4. Let $\TCKY$\ be a \blotaBs. Then for $p\ge2$\
we have
that $\pi_{p,1}(T) \le R^p(T) \le c\, \pi_{p,2}(T)$.
 
\Proof This follows from Proposition~1.3(i) and
Proposition~1.6(ii).
\endproof
 
From this, we derive the following result.
 
\proclaim Theorem 2.5. (See [Ma2 Thm.2]) Let $\TCKY$\ be a \blotaBs,
and $p>2$. Then the
following are equivalent.
\item{i)} $T$\ is $(p,1)$-summing.
\item{ii)} $T$\ is $(p,2)$-summing.
\item{iii)} $T$\ has Rademacher cotype $p$.
\item {iv)} $T$\ factors through a space of Rademacher cotype $p$.
 
\Proof It follows immediately from Proposition~2.4 and Corollary~1B:2.1a
that
(i)$\Rightarrow$(ii)$\Rightarrow$(iii)$\Rightarrow$(i). Clearly
(iv)$\Rightarrow$(iii), and (i)$\Rightarrow$(iv) follows from the
fact that
$L_{p,1}$\ has cotype $p$\ for $p>2$\ (see [Cr])
\endproof
 
\beginsection 3) The Problem of Cotype $2$
 
Now, we are ready to present the main problem of this thesis.
The following question was asked by Jameson [J1].
 
\proclaim Question 3.1. Let $\TCKY$\ be a \blotaBs. Do either of
the following
hold?
\item{i)} If $T$\ is $(2,1)$-summing, then $T$\ has cotype $2$.
\item{ii)} If $T$\ has cotype $2$, then it is $2$-summing.
 
We see from Proposition~2.4 that if $T$\ is $2$-summing, then it
has cotype $2$,
and that if $T$\ has cotype $2$, then it is $(2,1)$-summing. This
question can
be seen as exploring what happens in Theorem~2.5 in the case $p=2$,
when, by
Proposition~1B:2.2, (i) and (ii) are no longer equivalent conditions.
Part~(ii) would also be an obvious common
extension of Corollary~2.2a and Corollary~2.3a.
 
Since having cotype $2$, or being $2$-summing or $(2,1)$-summing
depends only
on the finite dimensional sub-structure, the above question is equivalent
to
the following.
 
\proclaim Question 3.2. Let $\TliNY$\ be a \blotaBs. Do either of
the following
hold?
\item{i)} $R^2(T) \le c \,\pi_{2,1}(T) $.
\item{ii)} $\pi_2(T) \le c \,R^2(T) $.
 
By Proposition~1B:2.2, we can immediately see that (i) and (ii) cannot
both be
true, indeed to have a negative answer to (ii), we only need that
$R^2(T) \le
o(\sqrt{\lm N}) \,\pi_{2,1}(T) $.
 
We can also relate this question to random walks in $l_\infty$. By
Theorem~1B:2.1 and Theorem~1B:3.1, showing (i) is equivalent to finding
a positive answer to the following question.
 
\proclaim Question 3.3. Is $R^2(l_\infty^N \hookrightarrow L_{2,1}^N)
\approx 1$,
that is, is it true that
$$ \E \Bernwalk \ge \invc \rmsxsLtwoone $$
for all $\xS\in\C^N$?
 
This question can be thought of as trying to find a partial converse
to
Proposition~1.6(i) (as $\normdot_{L_{2,1}^N} \le c \sqrt{\lm N}
\normdot_{L_2^N}$).
 
We will provide a partial answer to these problems, which we will
present in
Section~5.1. Part~(i) of Questions~3.1 and~3.2, and Question~3.3
almost hold; we
have $R^2(l_\infty^N\hookrightarrow L_{2,1}^N) \le \lm\lm N$. Thus
we have
negative answers to part~(ii) of Questions~3.1 and~3.2.
 
\bigskip
Finally, as an aside, we show that we cannot ask for any more than
a positive
answer to Question~3.3 would provide.
 
\proclaim Proposition 3.4. Let $\normdot_*$\ be a symmetric norm
on $\C^N$\ such that
for all $\xS\in\C^N$\ we have
$$ \E \normsumepsilon_\infty
   \ge \left(\sumS \normo{x_s}_*^2\right)^\half. $$
Then $\normdot_* \le c \normdot_{L_{2,1}^N} $.
 
\Proof If $k\in[N]$, let $S=\intNok$, and $\xS$\ be the disjoint
vectors
$x_s=\chi_{[(s-1)k+1,sk]} $. Then it is easy to see that
$$ \E\normsumepsilon_\infty = 1 ,$$
and hence $\normo{\chi_{[1,k]}}_* \le c \sqrt{k\over n} $. The result
follows
by Lemma~1D:4.2.
\endproof
 
We also have a similar result for Gaussian random walks.
 
\proclaim Proposition 3.5. Let $\normdot_*$\ be a symmetric norm
on $\C^N$\ such that
for all $\xS\in\C^N$\ we have
$$ \E \normsumgamma_\infty
   \ge \left(\sumS \normo{x_s}_*^2\right)^\half. $$
Then $\normdot_* \le c \normdot_{L_{T^2\lm T,1}^N} $.
 
\Proof If $k\in[N]$, let $S=\intNok$, and $\xS$\ be the disjoint
vectors
$x_s=\chi_{[(s-1)k+1,sk]} $. Then by Proposition~1.6(i), we have
$$ \E\normsumgamma_\infty \le \sqrt{\lm (N/k)} ,$$
and hence $\normo{\chi_{[1,k]}}_* \le c \sqrt{(\lm(N/k){k\over n}}
$. The
result follows by Lemma~1D:4.2.
\endproof
 
We also have a similar result for random walks in $L_p$.
 
\proclaim Proposition 3.6. Let $\normdot_*$\ be a $1$-unconditional
norm on
$\C^N$, and $2\le p<\infty$. Suppose that for all $\xS\in\C^N$, we
have
$$ \E\normsumepsilon_{L_p^N} \ge \left(\sumS \normo{x_s}_*^2\right)^\half
.$$
Then there is a probability measure $\mu$\ on $[N]$, and a number
$C<\infty$,
such that $\normdot_* \le C \normdot_{L_2(\mu)}$. If\/ $\normdot_*$\
is a
$1$-symmetric norm, then $\normdot_*\le\normdot_{L_2^N}$.
 
\Proof
The hypothesis of the proposition says that the map $L_p^N \hookrightarrow
(\C^N,\normdot_*)$\ has cotype $2$\ constant bounded by $1$. Hence,
we can apply Corollary~2.2a and deduce that this map factors as
$V\circ U$ through a Hilbert space $H$, where for some number $C<\infty$\
we have
$$ \normo{V\colon H\to(\C^N,\normdot_*)} \le C ,$$
$$ \normo{U\colon L_p^N\to H} \le 1 .$$
Define a Euclidean norm $\normdot_a$\ on $\C^N$\ by
$$ \normo x_a = \normo{U(x)}_H ,$$
so that $\normdot_*\le\normdot_a\le C\normdot_{L_p^N}$. Now define
the Euclidean
norm $\normdot_b$\ on $\C^N$\ by
$$ \normo x_b
   = \left(\E\normo{\sumN \varepsilon_n x(n) e_n}_a^2 \right)^\half
   = \left(\sumN \modo{x(n)}^2\normo{e_n}_a^2 \right)^\half ,$$
where $e_1$, $e_2,\ldots,$\ $e_N$\ are the unit vectors of $\C^N$.
Since
$\normdot_*$\ and $\normdot_{L_p^N}$\ are $1$-unconditional, we have
$\normdot_*\le\normdot_b\le C\normdot_{L_p^N}$. So
$$ \left(\sumN\normo{e_n}_a^2\right)^\half = \normo{\sumN e_n}_b
\le C .$$
If we let
$\mu$\ be the probability measure on $[N]$\ defined by
$$ \mu\{n\} = {\normo{e_n}_a^2 \over \sumN \normo{e_n}_a^2} ,$$
then we see that $\normdot_*
\le \normdot_b \le C\normdot_{L_2(\mu)}$.
 
If we also have that $\normdot_*$\ is $1$-symmetric, then
$$ \normo x_*
   \le C \left({1\over N!} \sum_{\sigma\in S_N} \normo{\sumN e_n
   x(\sigma(n))}_{L_2(\mu)}^2 \right)^\half
   = C \normo x_{L_2^N} .$$
\endproof
 
\vfill
\eject
 
\beginsection 4) Comparison of Gaussian and Rademacher Cotype
 
Here we introduce the second main problem of this thesis.
Most interest in cotype lies only with Rademacher cotype. However
for the
operators that we are considering, it is much easier to calculate
Gaussian
cotype. If we could deduce results about Rademacher cotype from results
about
Gaussian cotype, we would save ourselves much work.
 
\beginsection 4.1) Comparison of Gaussian and Bernoulli Random Walks
 
The first result states that Bernoulli random walks do not travel
as far
as Gaussian random walks.
 
\proclaim Proposition 4.1. Let $X$\ be a Banach space, and let $\normdot_A$\
be
a rearrangement invariant norm on the space of all scalar valued
random
variables. If $\xS\in X$, and $t>0$, then
\cditem{i)}
$$ \normo{\normsumepsilon_X}_A \le c \normo{\normsumgamma_X}_A ;$$
\cditem{ii)}
$$ \Pr \left( \normsumepsilon_X \ge t \right)
   \le c \Pr \left( \normsumgamma_X \ge \invc t \right) .$$
 
Part~(i) is usually stated in less generality as follows: for all
$1\le
p<\infty$\ we have
$$ \left(\E\normsumepsilon_X^p\right)^\invp
   \le c \left(\E\normsumgamma_X^p\right)^\invp .$$
However, we require the greater generality in order to prove (ii).
The proof of
(ii) also depends heavily on Theorem~1.5, and so it seems to be a
deep result.
I suspect that there is a better proof, but I cannot find it.
 
\proof of i): This is a slight modification of a well known method
(see, for
example [Mi--Sn \S9.4]). Let us write the underlying probability
space as
$\Omega_\gamma\times\Omega_\varepsilon$, where $\gammalist$\ depend
only on
$\Omega_\gamma$, and $\epsilonlist$\ depend only on $\Omega_\varepsilon$.
Let
$\Pr_\gamma$\ be the projection of $\Pr$\ onto $\Omega_\gamma$, and
$\Pr_\varepsilon$\ be the projection of $\Pr$\ onto $\Omega_\varepsilon$,
so
that $\Pr=\Pr_\gamma\times\Pr_\varepsilon$.
 
First we establish that the operator
$$ L_A(\Omega_\gamma\times\Omega_\varepsilon) \to L_A(\Omega_\varepsilon)
   ;\quad
   V \mapsto \int_{\Omega_\gamma} V \,d\Pr_\gamma $$
is a contraction, where $L_A(\Omega)$\ denotes the space of measurable
functions
$f\colon\Omega\to\C$\ such that $\normo f_A <\infty$, with norm $\normdot_A$.
But, this is clearly so if $\normdot_A =
\normdot_1$\ or $\normdot_\infty$, and the general case
then follows by the interpolation result given in [L--T2 2.a.10].
 
Now notice that $\normsumgamma_X$\ has the same law as
$\normo{\sumS\varepsilon_s\modo{\gamma_s}x_s}_X$. Also notice, that
as
$\normdot_X$\ is a norm, we have,
$$ \eqalignno{
   \int_{\Omega_\gamma} \normo{\sumS\varepsilon_s\modo{\gamma_s}x_s}_X
   \,d\Pr_\gamma
   &\ge \normo{\sumS\varepsilon_s
   \int_{\Omega_\gamma} \modo{\gamma_s} \,d\Pr_\gamma x_s}_X \cr
   &= \sqrt{2/\pi} \normsumepsilon_X . \cr}$$
Hence
$$ \eqalignno{
   \normo{\normsumgamma_X}_A
   &\ge \normo{\int_{\Omega_\gamma}
   \normo{\sumS\varepsilon_s\modo{\gamma_s}x_s}_X
   \,d\Pr_\gamma }_A \cr
   &\ge \sqrt{2/\pi} \normo{\normsumepsilon_X}_A .\cr}$$
\endproof
 
\proof of ii):
First we establish some notation. If $U$\ is a scalar valued random
variable,
let $U^*$\ be its decreasing rearrangement, and $U^{**}(t)=\int_0^t
U^*(u)\,du$. Note that the map $U\mapsto U^{**}(t)$\ is a rearrangement
invariant
norm on the space of random variables, for each $t\in(0,\infty]$.
 
Now let $U=\normsumepsilon$\ and $V=\normsumgamma$. It is sufficient
to show
that
$$ U^*(t) \le c V^*(\invc t) \quad\hbox{for $t\in[0,\infty]$} .$$
However, by Theorem~1.5, we have that $\invc\bigl(\mu+\sigma\sqrt{\log^+\invc
/t}\bigr)
\le V^*(t) \le c\bigl(\mu+\sigma\sqrt{\log^+c/t}\bigr)$, and hence
$V^{**}(t) \le c
V^*(\invc t)$. Furthermore, it is obvious that $U^*(t) \le U^{**}(t)$.
Finally,
by (i), $U^{**}(t) \le c V^{**}(t)$, and the result follows.
\endproof
 
The converse inequalities are weaker.
 
\proclaim Proposition 4.2. Let $X$\ be a Banach space, and $\xS\in
X$.
\cditem{i)}
$$ \E\normsumgamma \le c \sqrt{\lm S}\, \E\normsumepsilon .$$
\item{ii)} If $X$\ has cotype $q$\ for some $q<\infty$,
then for some number $C<\infty$, depending on $X$\ only, we have
$$ \E\normsumgamma \le C\, \E\normsumepsilon .$$
\item{iii)} If $X=l_\infty^N$, then
$$ \E\normsumgamma \le c \sqrt{\lm N}\, \E\normsumepsilon .$$
 
\Proof For (i) and (ii), see [Mi--Sn Append.II]. Part (iii)
follows straight away from Proposition~1.3(i) and Proposition~1.6(i).
\par \endproof
 
\beginsection 4.2) Comparison of Rademacher and Gaussian Cotype
 
For comparison of Rademacher and Gaussian cotypes we have the following
results.
 
\proclaim Proposition 4.3. Let $\TXY$\ be a \blobBs, and $1\le
p\le2\le q<\infty$.
\item{i)} $R_p(T) \le c \,G_p(T)$.
\item{ii)} $G^q(T) \le c \,R^q(T)$.
\item{iii)} $G_p(T) \le c \,R_p(T)$.
\item{iv)} If $X$\ has cotype $q_1$\ for some $q_1<\infty$, then
there is a
number $C<\infty$, depending on $X$\ only, such that $R^q(T) \le
C\, G^q(T)$.
\item{v)} If $X=l_\infty^N$, then $R^q(T) \le c \sqrt{\lm N} \,G^q(T)$.
 
\Proof Parts (i) and (ii) follow straight away from Proposition~4.1(i).
For (iii), see
[Mi--Sn \S9.4]. Parts (iv) and (v) follow straight away from Proposition~4.2.
\par\endproof
 
It would be of great value if one could give a
better converse to part~(ii) than is provided by parts~(iv)
or~(v), even if we had to put some strong condition on the image
of the
operator $T$. Thus we formulate the following question.
 
\proclaim Question. Let $2\le q<\infty$, and $\TCKY$\ be a \blotaBs\
$Y$, where
$Y$\ satisfies some suitable smoothness condition. Is there a number
$C<\infty$, depending on $Y$\ only, such that $R^q(T) \le C\, G^q(T)$?
 
In Section~5.2, we give a negative answer to this question, in fact
we cannot
improve on Proposition~4.3(v) at all.
 
\vfill
\eject
 
\beginsection 5) The Solutions
 
Here we present the main results of this thesis. The whole of
Part~2 is devoted to the proof of these and similar results.
 
\beginsection 5.1) The Problem of Cotype $2$
 
We give partial answers to the questions of Section~3, and also present
similar
results about Gaussian cotype $2$.
 
\proclaim Theorem 5.1. Let $\xS\in l_\infty^N$. Then
\cditem{i)}
$$ \E\Bernwalk \ge \invc \invloglogN \rmsxsLtwoone ;$$
\cditem{ii)}
$$ \E\Gausswalk \ge \invc \invsqrtloglogN \rmsxsLtwoone .$$
 
\proclaim Theorem 5.2. Let $\TliNY$\ be a \blotaBs. Then
\item{i)} $R^2(T) \le c \lm\lm N\, \pi_{2,1}(T)$,
\item{ii)} $G^2(T) \le c \sqrtloglogN\, \pi_{2,1}(T)$.
 
\Proof From Theorem~5.1, we have
$$ R^2(l_\infty^N \hookrightarrow L_{2,1}^N) \le c \lm\lm N ,$$
$$ G^2(l_\infty^N \hookrightarrow L_{2,1}^N) \le c \sqrt{\lm\lm N}
.$$
The result now follows from Theorem~1B:3.1.
\endproof
 
\proclaim Corollary 5.2a. There is a \blo\ $\TCKY$\ to a Banach space
that has
Rademacher cotype $2$, but does not factor through Hilbert space.
 
\beginsection 5.2) Comparison of Rademacher and Gaussian Cotype
 
We can give a complete answer to the question of Section~4.
 
\proclaim Theorem 5.3. Given $2\le p<q<\infty$, for suitably large
$N$,
there is a \blo\ $T\colon l_\infty^N\to L_q$\ such that
$$ R^p(T) \ge \invsqrtp \sqrt{\lm N}\, G^p(T) .$$
 
We can also show that the left hand inequality in Proposition~2.4
does not
extend to the Gaussian case.
 
\proclaim Theorem 5.4. Given $2<q<\infty$, for suitably large $N$,
there is a
\blo\ $T\colon l_\infty^N\to L_q$\ such that
$$ \pi_{2,1}(T) \ge \invc \sqrt{\lm N}\, G^2(T) .$$
 
\vfill
\eject
 
\beginsection Chapter 1D --- Miscellaneous Results
 
In this chapter I shall present some extra results, which although
they do not
fit into the main argument, are nevertheless of some interest.
 
\beginsection 1) The $p^\invp$\ in Pisier's Result
 
Let $C_p$\ be the function of $p\in[1,\infty)$\ defined to be the
smallest
number such that for all \blo s $\TCKY$\ that are $(p,1)$-summing,
there is a
Radon probability measure $\mu$\ on $K$\ such that
$$ \normo{T(x)} \le C_p \pi_{p,1}(T) \normo x_{L_p(\mu)}^\invp
   \normo x_\infty^{1-\invp} \quad\hbox{for all $x\in C(K)$.}$$
Pisier's Theorem, which we presented as Theorem~1B:2.1, tells us
that $C_p\le
p^\invp$. It is natural to ask whether $C_p$\ is any smaller, in
particular, if
it is $1$. We show that this is not so.
 
\proclaim Proposition 1.1. Let $C_p$\ be defined as above. Then
\ditem{i)} $C_p\ge \left({32^{p-1}\over2^p+1}\right)^\invp$;
\ditem{ii)} $C_p\ge (\invc(p-1))^\invp$.
\moreproclaim\noindent
Hence, if $p>1$, then $C_p>1$, and for all $1\le p<\infty$\ we have
$C_p^p\approx p$.
 
\proof of i): Let $T$\ be the formal identity map
$l_\infty^3\to(\C^N,\normdot_*)$, where $\normo x_*=x^*(1)+x^*(2)$.
Then by
Proposition~1B:2.3 we have
$$ \pi_{p,1}(T) = \sup\left\{\,\left(\sumS \normo{\chi_{A_s}}_*^p\right)^\invp
                  :\matrix{\hbox{$\AS$\ are}\hfill \cr
                           \hbox{disjoint subsets of $\{1,2,3\}$}\hfill
\cr}
                  \right\}.$$
By trying out all the possibilities, we see that $\pi_{p,1}(T)=(2^p+1)^\invp$.
Now suppose that $\mu$\ is a probability measure on $\{1,2,3\}$\
such that
$$ \normo x_* \le C\pi_{p,1}(T) \normo x_{L_p(\mu)}^\invp \normo
   x_\infty^{1-\invp} .$$
By considering the vectors $x=(1,1,0)$, $(1,0,1)$\ and $(0,1,1)$,
we see that
$$ 2^p \le C^p (2^p+1) (\mu(i)+\mu(j)) \quad\hbox{for $i\ne j\in\{1,2,3\}$.}$$
By adding these three equations we deduce that
$$ C^p \ge {32^{p-1}\over2^p+1} .$$
\endproof
 
\proof of ii): Let $N=K(K+1)$\ where $K\in\N$\ is sufficiently large.
Let
$\A$\ be the set system consisting of the sets
$$  \{\, n\in[N] : n\equiv m\pmod K\hbox{ or } n\equiv m'\pmod{K+1}
\} ,$$
where $m\in[K]$\ and $m'\in[K+1]$.
Let $\normdot_*$\ be the norm on $\C^N$\ given by
$$ \normo x_* = \sup_{A\in\A} \left\{\sum_{n\in A} \modo{x(n)} \right\}
,$$
and $T$\ be the formal identity $l_\infty^N\to(\C^N,\normdot_*)$.
First we
show that for sufficiently large $K$\ we have
$$ \pi_{p,1}(T) \le \left(c\ts{1\over p-1}\right)^\invp 2K ,\eqno
(1.1)$$
and to show this, we need the following lemma.
 
\proclaim Lemma 1.2. Let $\AS\in\A$. Then for $S\le K$\ we have
$$ \modo{\cupS A_s} \le S(2K+1-S).$$
 
\Proof We may write $A_s=E_s\cup F_s$, where
$$ \eqalignno{
   E_s &= \{ n\in[N] : n \equiv m_s  \pmod K    \}, \cr
   F_s &= \{ n\in[N] : n \equiv m'_s \pmod{K+1} \}. \cr }$$
For any $s_1,s_2\in[S]$, $E_{s_1}$\ and $E_{s_2}$\ are either disjoint
or
equal. List the distinct $E_s$s as $E'_1$, $E'_2,\ldots,$\ $E'_{S_1}$\
with
$S_1\le S$. Similarly, list the distinct $F_s$s as $F'_1$, $F'_2,\ldots,$\
$F'_{S_2}$\ with $S_2\le S$. Observe that for $s_1\in[S_1]$,
$s_2\in[S_2]$\ we have $\modo{E'_{s_1}\cap F'_{s_2}}=1$. Hence
$$ \eqalignno{
   \modo{\cupS A_s} &=
     \sum_{s_1=1}^{S_1} \modo{E'_{s_1}} +
     \sum_{s_2=1}^{S_2} \modo{F'_{s_2}} -
     \sum_{s_1=1}^{S_1} \sum_{s_2=1}^{S_2} \modo{E'_{s_1}\cap F'_{s_2}}
\cr
   &= S_1 (K+1) + S_2 K - S_1 S_2 \cr
   &\le S(2K+1-S) .\cr}$$
\endproof
 
Now we proceed with finding $\pi_{p,1}(T)$. By Proposition~1B:2.3
this is given by
$$ \pi_{p,1}(T) = \sup \left\{\,
                  \left(\sumS \normo{\chi_{B_s}}_*^p \right)^\invp
                  :\matrix{\hbox{$\BS$ are}\hfill \cr
                           \hbox{disjoint subsets of $[N]$}\hfill
\cr}
                  \right\} .$$
Since $\normo{\chi_{B_s}}_* = \sup_{A\in\A} \modo{A\cap B_s}$, we
see that
$$ \pi_{p,1}(T) = \sup \left\{\,
                  \left(\sumS \modo{B_s}^p \right)^\invp
                  :\matrix{\hbox{$\BS$ are disjoint subsets of $[N]$}\hfill
\cr
                           \hbox{with $B_s\subseteq A_s$ for some
$A_s\in\A$}
                           \hfill \cr}
                  \right\} .$$
Pick $\BS$\ and $\AS$\ so that the supremum is attained, and such
that the
$B_s$s are ordered so that $\modo{B_1}\ge\modo{B_2}\ge\ldots\ge\modo{B_S}$.
Then we have
$$ \eqalignno{
   \modo{B_t} &\le 2K+1-t \quad\hbox{for $t\le K$,} \cr
   \modo{B_t} &\le {N\over t} \quad\hbox{for $K<t\le S$,} \cr }$$
for if $t\le K$\ and $\modo{B_t} > 2K+1-t$, then
$\modo{B_1}$, $\modo{B_2},\ldots$, $\modo{B_t} > 2K+1-t$. Hence
$$ t(2K+1-t) < \modo{\bigcup_{s=1}^t B_s}
   \le \modo{\bigcup_{s=1}^t A_s} \le t(2K+1-t), $$
which is a contradiction. The argument is similar for $t>K$. Therefore
$$ \eqalignno{
   \sumS \modo{B_s}^p
   &\le \sum_{s=1}^K (2K+1-s)^p + \sum_{s=K+1}^\infty {N^p\over s^p}
\cr
   &\le c \ts{1\over p-1} (2K)^{p+1} ,\cr}$$
for sufficiently large $K$, and we have shown $(1.1)$.
 
Now suppose that $\mu$\ is a probability measure on $[N]$\ such that
for all
$x\in l_\infty^N$, we have
$\normo x_* \le C \pi_{p,1}(T) \normo x_{L_1(\mu)}^\invp
\normo x_\infty^{1-\invp}$. Then by considering $x=\chi_A$\ where
$A\in\A$, we
see that
$$ (2K)^p = \modo A^p \le C^p \bigl(\pi_{p,1}(T)\bigr)^p \sum_{m\in
A} \mu(m) .$$
Now notice that we may list the elements of $\A$\ as $\{\,A+n:n\in[N]\}$,
where
$A\in\A$\ and $A+n=\{\,(m+n)\bmod N : m\in A\}$. Also notice that
each
$n\in[N]$\ appears as an element in exactly $\modo A=2K$\ sets in
$\A$. So
$$ \eqalignno{
   N(2K)^p
   &\le C^p \bigl(\pi_{p,1}(T)\bigr)^p \sumN \sum_{m\in A+n} \mu(m)
\cr
   &=   C^p \bigl(\pi_{p,1}(T)\bigr)^p \modo A .\cr}$$
Therefore
$$ C^p \ge {N(2K)^{p-1}\over\bigl(\pi_{p,1}(T)\bigr)^p} \ge \invc
(p-1) .$$
\endproof
 
\vfill
\eject
 
\beginsection 2) The Space $L_{2,1}$\ is not $(2,1)$-Summing
 
The usual way to see that a space
is $(p,1)$-summing is to deduce this from the following result.
 
\proclaim Proposition 2.1. Let $\TXY$\ be a \blobBs, and $2\le p<\infty$.
If\/ $T$\ has Rademacher cotype $p$, then it is $(p,1)$-summing,
with
$$ \pi_{p,1}(T) \le R^p(T) .$$
 
\Proof This follows from Proposition~1A:3.1(i).
\endproof
 
Hence $L_{p,1}$\ is $(p,1)$-summing for $p>2$, and $L_q$\ is $(2,1)$-summing
for $1\le q\le2$.
Now the map $\CKtLtoKm$\ is $(2,1)$-summing, and so it is natural
to ask
whether the
space $L_{2,1}$\ itself is $(2,1)$-summing. However $L_{2,1}$\ does
not have
cotype $2$, and so the above
argument will not work. We show that $L_{2,1}$\ is not $(2,1)$-summing,
and
note that this adds support to the conjecture that all spaces that
are $(2,1)$-summing have cotype $2$\ (see
for example [P1 Ch.6] or [Ma2 Rem.2]).
 
\proclaim Proposition 2.2. For any $N\ge2$, we have
$$ \pi_{2,1} (l_{2,1}^{N2^N} ) \ge \invc \sqrt{\lm N} .$$
 
\proclaim Lemma 2.3. The space $L_{2,1}$\ is $q$-concave for $q>2$.
 
\Proof See [Cr].
\endproof
 
\proof of Proposition 2.2: Identify $[N2^N]$ with the space
$[N]\times\{1,-1\}^N$. Define the functions
$a_1$, $a_2,\ldots$, $a_N$, $\zeta_1$, $\zeta_2,\ldots$, $\zeta_N$\
by
$$\eqalignno{
a_n    (m,s_1,s_2,\ldots,s_N)
  &= {1\over\sqrt{(m+n)\bmod N}} , \cr
\zeta_n(m,s_1,s_2,\ldots,s_N)
  &= s_n .\cr }$$
Then for any signs $s'_n=\pm 1$\ we have that $\sumN s'_n \zeta_n
a_n$\ has the
same distribution as $\sumN\zeta_n a_n$. Using Proposition~1A:3.1(i)
and
Proposition~1C:1.3(ii), we see that
$$ \eqalignno{
   \sup\left\{\, \sumN \lmod\langle \xi,\zeta_n a_n \rangle\rmod
:
                 \xi\in B_{\left(L_{2,1}^{N2^N}\right)^*} \right\}
   &= \sup\left\{\,\normo{\sumN s_n\zeta_n a_n}_{2,1} : s_n=\pm 1
\right\} \cr
   &= \E \normo{\sumN \varepsilon_n \zeta_n a_n}_{2,1} \cr
   &\le c \normo{\left(\sumN\modo{\zeta_n a_n}^2\right)^\half}_{2,1}
\cr
   &\le c\, N\, 2^N \sqrt{\lm N} . \cr }$$
But
$$ \left(\sumN\normo{\zeta_n a_n}_{2,1}^2\right)^\half \approx N\,
2^N \lm N, $$
and the result follows.
\endproof
 
\vfill
\eject
 
\beginsection 3) A Proof of Grothendieck's Theorem via Pisier's Result
 
\proclaim Theorem 3.1. Let $\TCKY$\ be a \blotaBs. If\/ $Y$\ has cotype
$2$, then $T$\ is $2$-summing, with
$$ \pi_2(T) \le c\, R^2(Y) \sqrt{\lm R^2(Y)} .$$
 
I do not know whether this result is
new. The methods given in [P1 Ch.4] only
show that $\pi_2(T) \le c\, R^2(Y) \lm
R^2(Y)$. The argument given below takes
many of its ideas from [P1 Ch.9]. Its original feature is in
its use of $L_{\em(T^2)}$ ([P1 Ch.9] uses $L_4$).
 
\proclaim Lemma 3.2. Let $\mu$\ be a Radon
probability measure on $K$. Then for
all $\xS\in C(K)$, we have
$$ \E\normsumepsilon_\emTtwo \le c \normo{\rmsxs}_\infty . $$
 
\Proof First note for any $x\in C(K)$\ that
$$ \normo x_\emTtwo \le \int e^{\modo x^2}\,d\mu ,$$
for if $\int e^{\modo x^2}\,d\mu < e$, then $\int \em(\modo x^2)\,d\mu <
1$\ and so $\normo x_{\em(T^2)} \le 1$.
But as we always have $\int e^{\modo
x^2} \,d\mu \ge 1$, the result follows. If, on the other hand, we have
$ C = \int e^{\modo x^2}\,d\mu \ge e$, then
$$ \int \left(e^{\modo{x\over C}^2}-1\right)\,d\mu
   \le \ts{1\over C^2} \int \left( e^{\modo x^2} -1\right)\,d\mu \le 1 ,$$
and hence
$$ \int e^{\modo{x\over C}^2-1} \,d\mu \le 2e^{-1} < 1 ,$$
that is, $\normo x_{\em(T^2)} \le C$.
 
Now suppose that $\normo{\sumS\modo x^2}_\infty =1$. It follows from
Proposition~1C:1.2(i) that for some number $C<\infty$\ that for all $t>0$\
and $w\in K$\ we have
$$ \Pr\left(\modo{\sumepsilon(w)} \ge t\right) \le C e^{-C^{-1} t^2} .$$
Hence
$$ \eqalignno{
   \E\normo{\sumepsilon}_\emTtwo
   &\le \sqrt{2C}\, \E \int
e^{\modo{{1\over\sqrt{2C}}\sum \varepsilon_s x_s}^2}
   \,d\mu \cr
   &\le \sqrt{2C} \int_K \int_{t=0}^\infty
e^{\half C^{-1} t^2} {d\over dt}
        \left(C e^{-C^{-1} t^2}\right) \,dt \,d\mu \cr
   &\le c , \cr }$$
and the result follows.
\endproof
 
\proof of Theorem~3.1: First note that by
Proposition~2.1, $T$\ is $(2,1)$-summing with
$\pi_{2,1}(T)\le R^2(Y)$. Hence there is
a Radon probability measure $\mu$\ on
$K$\ such that for all $x\in C(K)$\ we have
$$ \normo{T(x)} \le \sqrt2 R^2(Y) \normo x_{L_{2,1}(\mu)} .$$
 
Now we show that for all $x\in C(K)$\ we have
$$ \normo{T(x)} \le c \sqrt{\lm R^2(Y)} \normo x_{L_\emTtwo(\mu)} .
   \eqno (3.1)$$
For suppose that $\normo x_\emTtwo < 1$. Then there is a positive simple
function $y$\ such that $\modo x<y$\ and $\normo y_\emTtwo \le 1$. By
Theorem~1A:2.7(ii), $\normo y_{\emTtwo,\infty}
\le c$, that is, $y^*(t) \le
c/\sqrt{\lm t}$. Hence
$$ y = \sumN a_n \chi_{A_n} ,$$
where $A_1\subseteq A_2\subseteq \ldots
\subseteq A_N$\ are measurable subsets
of $K$, and $a_1$, $a_2,\ldots,$\
$a_N\ge0$\ are such that $\sum_{n=M}^N a_n
\le c\big/\sqrt{\lm\mu(A_M)}$. Let $N_0$\
be the largest natural number such that
for $n\le N_0$\ we have $\mu(A_n)\le 1/(R^2(Y))^2$, and write $x=x_1+x_2$\
where
$$\eqalignno{
x_1 &= {x\over y} \sum_{n=1}^{N_0} a_n \chi_{A_n} \cr
x_2 &= {x\over y} \sum_{n=N_0+1}^N a_n \chi_{A_n}. \cr }$$
Now $\normo{T(x)} \le \normo{T(x_1)} + \normo{T(x_2)}$. We have that
$$\normo{T(x_1)} \le \sqrt2 R^2(Y) \normo{x_1}_{L_{2,1}(\mu)} .$$
Since
$$ x_1^*(t) \le c\, {\chi_{[0,1/(R^2(Y))^2]}(t)\over\sqrt{\lm(t)}} ,$$
we have
$$ \normo{x_1}_{L_{2,1}(\mu)}
   \le c \int_0^{1/(R^2(Y))^2} \ts{1\over 2\sqrt{t\lm t}} \,dt
   \le c\sqrt{\lm R^2(Y)} \Big/ R^2(Y) .$$
Also
$$\normo{T(x_2)} \le \normo{x_2}_\infty \le \sum_{n=N_0+1}^N a_n \le c
  \sqrt{\lm R^2(Y)} .$$
Thus $(3.1)$\ follows.
 
Therefore, for $\xS\in C(K)$, we have
$$ \eqalignno{
   \left( \sumS \normo{T(x_s)}_Y^2 \right)^\half
   &\le R^2(Y) \,\E\BernwalkTx_Y \cr
   &\le c \,R^2(Y) \,\sqrt{\lm R^2(Y)} \,\E\BernwalkTx_\emTtwo \cr
   &\le c \,R^2(Y) \,\sqrt{\lm R^2(Y)} \,\normo{\rmsxs}_\infty . \cr } $$
\endproof
 
\vfill
\eject
 
\beginsection 4) The $(\Phi,1)$-Summing Norm
 
It is very easy to extend Pisier's result
to cover $(\Phi,1)$-summing operators
for suitable \nqOf s $\Phi$. I believe
this result is new, but the proof is
only a slight modification of that given in [P3], [P4] or [J2 14.1].
 
\proclaim Theorem 4.1. Let $\TCKY$\ be a \blotaBs, and $\Phi$\ be a convex
\nqOf\ satisfying the $\Delta_2$-condition.
Then the following are equivalent.
\item{i)} $T$\ is $(\Phi,1)$-summing.
\item{ii)} There is a Radon probability
measure $\mu$\ on $K$\ and a number
$C<\infty$\ such that for all $x\in C(K)$\ with $\normo x_\infty \le 1$\
we have
$$ \normo{T(x)} \le C \Phi^{-1}\big(\normo x_{L_q(K,\mu)}\big) .$$
\item{iii)} There is a Radon probability measure $\mu$\ on $K$\ and the
factorization
$$ T\colon C(K)\hookrightarrow L_{\tilde\Phi,1}(K,\mu) \tonamed U X $$
where $U$\ is a \blo.
\endit
 
\proclaim Lemma 4.2. Let $\normdot_s$\ be a semi-norm on $C(K)$, $\Phi$\ a
\nqOf, and $\mu$\ a
Radon probability measure on $K$\ such that for all $x\in C(K)$\ and
measurable $A\subseteq K$\ with $\modo x\le\chi_A$\ we have
$$ \normo{x}_s \le \Phi^{-1}\bigl(\mu(A)\bigr) .$$
Then for all $x\in C(K)$\ we have
$$ \normo{x}_s \le \normo x_{L_{\tilde\Phi,1}(K,\mu)} .$$
 
\Proof Suppose $x\in C(K)$\ with $\normo
x_{L_{\Phi,1}} < 1$. Then there is a
positive simple function $y\colon C(K)\to\C$\
with $\modo x\le y$\ and $\normo
y_{L_{\Phi,1}} < 1$. Write $ y = \sumN
a_n \chi_{A_n} $, where $A_1\subseteq
A_2\subseteq\ldots\subseteq A_N$\ are
measurable subsets of $K$, and $a_n\ge0$.
Then
$$ \eqalignno{
   \normo{x}_s
   &\le \sumN \normo{{x\over y}\, a_n \chi_{A_n}}_s \cr
   &\le \sumN a_n \Phi^{-1}\bigl(\mu(A_n)\bigr) \cr
   &= \normo y_{L_{\Phi,1}} \cr
   &< 1 .\cr}$$
\endproof
 
\proof of i)$\Rightarrow$ii):
By Proposition~1A:2.1, there is a convex
function $\Psi$, a number $C<\infty$,
and a number $1\le q<\infty$,
such that $\Psi^{-1}
\labelledapprox C \Phi^{-1}$\ and $\Psi\circ T^{\invq}$\ is concave.
Since, by Proposition~1A:2.3(i) we have that
$\normdot_\Psi \labelledapprox C \normdot_\Phi$, it follows that
$T$\ is $(\Psi,1)$-summing.
 
So we may suppose that $\pi_{\Psi,1}(T)=1$, that is,
$$ \sup \left\{\, \normo{\bigl(\normo{T(x_s)}\bigr)_{s=1}^S}_\Psi
   : \normo{\sumS \modo{x_s}}_\infty \le 1 \right\} = 1 .$$
For each $\epsilon>0$, choose $\xS\in C(K)$\ such that
$$ \normo{\sumS\modo{x_s}}_\infty \le 1+\epsilon
   \quad\hbox{and}\quad
   \normo{\bigl(\normo{T(x_s)}\bigr)_{s=1}^S}_\Psi = 1 .$$
Since $\Psi$\ is convex, $l_\Psi$\ is a
norm. Hence we can choose $\zeta_1$,
$\zeta_2,\ldots,$\ $\zeta_S\in Y^*$\ such that
$$ \normo{\bigl(\normo{\zeta_s}\bigr)_{s=1}^S}_\Psi^* =1
   \quad\hbox{and}\quad
   \sumS \langle \zeta_s,T(x_s) \rangle = 1 .$$
Define $\varphi_\epsilon\colon C(K)\to\C$\ to be
$$ \varphi_\epsilon(y) = \sumS \langle \zeta_s,T(yx_s) \rangle .$$
We list three properties of $\varphi_\epsilon$.
$$ \normo{\varphi_\epsilon} \le 1+\epsilon, \eqno (4.1) $$
$$ \varphi_\epsilon(1) = 1, \eqno (4.2) $$
$$ \Psi\left(\ts{\normo{T(x)}\over(1+\epsilon)^2}\right)
   \le 1 - \left(\ts{1\over(1+\epsilon)^2}
\varphi_\epsilon\bigl(1-\modo x\bigr)\right)^q
   \quad\hbox{for $\normo x_\infty\le 1$}. \eqno (4.3) $$
Properties $(4.1)$\ and $(4.2)$\ are easily
established. For property $(4.3)$, if
$\normo x_\infty\le1$, let $y=1-\modo x$, $z_0=x$, and $z_s=yx_s$\ for
$s\in[S]$. Then $\normo{\sum_{s=0}^S
\modo{z_s}}_\infty \le 1+\epsilon$, and
hence
$$ \normo{\bigl(\normo{T(z_s)}\bigr)_{s=0}^S}_\Psi \le 1+\epsilon .$$
Therefore
$$ \sum_{s=0}^S
\Psi\left(\ts{\normo{Tz_s}\over(1+\epsilon)^2}\right) \le 1 .$$
 
Now we show that
$$ \sumS \Psi\left(\ts{\normo{T(z_s)}\over(1+\epsilon)^2}\right)
\ge
\normo{\left(\ts{\normo{T(z_s)}\over(1+\epsilon)^2}\right)_{s=1}^S}_\Psi^q,
$$
for if
$ \normo{\left({\normo{T(z_s)}\over
(1+\epsilon)^2}\right)_{s=1}^S}_\Psi >u $,
then
$ \sum_{s=1}^S
\Psi\left({\normo{T(z_s)}\over(1+\epsilon)^2u}\right) \ge 1 $.
As $\Psi\circ T^\invq$\ is concave, we have
$ \sum_{s=1}^S
\Psi\left({\normo{T(z_s)}\over(1+\epsilon)^2}\right) \ge u^q $,
and the result follows.
 
Therefore
$$ \eqalignno{
   \Psi\left(\ts{\normo{T(x)}\over(1+\epsilon)^2}\right)
   &= \Psi\left(\ts{\normo{T(z_0)}\over(1+\epsilon)^2}\right) \cr
   &\le 1 - \sum_{s=1}^S
\Psi\left(\ts{\normo{T(z_s)}\over(1+\epsilon)^2}\right) \cr
   &\le 1 -
\normo{\left(\ts{\normo{T(z_s)}\over(1+\epsilon)^2}\right)_{s=1}^S}_\Psi^q
\cr
   &\le 1 - \left(\ts{1\over(1+\epsilon)^2}
\sumS\langle \zeta_s,T(z_s) \rangle
   \right)^q \cr
   &= 1 - \left(\ts{1\over(1+\epsilon)^2}
\varphi_\epsilon\bigl(1-\modo x\bigr) \right)^q
   , \cr}$$
and property~$(4.3)$\ is established.
 
Now let $\varphi$\ be a weak * limit point of $\varphi_\epsilon$\ as
$\epsilon\to0$. Then, by $(4.1)$\ and
$(4.2)$, $\varphi$\ is a positive functional
of norm $1$, and hence by the Riesz
representation theorem, there is a Radon
probability measure $\mu$\ such that
$\varphi(x) = \int_K x\,d\mu$\ for all
$x\in C(K)$.
 
Also, from $(4.3)$\ we deduce that, if $\normo x_\infty \le 1$, then
$$ \eqalignno{
   \Psi\bigl(\normo{T(x)}\bigr)
   &\le 1 - \Bigl(\varphi\bigl(1-\modo x\bigr)\Bigr)^q \cr
   &\le q\,\varphi(\modo x) .\cr}$$
Therefore
$$ \eqalignno{
   \normo{T(x)}
   &\le \Psi^{-1}\bigl(q\varphi(\modo x)\bigr) \cr
   &\le q\, \Psi^{-1}\bigl(\varphi(\modo x)\bigr) \cr
   &\le C q\, \Phi^{-1}\bigl(\varphi(\modo x)\bigr) , \cr}$$
as $\Psi$\ is convex, and as $\Psi \labelledapprox C \Phi$.
\endproof
 
\proof of ii)$\Rightarrow$iii): This follows by Lemma~4.2.
\endproof
 
\proof of iii)$\Rightarrow$i):
Suppose that $\xS\in C(K)$\ have disjoint supports $\AS$\ on $K$, and that
$\normo{x_s}_\infty <1$\ for each $s\in[S]$. Then $\normo{T(x_s)} \le C
\normo{x_s}_{L_{\tilde\Phi,1}} < C
\Phi^{-1}\bigl(\mu(A_s)\bigr)$, where $C=\normo U$. Hence
$$ \sumS \Phi\left({\normo{T(x_s)}\over C}\right)
   < \sumS \mu(A_s)
   \le 1 ,$$
and so $\normo{\bigl(\normo{Tx_s}\bigr)_{s=1}^S}_\Phi \le C$. By
Proposition~1A:2.10,
this is sufficient to show that $\pi_{\Phi,1}(T) \le C$.
\endproof
 
\vfill
\eject
 
\beginsection Part 2 --- Lower Bounds for Random Walks in $l_\infty^N$
 
\beginsection Contents
 
\contents{%
Chapter&2A & The Problem of Cotype $2$                 \dotfill 
45\cr
\ns
&          & Outline of the Proof of Theorem 0.3       \dotfill
45\cr
Section&1  & Notation                                  \dotfill
46\cr
Section&2  & Reducing to Independent Processes         \dotfill
47\cr
Section&3  & Independent Gaussian Processes            \dotfill
50\cr
Section&4  & The Averaging Argument in the Gaussian Case
                                                       \dotfill
52\cr
&4.1       & The Cyclic Case                           \dotfill
52\cr
&4.2       & The $L_2$\ Averaging Argument             \dotfill
54\cr
&4.3       & The Duality Argument                      \dotfill
55\cr
Section&5  & Independent Bernoulli Processes           \dotfill
59\cr
&5.1       & The Tail of the Distribution of a Bernoulli Random Walk
                                                       \dotfill
59\cr
&5.2       & Suprema of Independent Bernoulli Processes
                                                       \dotfill
60\cr
Section&6  & The Averaging Argument in the Bernoulli Case
                                                       \dotfill
62\cr
&6.1       & The Proof of Proposition 6.3              \dotfill
63\cr
\nm
Chapter&2B & A Discussion of the Methods of Chapter 2A \dotfill
74\cr
\ns
Section&1  & The Reduction to Independent Processes    \dotfill
74\cr
&1.1       & The Cyclic Case                           \dotfill
75\cr
&1.2       & Lack of Unconditionality of Processes     \dotfill
76\cr
Section&2  & The Averaging Arguments of Sections 4 and 6
                                                       \dotfill
77\cr
Section&3  & Cotype $2$\ Constants of Other Operators from $l_\infty^N$
                                                       \dotfill
78\cr
\nm
Chapter&2C & Applications of Talagrand's Theorem       \dotfill
79\cr
\ns
Section&1  & The Gaussian Cotype $2$\ Constant of $l_\infty^N \hookrightarrow
             L_{T^2 \lm T,2}^N$                        \dotfill
80\cr
Section&2  & The Gaussian Cotype $2$\ Constant of $l_\infty^N \hookrightarrow
             L_{2,1}^N$                                \dotfill
82\cr
\nm
Chapter&2D & Comparison of Gaussian and Rademacher Cotype
                                                       \dotfill
88\cr
}
 
\beginsection Introduction to Part 2
 
The purpose of Part~2 is to prove the results of Section~1C:5. All
of this part
is devoted to calculating the cotype $p$\ constants of various operators
from
$l_\infty^N$. That is, we prove results of the form: for all $\xS\in\C^N$\
we have
$$ \E \normsumtheta_\infty \ge {1\over f(N)}
   \left( \sumS \normo{x_s}_*^p \right)^\invp ,$$
where $\thetalist$\ are either normalised Gaussians or Bernoulli
random
variables, $\normdot_*$\ is a $1$-symmetric norm on $\C^N$, $2\le
p<\infty$, and $f\colon\N\to\R_+$\ is some function.
 
Briefly, Theorems~1C:5.1(i) and~1C:5.2(i) are proven in Chapter~2A,
Theorems~1C:5.1(ii) and~1C:5.2(ii) are proven in Chapter~2C, and
Theorems~1C:5.3 and~1C:5.4 are proven in Chapter~2D (Chapter~2B is
taken up
with a discussion of the techniques used in Chapter~2A).
 
\vfill
\eject
 
\beginsection Chapter 2A --- The Problem of Rademacher Cotype $2$
 
This chapter proves the main result of the thesis,
Theorem~1C:5.1(i), which we restate here.
 
\proclaim Theorem 0.1. Let $\TliNY$\ be a \blotaBs. Then
$$ R^2(T) \le c \,\lm\lm N\, \pi_{2,1}(T) .$$
 
\noindent
As we showed in Section~5.1, by Theorem~1B:3.1, it is sufficient
to prove
Theorem~1C:5.2(i), that is, $R^2( l_\infty^N \hookrightarrow
L_{2,1}^N) \le c\, \lm\lm N$. The whole of this chapter is devoted
to proving
this result, and for convenience, we restate it here.
 
\proclaim Theorem 0.2. Let $\xS\in\linftyN$. Then
$$ \E \Bernwalk
   \ge \invc
   \invloglogN \rmsxsLtwoone .$$
 
\noindent
This seems to be difficult to prove, and so as a prelude, we first
prove a
weaker result.
 
\proclaim Theorem 0.3. Let $\xS\in\linftyN$. Then
$$ \E \Gausswalk
   \ge \invc
   \invloglogN \rmsxsLtwoone .$$
 
I do not know whether the $\lm\lm N$\ factor of Theorems~0.1 and~0.2
is the best
possible. However, Theorem~0.3 will be superseded in Chapter~2C,
where we will
replace the $\lm\lm N$\ factor by a $\sqrt{\lm\lm N}$\ factor.
 
\beginsection Outline of the Proof of Theorem 0.3
 
We are concerned with finding lower bounds for the $l_\infty$\ norm
of a
random walk.
The first thing we do is to treat the random walk as a process.
Much work has already been done on finding lower bounds for suprema
of
Gaussian processes,
and this is discussed in Chapters~2B and~2C.
However, I present my own way of handling this situation
in Section~2, which also deals with Bernoulli processes.
There, we reduce the problem to finding the
expectation of suprema of independent processes.
 
Then we find formulae for lower bounds of suprema of
independent processes.
For Gaussian processes, the problem
is easy, and we deal with this in Section~3. The Bernoulli
case is more difficult and more interesting, and amongst other
things, requires an interesting result describing the tail of a Bernoulli
random walk.
This we deal with in Section~5.
 
After these, an averaging argument takes over. The Gaussian case
is discussed in Section~4. Two variations of the argument are
presented. The first argument is simpler, but
the second argument is needed as it generalizes to the Bernoulli
case.
 
The Bernoulli case, given in Section~6, is a more difficult argument
with many technical details.
 
\beginsection 1) Notation
 
For the rest of this chapter, and indeed for Chapters~2B, 2C and~2D,
we will work with a fixed $x=(\xS)\in \CNS$\ (here $\CNS$\ denotes
the space of
$S$-tuples of $N$-vectors). We associate with each $x_s$\ an
ordering permutation $\pi_s\colon[N]\to[N]$,
so that we have
$$ \lnorm x_s \rnormtwoone \approx \sumN {1\over \sqrt{\pi_s(n)}}
   \lmod x_s(n)\rmod .$$
 
Our main motivating example will be when $x$\ is {\dt cyclic} on
a vector
$a\in\C^N$, that is, we have $a_1\ge a_2\ge\ldots\ge a_N\ge0$, $S=N$,
and
$$ x_s(n) = a((s+n)\bmod N) .$$
 
We write $\Gamma(x)$, or simply $\Gamma$\ (as no confusion can
arise) for the Gaussian process $\Gammaproc$\ where
$$ \Gamma_n = \sumS \gamma_s x_s(n).$$
Similarly, we write $E(x)$\ or $E$\ for the Bernoulli process
$\Eproc$\ where
$$ E_n = \sumS \varepsilon_s x_s(n).$$
Thus
$$ \E \Gausswalk = \E \supGauss, $$
and
$$ \E \Bernwalk = \E \supBern .$$
 
It will be useful to write $\thetalist$\ to denote either
$\gammalist$\ or $\epsilonlist,$\ and $\Theta(x)$\ for
$\Gamma(x)$\ or $E(x)$.
 
We will say that the process $\Theta=\Thetaproc$\ is {\dt independent}
if the random variables $\ThetaN$\ are independent, and that it has
{\dt size $k$}\ if $\lmod\{\,n\in[N]:\Theta_n\ne 0\}\rmod = k$.
 
\beginsection 2) Reducing to Independent Processes
 
Our problem is to find a lower bound to $\E \supTheta$,
where, as stated before, $\Theta_n = \sumS \theta_s x_s(n)$.
This is a difficult problem as $\ThetaN$\ are not necessarily independent.
The main result of this section is to replace $\ThetaN$\ by
independent random variables.
 
\proclaim Theorem 2.1. Let $\sigmaN$\ be disjoint subsets of $[S]$.
Let $\Theta^\sigma$\ be the process
$$ \Theta^\sigma_n = \sum_{s\in\sigma_n} \theta_s x_s(n), $$
so that $\ThetasigmaN$\ are independent. Then
$$ \E \supTheta \ge \smallquarter \E \supThetasigma .$$
 
At first sight this result appears to throw away far
too much information. However this is not the case, although
it may well account for the $\lm\lm N$\ factor (this will be discussed
in
Section~2B:1).
 
Before proving this result, we introduce some notation which will
allow us to apply it more easily.
 
\proclaim Definition. A {\dt system of strips} is a $N$-tuple
$\sigma=\sigmatuple$\ of disjoint subsets of $[S]$. It is said
to be of {\dt size $k$} if exactly $k$\ of the subsets
$\sigmaN$\ are non-empty. If $\sigma$\ is a $N$-tuple of
subsets of $[S]$, not necessarily disjoint, then we
say $\sigma$\ is {\dt almost a system of strips}.
\moreproclaim
If\/ $\Theta=\Thetaproc$\ is a process with $\Theta_n=\sumS \theta_s
x_s(n)$, then $\Theta^\sigma=\Thetasigmaproc$\ is the process
$\Theta^\sigma_n=\sum_{s\in\sigma_n} \theta_s x_s(n)$.
\moreproclaim
If\/ $\xS\in\linftyN$\ and $\sigma\subseteq[S]$, we write $x_\sigma(n)$\
for the vector in $\C^S$\ given by
$$ x_\sigma(n)(s) = \cases{ x_s(n) & if $s\in\sigma$ \cr
                            0      & if $s\not\in\sigma$.\cr}
$$
\moreproclaim
For $y\in\CNS$, and any system of strips $\sigma$, we write (with
a slight abuse
of the usual notation)
$$ \supp x \subseteq \sigma ,$$
if for all $n\in[N]$\
and $s\in[S]$, we have $x_s(n)\ne0$\ only if $s\in\sigma_n$.
 
Since Theorem~2.1 seemingly throws away so much information, we will
have
to choose our strips wisely and make sure that they pick out
the larger elements of $\xS$. First we illustrate this
in the case when $x$\ is cyclic on $a$\ as follows. For each
$k\in[N]$, let $\sigma(k)=(\sigmaN)$\ be the system of strips
of size $k$\ given by
$$ \sigma_n = \cases { [N-n+1, N-n+\intNok] &if $\intNok \big| n$\cr
                       \emptyset            &otherwise.\cr}$$
Then $\E \supThetasigmak$\ is the expectation of the supremum
of $k$\ independent copies of
$\lmod \sum_{s=1}^{\intNok} \theta_s a(s) \rmod$.
If $x$\ is not cyclic things are more tricky. The first natural
system of strips that one would choose is not a tuple of disjoint
subsets, that is, it is only almost a systems of strips.
 
\proclaim Definition. Given $\nu\in\Nk$, so that $\nu=
\{\nk\}$\ with $1\le n_1<n_2<\ldots<n_k\le N $, we define
$\sigma'(\nu)=(\sigma'_1,\sigma'_2,\ldots,\sigma'_N)$\ to be
$$ \sigma'_n =
   \cases{ \lbrace\,s\in[S]:\pi_s(n)\le\intNok \rbrace
           & if $n\in\nu$ \cr
           \emptyset
           & otherwise. \cr}
$$
Thus $\sigma'(\nu)$\ is almost a system of strips.
 
The required system of strips is given by the following definition.
 
\proclaim Definition. Given $\nu\in\Nk$, we define the system of
strips $\sigma(\nu)=(\sigmaN)$\ by
$$ \sigma_n(\nu) = \sigma'_n(\nu) \setminus \bigcup_{n'\ne n}
                   \sigma'_{n'}(\nu).
$$
 
These systems of strips will be referred to as the {\dt standard
systems of strips}.
The following result shows that the standard systems of strips
inherit many of the properties of the $\sigma'(\nu)$.
 
\proclaim Proposition 2.2. Let $s\in[S]$, $n\in[N]$\ and $k\in[N/3]$.
Then
$$ \lmod\{\,\nu\in\Nk:s\in\sigma_n(\nu)\}\rmod
   \ge \invc
   \lmod\{\,\nu\in\Nk:s\in\sigma'_n(\nu)\}\rmod.$$
and
$$ \lmod\{\,\nu\in\Nk:s\in\sigma'_n(\nu)\}\rmod =
   \cases{ {k\over N}\mNk & if $\pi_s(n)\le \intNok$ \cr
           0              & otherwise. \cr}
$$
 
\Proof
The second equation is easy, for we have that
$$ \modo{\{\, \nu\in\Nk : n\in\nu \}} = \koNmNk ,$$
and that if $n\in\nu$, then $s\in\sigma'_n(\nu)$\ if and only if
$\pi_s(n) \le
\intNok$.
 
So let us derive the first equation. We suppose that $\pi_n(s) \le
\intNok$\
(otherwise it is clearly true). We are interested in showing that
the
proportion of those $\nu\in\Nk$\ with $n\in\nu$ that are such that
$\pi_s(n') >
\intNok$\ for $n'\in\nu\setminus\{n\}$, is bounded by a universal
constant. In
calculating this quantity, we may assume without loss of generality
that
$n=1$\ and $\pi_s = \Id_{[N]}$. Then we are finding what proportion
of
$\nu'\in[2,N]^{(k-1)}$\ have $\nu'\cap[1,\intNok] = \emptyset$.
 
For $k=1$\ this is $1$. Otherwise, it is
$$ { (N-\intNok) (N-\intNok-1) \cdots (N-\intNok-k+2)
   \over
   (N-1) (N-2) \cdots (N-k+1) }.$$
Remembering that $k\le N/3$, we see that this is greater than
$$ \eqalignno{
   &\phantom{=}
   { (N-N/k) (N-N/k-1) \cdots (N-N/k-k+2)
   \over
   (N-1) (N-2) \cdots (N-k+1) } \cr
   &=
   { (N-N/k) \over (N-k+1) }
   \left( 1 - {N \over (N-1) k} \right)
   \left( 1 - {N \over (N-2) k} \right) \cdots
   \left( 1 - {N \over (N-k+2) k} \right) \cr
   &\ge
   {\half N \over N} \left( 1 - {3\over2} \invk \right)^{k-1} \cr
   &\ge \invc , \cr}$$
as desired.
\endproof
 
Now we prove Theorem~2.1. What follows is well known, and
combines a lemma of P.~L\'evy with the so called reflection
principle.
 
 
\proclaim Lemma 2.3.
Let $v_1$, $v_2,\ldots$, $v_S$\ be independent symmetric
random variables taking values in a Banach space $X$.
Define the quantities
$$ U = \lnorm\sumS v_s \rnorm ,$$
$$ V = \sup_{S'\in[S]} \lnorm\sum_{s=1}^{S'} v_s \rnorm ,$$
$$ W = \sup_{1\le S_1\le S_2\le S}\lnorm\sum_{s=S_1}^{S_2}v_s\rnorm.$$
Then we have the following inequalities for all $r>0$:
\cditem{i)}
$$ \Pr (U>r) \ge \smallhalf \Pr (V>r); $$
\cditem{ii)}
$$ 2V\ge W. $$
%$$ \Pr (V>r) \ge \smallhalf \Pr (W>r). \leqno{\sl ii)}$$
 
\proof of i): See [Ka, Ch.2, Lem.1].
\endproof
 
\proof of ii): This follows as
$$ \lnorm\sum_{s=S_1}^{S_2}v_i\rnorm
\le \lnorm\sum_{s=1}^{S_1-1}v_i\rnorm
+ \lnorm\sum_{s=1}^{S_2}v_i\rnorm
\le 2V. $$
\endproof
 
\proclaim Proposition 2.4. Let $\sigma$\ be a system of strips. Then
for all $r>0$ we have
$$ \Pr\lbrack\supTheta\ge r\rbrack
   \ge \smallhalf
   \Pr\lbrack\supThetasigma \ge\smallhalf r\rbrack.$$
 
\Proof
Without loss of generality we may assume that
$ \sigma_n = [S_n,S'_n] $\ for $t\le k$,
where
$1\le S_1\le S'_1<S_2\le S'_2 <\ldots<S_k\le S'_k\le S $\
is a sequence of integers, and that $\sigma_n=\emptyset$\ for $t>k$.
Then
$$\supN\lmod\sum_{s\in\sigma_n}
\theta_s x_s(n)\rmod
 \le \supN\lnorm\sum_{s\in\sigma_n} \theta_s x_s
\rnorminfty
 \le \sup_{1\le S_1\le S_2\le N} \left\|\sum_{s=S_1}^{S_2}
\theta_s x_s \rnorminfty $$
and the result follows immediately from Lemma~2.3.
\endproof
 
\bigskip
 
\proof of Theorem 2.1: This follows straight away from Proposition~2.4.
\endproof
 
\vfill
\eject
 
\beginsection 3) Independent Gaussian Processes
 
The main result of this section is easy to prove.
 
\proclaim Proposition 3.1. Let $\Gamma=\Gammaproc$\ be an independent
Gaussian process of size at most $k$\ such that $\Gamma_n$\ has
standard deviation $a_n$. Then for $1\le p<\infty$\ we have
$$ \E \supGauss \ge \invc \invsqrtp {\sqrtlogk \over k^\invp}
   \lnorm (a_n)_{n\in[N]} \rnorm_p .$$
 
The proof of this theorem falls into two easy parts.
 
\proclaim Proposition 3.2. Let $\Gamma=\Gammaproc$\ be an independent
Gaussian process such that $\Gamma_n$\ has standard deviation $a_n$.
Then
$$ \E \supGauss \ge \invc \lnorm (a_n)_{n\in[N]} \rnorm_{\em(T^2)}.
$$
 
To prove this, we require the following lemma.
 
\proclaim Lemma 3.3. Given $C_1>0$, there is a $C_2<\infty$\ such
that for all
$0\le x_1$, $x_2\ldots,$\ $x_N \le 1$\ we have that
if $ \prodN (1-x_n) \ge C_1$, then $ \sumN x_n \le C_2$.
 
\Proof This follows by `A'-level calculus.
\endproof
 
\proof of Proposition 3.2: This is essentially a finite version of
the second
Borel--Cantelli Lemma.
 
Suppose that $\E\supGauss \le 1$. Then $\Pr(\supGauss \ge 2) \le
\half$, that
is,
$$ \prodN \left(1-\Pr(\modo{\Gamma_n} \ge 2) \right) \ge \ts\half
.$$
By Proposition~1C:1.1, this implies that
$$ \prodN \left(1-e^{-\invc/a_n^2}\right) \ge \invc ,$$
and by Lemma~3.3, this implies that
$$ \sumN e^{-\invc/a_n^2} \le c .$$
From this, we deduce
$$ \sumN \em(\invc a_n^2) < 1 ,$$
that is, $\normo{(a_n)_{n\in[N]}}_{\em(T^2)} \le c $.
\endproof
 
\proclaim Proposition 3.4. If $a\in\C^k$, then
$$ \lnorm a \rnorm_{\em(T^2)} \ge \invc \invsqrtp {\sqrtlogk \over
   k^\invp} \lnorm a \rnorm_p .$$
 
\Proof This follows from Proposition~1A:2.3(ii), and the fact that
for $1\le
t\le k$\ we have
$$ \sqrt{\lm t} \ge \invc \invsqrtp {\sqrtlogk \over k^\invp} t^\invp
.$$
\endproof
 
We also have a converse to Proposition~3.2.
 
\proclaim Proposition 3.5. Let $\Gamma=\Gammaproc$\ be a
Gaussian process such that $\Gamma_n$\ has standard deviation $a_n$.
Then
$$ \E \supGauss \le c \lnorm (a_n)_{n\in[N]} \rnorm_{\em(T^2)}. $$
 
\Proof This is somewhat like the proof of the first Borel--Cantelli
lemma.
 
Suppose that $\normo{(a_n)_{n\in[N]}}_{\em(T^2)} \le 1$, that is
$$ \sumN e^{-1/a_n^2} \le e^{-1} .$$
Then, by Proposition~1C:1.1, we have
$$ \Pr \left( \supGauss \ge 1 \right)
   \le \sumN \Pr \bigl(\modo{\Gamma_n} \ge 1\bigr)
   \le c .$$
By Corollary~1C:1.5c, it follows that $\E\supGauss \le c$.
\endproof
 
\vfill
\eject
 
\beginsection 4) The Averaging Argument in the Gaussian Case
 
In this section, we establish Theorem~0.3.
We give two arguments, both of them
based on taking suitable averages.
 
\beginsection 4.1) The Cyclic Case
 
First of all we give the argument for when $x$\ is cyclic. This will
illustrate many of the techniques that we shall use.
 
\proclaim Proposition 4.1. Suppose that $x$\ is cyclic on $a$.
Then
$$ \E \Gausswalk \ge \invc \invloglogN \normo a_{2,1} .$$
 
We split the proof of this proposition
up into a series of smaller results. The
purpose of this is not to make it easier to understand, but rather to
illustrate some of the main steps that will be used in future proofs.
 
\proclaim Proposition 4.2. Suppose that
$x$\ is cyclic on $a$. Then there is a
$k\in[N/3]$\ such that
$$ \sqrtlogk \normo{\asubNok}_2 \ge \invc \invloglogN \normo a_{2,1} .$$
 
\proclaim Proposition 4.3. Suppose that
$x$\ is cyclic on $a$. Then there is a
$k\in[N/3]$\ such that
$$ \sqrtlogk \normo{\asubNok}_2 \ge \invc \invsqrtloglogN \sqrt N
   \normo a_\LTtlmTt .$$
 
\proclaim Proposition 4.4. Suppose that $x$\ is cyclic on $a$. Let $W_k =
\ds\invklogk$. Then
$$ \left( \sumkN W_k \logk \normo{\asubNok}_2^2 \right)^\half
   \ge \invc \sqrt N \normo a_\LTtlmTt .$$
 
\proclaim Proposition 4.5. Let $a\in\C^N$. Then
$$ \normo a_\LTtlmTt \ge \invc \invsqrtloglogN \normo a_{L_{2,1}^N} .$$
 
\proof of Proposition 4.5: By Proposition~1A:2.6(ii), we have
$$ \normo a_\LTtlmTt
   \approx \invsqrtN \left( \sumN
\lm(N/\pi(n)) \modo{a(n)}^2 \right)^\half ,$$
where $\pi$\ is an ordering permutation
for $a$, and by the Cauchy--Schwartz
inequality, we have
$$ \eqalignno{
   \normo a_{L_{2,1}^N}
   &\approx \invsqrtN \sumN {1\over\sqrt{\pi(n)}} \modo{a(n)} \cr
   &\le \invsqrtN \left( \sumN {1\over\pi(n) \lm(N/\pi(n))} \right)^\half
   \left( \sumN \lm(N/\pi(n)) \modo{a(n)}^2 \right)^\half \cr
   &\approx \invc \sqrt{\lm\lm N} \normo{a}_\LTtlmTt .\cr}$$
\endproof
 
\proof of Proposition 4.4:
$$ \eqalignno{
   \sumkN W_k \logk \normo{\asubNok}_2^2
   &= \sumkN \invk \sumNok \modo{a(n)}^2 \cr
   &\approx \sumN \sumkNon \invk \modo{a(n)}^2 \cr
   &\approx \sumN \lm(N/n) \modo{a(n)}^2 \cr
   &\approx \sqrt N \normo a_\LTtlmTt .\cr}$$
\endproof
 
\proof of Proposition 4.3: It is easy to see that
$$ \sumkN W_k \approx \lm\lm N ,$$
and hence
$$ \supkN \sqrtlogk \normo{\asubNok}_2 \ge
   \invc \invsqrtloglogN \left( \sumkN W_k \logk \normo{\asubNok}_2^2
   \right)^\half .$$
Now apply Proposition~4.4.
\endproof
 
\proof of Proposition 4.2: This follows
straight away from Propositions~4.3 and~4.5.
\endproof
 
\proof of Proposition 4.1: Let $\sigma(k)$\
be the system of strips defined in
Section~2. By Theorem~2.1, we have
$$ \E \Gausswalk \ge \smallquarter \E \supGausssigmakx .$$
By Proposition~3.1, the right hand side of this dominates
$$ \invc \sqrtlogk \left( \AvokN
\normo{x_{\sigma_n(k)}(n)}_2^2 \right)^\half
   \ge \invc \sqrtlogk \normo{\asubNok}_2 .$$
Finally, the result follows from Proposition~4.2.
\endproof
 
The choice of the weighting $W_k$\ seems
somewhat arbitary, but it is going to
be fundamental to the rest of this chapter. In Chapter~2B
we will show how it occurs naturally as
a consequence of Fernique's Theorem. We
will also consider the effect of other weightings.
 
\beginsection 4.2) The $L_2$\ Averaging Argument
 
Now we prove Theorem~0.3 when $x$\ is not cyclic.
First note that, by Proposition~4.5, it
is sufficient to prove the following.
 
\proclaim Proposition 4.6. We have
$$ \E \Gausswalk \ge \invc \invsqrtloglogN \left( \sumS \lnorm x_s
   \rnormLtwoltwoN \right)^\half. $$
 
\Proof If $\nu\in\Nk$, then by Theorem~2.1. we have
$$ \E \Gausswalk \ge \smallquarter \E \supGausssigmanux ,$$
and by Proposition~3.1, this is greater than
$$ \invc \sqrtlogk \left( \AvokN \normo{\xsigmann}_2^2 \right)^\half .$$
Now we take a $L_2$\ average over all
standard collections of strips of size
$k$, and deduce
$$ \E \Gausswalk
   \ge \invc \left( \AvNk {\logk\over k} \sumN \lnorm \xsigmann \rnorm_2^2
        \right)^\half ,$$
which is easily seen to be
$$ = \invc \left( {\logk\over k} \sumS \sumN \mxsn^2
     {\mnuinsigma \over \mNk} \right)^\half ,$$
which by Proposition~2.2
$$ \ge \invc \left( {\logk\over N} \sumN \sumpis \mxsn^2 \right)^\half.$$
Now we take the $L_2$\ average over all $k\in[N/3]$\ with the weighting
$W_k = \ds\invklogk$, remembering that $\sumkN W_k \approx \lm\lm N$, and
derive the following.
$$ \eqalignno{
   \E \Gausswalk &\ge \invc \left(
\invloglogN \sumkN {1\over Nk} \sumN \sumpis
                      \mxsn^2 \right)^\half \cr
   &\approx \invc \invsqrtloglogN \left( \sumN \invN \sumS \sumkNopi \invk
   \mxsn^2 \right)^\half \cr
   &\approx \invc \invsqrtloglogN \left( \sumN \invN \sumS \lm(N/\pi_s(n))
   \mxsn^2 \right)^\half \cr
   &\approx \invsqrtloglogN \left( \sumN \lnorm x_s \rnormLtwoltwoN
   \right)^\half ,\cr } $$
as desired.
\endproof
 
\beginsection 4.3) The Duality Argument
 
Here we give a different proof of Theorem~0.3. It can be presented as an
averaging argument, where the average
over $k$\ is an $L_1$\ average, or as
a duality argument. The arguments involve
a parameter $\beta$, but this can be
chosen arbitarily as long as it is some number greater than $\smallhalf$.
Throughout, $W_k$\ will be the weighting equal to $\ds\invklogk$.
 
As before, we first illustrate the argument in the cyclic case.
 
\proclaim Proposition 4.7. Let $x$\ be cyclic on $a$. Then
$$ \sumkN W_k \E \supGausssigmakx \ge \invc \lnorm a \rnormtwoone.$$
 
\Proof As before,
$$ \E \supGausssigmakx \ge \invc \sqrtlogk \asubNoktwo .$$
Now, let
$$ w^k(n) = \cases{
   \ds{\invsqrtn \left({\logk\over\logNon}\right)^\beta}
& if $n\le N/k$ \cr
                  &               \cr
   0
                 & otherwise     \cr}$$
so that $\lnorm w^k \rnorm_2 \le c\left(1\v{1\over\sqrttbmo}\right)
\sqrtlogk$\ for
$\beta>\half$. Then by the Cauchy--Schwartz inequality we have
$$ \sqrtlogk \asubNoktwo \ge \invc (1\w\sqrttbmo) \sumN w^k(n)
   a(n). $$
Hence
$$ \eqalignno{
   \sumkN W_k \E \supGausssigmakx
   &\ge \invc (1\w\sqrttbmo) \sumkN \invklogk \sumNok w^k(n) a(n) \cr}$$
$$\eqalignno{
   &= \invc (1\w\sqrttbmo) \sumN \invsqrtn (\logNon)^{-\beta} \sumkNon
      \invk (\logk)^{\beta-1} \cr
   &\ge \invc {1\w\sqrttbmo\over\beta} \lnorm a \rnormtwoone .\cr}$$
If we choose $\beta=1$, say, the result follows.
\endproof
 
Now we give the argument for the
non-cyclic case. However, by rewriting the
argument in a dual formulation, we concentrate on the choice of
weightings.
 
\proclaim Proposition 4.8. Let $\lnorm\widecdot\rnormGamma$\ be a norm on
$\CNS$\ defined by
$$ \lnorm x \rnormGamma = \supkN \supNk \sqrtlogk \left( \AvokN \lnorm
   \xsigmanunn \rnorm_2^2 \right)^\half ,$$
and let $\lnorm\widecdot\rnormGammadual$\
be its dual norm with respect to the
duality
$$ \langle w,x \rangle = \sumS \sumN w_s(n) x_s(n).$$
Then
$$ \lnorm w \rnormGammadual = \inf
\lbrace \sumkN \sumNk \kosqrtlogk \left(
   \AvokN \lnorm \wnusigmanunn \rnorm_2^2 \right)^\half \rbrace ,$$
where the infimum is over the set
$$ \lbrace \, (w^\nu\in\CNS)_{\nu\in\Nk,k\in[N/3]} :
   \supp w^\nu \subseteq \sigma(\nu),
   \,\sum_\nu w^\nu\ge w
   \rbrace .$$
 
\Proof Let $Z$\ be the space $\{
(x^\nu\in\CNS)_{\nu\in\Nk,k\in[N/3]} \}$\ with
norm
$$ \normo{(x^\nu)}_Z = \supkN \supNk \sqrt{\lm k\over k} \left( \sumN
   \normo{x^\nu_{\sigma_n(\nu)}(n)}_2^2 \right)^\half .$$
Then $(\CNS,\normdot_{\Gamma})$\ embeds isometrically into $Z$\ via the
diagonal map
$I\colon x\mapsto(x)_\nu$. The dual of $I$\ is the map
$$ \eqalign{
   I^* \colon Z^* &\to     (\CNS,\normdot_\Gamma^*) \cr
   (w^\nu)_\nu    &\mapsto \sum_\nu w^\nu ,\cr}$$
where the induced quotient map $I^*\colon
Z^*/\ker(I^*) \to (\CNS,\normdot_\Gamma^*)$\
is an isometry. But
$$ \normo{(w^\nu)}_Z^* = \sumkN \sumNk \sqrt{k\over\lm k} \left(
   \normo{\wnusigmanunn}_2^2 \right)^\half ,$$
and the result follows.
\endproof
 
Now, if $w\in\CNS$\ is given by
$$ w_s(n) = \overline{\sign(x_s(n))} \invsqrtpi u_s, \eqno (4.1) $$
where $u_s=\lnorm x_s \rnormtwoone \Bigg/
\rmsxstwoone$, then it is easy to see
that
$$ \rmsxstwoone \approx \sumS \sumN w_s(n) x_s(n). \eqno(4.2) $$
Now Theorem~2.1 can be stated as follows: for all $x\in\CNS$\ we have
$$ \E \Gausswalk \ge \invc \lnorm x \rnormGamma. $$
Hence it is sufficient to show that
$$ \lnorm x \rnormGamma \ge \invc \invloglogN \invsqrtN \rmsxstwoone.$$
But then, by Proposition~4.8 and equation
$(4.2)$, it is sufficient to prove the
following proposition, to whose proof we devote the rest of this section.
 
\proclaim Proposition 4.9. If $w\in\CNS$\
is the vector given by $(4.1)$, then
$$ \lnorm w \rnormGammadual \le c \sqrt{N} \lm\lm N .$$
 
\Proof We first note that it is sufficient to prove this in the case that
$w\ge0$. The proof now proceeds by choosing a suitable sequence $(w^\nu)$\
and checking that it has the correct properties.
 
For $\nu\in\Nk$, we let
$$ w_s^\nu(n) = \cases{
   \ds{w_s(n) W_k \invkoNmNk
\logkologNopi^\beta}& if $s\in\sigma_n(\nu)$ \cr
          &                        \cr
   0                                             & otherwise. \cr}$$
We need to show
$$ \sum_\nu w^\nu \ge \invc w ,\leqno \rm i)$$
and
$$ \sumkN \sumNk \kosqrtlogk \left( \AvokN \lnorm \wnusigmanunn \rnorm_2^2
   \right)^\half \le c \sqrt{N} \lm\lm N .\leqno \rm ii)$$
 
\noindent
To show (i) we note that
$$ \eqalignno{
   &\phantom{=} \sumkN \sumNk w_s^\nu(n) \cr
   &= w_s(n) \sumkN W_k \invkoNmNk \logkologNopi^\beta \mnuinsigma \cr
   &\ge w_s(n) \sum_{k=1}^{N/\pi_s(n)} W_k \logkologNopi^\beta \cr
   &= w_s(n) (\lm(N/\pi_s(n)))^{-\beta} \sum_{k=1}^{N/\pi_s(n)}
   \invk (\lm k)^{\beta-1} \cr
   &\approx \ts\invbeta w_s(n) . \cr } $$
 
\noindent
To show (ii) we have the following chain of inequalities. The quantity
$$ \sumkN \sumNk \kosqrtlogk \left( \AvokN \lnorm \wnusigmanunn \rnorm_2^2
   \right)^\half $$
is, by the Cauchy--Schwartz inequality, less than
$$ \sumkN \kosqrtlogk \left( \mNk \sumNk
\AvokN \lnorm \wnusigmanunn \rnorm_2^2
   \right)^\half $$
$$ \eqalign{
   = \sumkN \kosqrtlogk & \left( \mNk \sumS \left[ \invk \sumN
   w_s(n)^2 W_k^2 \right. \right.\times\cr
   & \left. \left.{1\over\left(\koNmNk\right)^2} \logkologNopi^{2\beta}
   \mnuinsigma \right]\right)^\half. \cr}$$
This, by Proposition~2.2, (and collecting terms) is approximately equal to
$$ \sqrt N \sumkN W_k \invsqrtlogk \left( \sumS u_s^2
   \sumss{n=1}{\pi_s(n)\le N/k}^N \invpi \logkologNopi^{2\beta}
   \right)^\half. $$
Now $\sumS u_s^2 = 1$, and hence the above is equal to
$$ \sqrt N \sumkN W_k \invsqrtlogk \left(
\sumNok \invn \logkologNon^{2\beta}
   \right)^\half $$
which is approximately less than $\left(1\v\invsqrttbmo\right)
\sqrt N \lm\lm N$.
 
\endproof
 
\vfill
\eject
 
\beginsection 5) Independent Bernoulli Processes
 
We now turn our attention to Bernoulli processes, first dealing with
the
independent case. In contrast to the Gaussian case, this problem
is rather
difficult. Firstly we are required to know something about the tail
of the
distribution of a Bernoulli random walk. Secondly, the formula so
obtained does
not fit into an argument like that given for Proposition~3.2,
and a new approach is needed.
 
\beginsection 5.1) The Tail of the Distribution of a Bernoulli Random
Walk
 
Here we are concerned with finding lower bounds for
$$ \Pr \left( \lmod \sumS \varepsilon_s a(s) \rmod \ge r \right)$$
where $a\in\C^S$\ and $r>0$. To simplify things, we note that it
is sufficient
to consider
$ \Pr \left( \sumS \varepsilon_s a(s) \ge r \right)$\
when $a\in\R^S$, for we have the following result.
 
\proclaim Proposition 5.1. (See [Ka Ch.2 \S6].) Let $a\in\C^S$, and
$r>0$. Then
$$ \eqalignno{
   \invc \Pr \left( \sumS \varepsilon_s |a(s)| \ge c r \right)
   &\le \Pr \left( \lmod \sumS \varepsilon_s a(s) \rmod \ge r \right)
\cr
   &\le c \Pr \left( \sumS \varepsilon_s |a(s)| \ge \invc r \right)
.\cr}$$
 
\noindent
Furthermore, to save writing, we write $E_a$\ for the random variable
$ \sumS \varepsilon_s a(s) $.
 
First, we consider upper bounds. We have, by Proposition~1C:1.2(i),
that
$$ \Pr ( E_a \ge t \norma_2 ) \le ce^{-\invc t^2}. \eqno (5.1)$$
However, this cannot provide the lower bound, because we also have
$$ \Pr ( E_a > \norma_1 ) = 0. \eqno (5.2)$$
Finding conditions on $a$\ for which $(5.1)$\ has a reverse inequality
has
received a great deal of attention (see, for example [Ch Ch.7]).
However we
take a different approach.
 
If we combine equations $(5.1)$\ and $(5.2)$, we see that whenever
$a=a'+a''$,
we have
$$ \Pr ( E_a > \norma_1 + t\norma_2 ) \le ce^{-\invc t^2}.$$
Hence
$$ \Pr (E_a > K(a,t\noneatwo) ) \le ce^{-\invc t^2} , $$
where $K(\widecdot,t\noneatwo)$\ is the interpolation norm given
in
Section~1A:2.5. The
surprising fact is that this is the best result.
 
\proclaim Theorem 5.2. If $a\in\R^S$\ and $t>0$, then
$$ \Pr ( E_a \ge K(a,t\noneatwo) ) \ge \invc \emctt.$$
 
\proclaim Lemma 5.3. (Paley--Zygmund, see [Ka Ch.3 Thm.3].) If $a\in\R^S$,
then
$$ \Pr ( E_a \ge \smallhalf \norma_2 ) \ge {\textstyle {3\over 32}}
. $$
 
\proof of Theorem~5.2: First note that it is sufficient to prove
this theorem
when $t$\ is a perfect square, say $t=M^2$. By Proposition~1A:2.9,
we need only show
$$ \Pr ( E_a \ge \invc \norma_{\PonetwoM} ) \ge e^{-cM} , $$
where $\normdot_{\PonetwoM}$\ is the $(1,2)$-$M$-partition norm described
in
Section~1A:2.5. But if $\betaM$\ is a $M$-partition of $[S]$ such
that
$$ \norma_{\PonetwoM} = \sumM \lnorm \asubbetam \rnorm_2 , $$
then by Lemma~5.3, we have
$$ \Pr ( E_a \ge \smallhalf \norma_{\PonetwoM} )
   \ge \prodM \Pr \left( E_{\asubbetam} \ge \smallhalf \lnorm \asubbetam
       \rnorm_2 \right)
   \ge \left({\textstyle {3\over 32}}\right)^M .$$
\endproof
 
\beginsection 5.2) Suprema of Independent Bernoulli Processes
 
Here we prove the Bernoulli analogue of Proposition~3.1.
 
\proclaim Theorem 5.4. Let $E=\Eproc$\ be an independent Bernoulli
process of
size $k$, where $E_n=E_{a_n}$\ for some $a_n\in\C^S$. Then for $1\le
p<\infty$\
we have
$$ \left( \E \supBern^p \right)^\invp
   \ge \invc \invsqrtp \invkinvp
   \lnorm\bigl(K(a_n,\sqrtlogk\noneatwo)\bigr)_{n=1}^N \rnorm_p .$$
 
\noindent
(Note that by Corollary~1C:1.5b we have
$$ \E \supBern \ge \invc \invsqrtp \left( \E \supBern^p \right)^\invp
$$
for any $1\le p<\infty$.)
 
What is this result saying? If we let $K_n=K(a_n,\sqrtlogk\noneatwo)$,
so that
$\Pr(E_n\ge\invc K_n)\ge \invc\invk$, then this result says that
the expected
supremum of the $E_n$s dominates the $L_p$\ average of the $K_n$s.
Now this is not obvious.
It {\it is}\/ obvious that the expected supremum is greater than
the median of
the non-zero $K_n$s. For if we rearrange the $a_n$s so that the non-zero
$K_n$s are arranged
$ 0<K_1\le K_2 \le \ldots \le K_k $,
then we see that
$$ \eqalignno{
   \Pr\left(\supBern \ge \invc K_{k/2}\right)
   &\ge \Pr\left(\sup_{k\in[k/2,k]} \modo{E_n} \ge \invc K_{k/2}\right)
\cr
   &= 1- \prod_{k=k/2}^k \left(1-\Pr( \modo{E_n} \ge \invc K_{k/2})
\right) \cr
   &\ge 1- \left( 1-\invc\invk\right)^{k/2} \cr
   &\ge \invc. \cr}$$
However, there is no reason why the median, $K_{k/2}$, should come
anywhere
near the desired $L_p$\ average.
 
But we can do better than this. We can show that the expected supremum
is
larger than the upper $\invsqrtk$-tile, that is, $\Kkmsqrtk$. This
is
because $\lm k \approx \lm\sqrt{k}$, and hence $\Pr(E_n\ge\invc
K_n)\ge \invc \invsqrtk$. Therefore, following the same argument
as above, we
have
$$ \eqalignno{
   \Pr\left(\supBern \ge \invc \Kkmsqrtk \right)
   &\ge 1- \left( 1-\invc\invsqrtk\right)^{\sqrt{k}} \cr
   &\ge \invc. \cr } $$
This turns out to be sufficient, as we now show. To make the argument
clearer,
we abstract Theorem~5.4 into the following result.
 
\proclaim Theorem 5.5. Let $\Theta_1$, $\Theta_2,\ldots,$\ $\Theta_k$\
be independent random variables, $M_1$, $M_2,\ldots,$\ $M_k$, $K_1$,
$K_2,\ldots,$\ $K_k\ge0$\ and $1\le p<\infty$. Suppose we have the
following
for each $n\in[k]$:
\cditem{i)}
$$ \Pr ( \lmod \Theta_n \rmod > K_n ) \ge \invc \invsqrtk, $$
\cditem{ii)}
$$ \E ( \lmod \Theta_n \rmod^p )^\invp \ge \invc M_n , $$
\smallskip
\cditem{iii)}
$$ K_n \le \,c\, \sqrtlogk M_n .$$
\moreproclaim\noindent
Then
$$ \left( \E \supTheta^p) \right)^\invp \ge \invc \invsqrtp \normKnLpk
. $$
 
\Proof Suppose, first, that $K_1\le K_2\le\ldots\le K_k$. From the
above
arguments we see that if $\Kkmsqrtk^p \ge \half \normKnLpk^p$, then
we are done. Furthermore the theorem is easy to prove when $k<16$.
So let
us assume that none of these hold.
 
First we show that
$$ \lnorm (K_n)_{n=k-\sqrt{k}}^k \rnorm_{L_p^k}^p \ge \quarter \normKnLpk^p
.$$
For, we have
$$ {1\over k-\sqrt k} \sum_{n=1}^{k-\sqrt k} K_n^p
   \le {1\over 2k} \sum_{n=1}^k K_n^p ,$$
which implies
$$ {1\over k-\sqrt k} \sum_{n=k-\sqrt k}^k K_n^p
   \ge \left( {1\over k-\sqrt k} - {1\over 2k} \right) \sum_{n=1}^k
K_n^p ,$$
which, as $k\ge16$, gives the result.
 
So to prove the theorem, we see that
$$ \eqalignno{
   \E \supTheta^p &\ge \E \left( \invsqrtk \sum_{n=k-\sqrt{k}}^k
\lmod
                       \Theta_n \rmod^p \right) \cr
   &\ge c^{-p} \invsqrtk \sum_{n=k-\sqrt{k}}^k M_n^p \cr
   &\ge c^{-p} {1\over \sqrt{k}(\logk)^{\potwo}} \sum_{n=k-\sqrt{k}}^k
K_n^p
        \cr
   &\ge c^{-p} {\sqrt{k}\over (\logk)^{\potwo}} \invk \sumnk K_n^p.
\cr }$$
Since
$$ {\sqrt{k}\over(\logk)^{\potwo}} \ge {1\over(cp)^{\potwo}} \quad
   \hbox{for all $k\ge1$,} $$
the result follows.
\endproof
 
\vfill
\eject
 
\beginsection 6) The Averaging Argument in the Bernoulli Case
 
Here we prove Theorem~0.2.
The arguments here take up the process
we followed in Section~4.3. Once again,
we first illustrate the argument in the
cyclic case. However the non-cyclic case
contains many more difficulties, which we elaborate on later.
 
As in Section~4.3, we work with a parameter $\beta$, which will be a
number, usually greater than $\half$\ (we will indicate at what point this
limitation is necessary). To save much
writing, as in Section~1A:1.1, we will
write $c_\beta$\ to denote the phrase `a continuous function of
$\beta\in(\half,\infty)$, taking positive real values'.
 
The cyclic case is as follows.
 
\proclaim Proposition 6.1. Let $x$\ be
cyclic on $a$. If $W_k$\ is the weighting
equal to $\ds\invklogk$\ then
$$ \sumkN W_k \E \supBernsigmakx \ge \invc \norma_{2,1}.$$
 
\Proof By Theorem~5.2, we have
$$ \E \supBernsigmakx \ge \invc K(\asubNok,\sqrtlogk\noneatwo).$$
Now we use the duality given in Proposition~1A:2.8. Let
$$ w^k(n) = \cases{
   \ds{\invsqrtn \left({\logk\over\logNon}\right)^\beta}
& for $n\le N/k$ \cr
                  &                \cr
   0
                 & otherwise.    \cr}$$
Then $ J\bigl(w^k,\invsqrtlogk\ninfatwo\bigr) \le c (1\v\sqrttbmo)$\ for
$\beta>\smallhalf$. So
$$ K\bigl(\asubNok,\sqrtlogk\noneatwo\bigr)
\ge \invc_\beta \sumN w^k(n) a(n).$$
Now the argument proceeds as in the proof of Proposition~4.7.
\endproof
 
In the non-cyclic case, we use a duality
argument as in Section~4.3. However,
whereas in Section~4.3 we use Proposition~3.1 with $p=2$, here we need to
use Theorem~5.4 with $p>2$\ (we will indicate when this
is needed). So for the rest of Section~6, we fix $p=3$,
and $p'={3\over2}$\ so that $\invp+\invpp=1$.
 
\proclaim Proposition 6.2. Let
$\lnorm\widecdot\rnormE$\ be a norm on $\CNS$\
defined by
$$ \lnorm x \rnormE = \supkN \supNk \left( \AvokN K(
   \xsigmanunn,\sqrtlogk\noneatwo)^p \right)^\invp ,$$
and let $\lnorm\widecdot\rnormEdual$\ be its dual norm with respect to the
duality
$$ \langle w,x \rangle = \sumS \sumN w_s(n) x_s(n).$$
Then
$$ \lnorm w \rnormEdual = \inf \lbrace \sumkN \sumNk k \left(
   \AvokN J(\wnusigmanunn,\invsqrtlogk\ninfatwo)^\pp \right)^\invpp
   \rbrace ,$$
where the infimum is over the set
$$ \lbrace \, (w^\nu\in\CNS)_{\nu\in\Nk,k\in[N/3]}
   : \supp w^\nu \subseteq \sigma(\nu),\, \sum_\nu w^\nu\ge w
   \rbrace .$$
 
\Proof As Proposition~4.8.
\endproof
 
As in Section~4.2, we let $w\in\CNS$ be given by
$$ w_s(n) = \overline{\sign(x_s(n))} \invsqrtpi u_s, \eqno (6.1) $$
where $u_2=\lnorm x_s \rnormtwoone \Bigg/
\rmsxstwoone$, and note that it is
sufficient to prove the following.
 
\proclaim Proposition 6.3. If $w\in\CNS$\
is the vector given by $(6.1)$, then
$$ \lnorm w \rnormEdual \le c \sqrt{N} \lm\lm N .$$
 
\beginsection 6.1) The Proof of Proposition 6.3
 
This proof is long and involved, and so it is split up into several steps.
It is presented roughly in the order in which I thought of it, that is,
as a sequence of attempts to prove the
result, each successive attempt being
more refined than the previous attempt, until eventually the result is
established. At the end, I shall recap briefly, indicating where the main
thread of the `correct' argument may be found.
 
The main motivating example will be when all the $x_s$s have the same
$L_{2,1}$\ norm, that is, when
$u_1=u_2=\ldots=u_S = \invsqrtS$. These examples
will be presented in `preludes to steps'.
Thus, for example, Step~5 will be
illustrated with this example in Prelude to Step~5.
 
\tstep 1: Setting the Scene
 
Since $\normdot_E$\ is a lattice norm, we may assume that $w\ge0$. We are
required to find a sequence
$(w^\nu)$\ that satisfies the required properties:
$$ \sum_\nu w^\nu \ge \invc w, \leqno \rm i) $$
and
$$ \sumkN \sumNk  k \left( \AvokN
J(\wnusigmanunn,\invsqrtlogk\ninfatwo)^\pp
   \right)^\invpp \le c \sqrt{N} \lm\lm N. \leqno \rm ii) $$
It is easy to see that showing (ii) is equivalent to showing both of
$$ \sumkN \sumNk \kosqrtlogk \left( \AvokN \normwnusigmanunn_2^\pp
   \right)^\invpp \le c \sqrt{N} \lm\lm N, \leqno \rm ii')$$
and
$$ \sumkN \sumNk k \left( \AvokN
\normwnusigmanunn_\infty^\pp \right)^\invpp
   \le c \sqrt{N} \lm\lm N. \leqno \rm ii'')$$
 
\tstep 2: The First Guess at $(w^\nu)$
 
For the rest of this section, we set $ W_k = \ds\invklogk $\
(so that $\sumkN W_k \approx \lm\lm N$).
Let us first consider the $w^\nu$\ considered in Section~4, that is,
let
$$ w^{(k)}_s(n) = w_s(n) W_k \invkoNmNk \logkologNopi^\beta ,$$
and for $\nu\in\Nk$, let
$$ w^\nu_s(n) = \cases{
   w^{(k)}_s(n) & if $s\in\sigma_n(\nu)$ \cr
                &                        \cr
   0            & otherwise. \cr }$$
 
\tstep 3: Establishing Conditions (i) and (ii${}'$)
 
Condition~(i) holds, exactly as in the proof of Proposition~4.9.
To show (ii${}'$), we note
that the quantity
$$\left(\AvokN \lnorm \wnusigmanunn \rnorm_2^\pp \right)^\invpp $$
is a $L_\pp$\ average (because only at most $k$\ of the
terms $\lnorm\wnusigmanunn\rnorm_2$\ are
non-zero), and hence, by H\"older's
inequality, it dominates
$$\left(\AvokN \lnorm\wnusigmanunn\rnorm_2^2\right)^\half.$$
Hence condition~(ii${}'$) also holds as in the proof of Proposition~4.9.
 
\tstep 4: Setting the Scene for Condition (ii${}''$)
 
Condition~(ii${}''$) is quite different. We have the following chain of
inequalities. The quantity
$$ \sumkN \sumNk k \left(\AvokN \normwnusigmanunn_\infty^\pp
   \right)^\invpp $$
is, by H\"older's inequality, less than
$$ \sumkN k \mNk \left( \AvNk \AvokN \lnorm \wnusigmanunn
   \rnorm_\infty^\pp \right)^\invpp. $$
With a bit of thought, we see that this is at most
$$ \sumkN k \mNk \left( \AvN \lnorm
w_{\rho_{n,k}}^{(k)}(n) \rnorm_\infty^\pp
   \right)^\invpp , \eqno (6.2) $$
where $\rho_{n,k} = \cupNk \sigma_n(\nu)$. This, in turn, is dominated by
$$ \sumkN k \mNk \left( \AvN
\bigl(w_{s_{n,k}}^{(k)}(n)\bigr)^\pp \right)^\invpp $$
for some $s_{n,k} \in \rho_{n,k}$. This is the same as
$$ N^\invp \sumkN W_k \left( \sumN \left( u_{s_{n,k}}
   {1\over\sqrt{\pi_{s_{n,k}}(n)}}
   \left({\logk\over\lm(N/\pi_{s_{n,k}}(n))}\right)^\beta \right)^\pp
   \right)^\invpp ,$$
and this is less than
$$ N^\invp \sumkN W_k M_k^\invpp, \eqno (6.3) $$
where $M_k$\ is the sum of the $N$\ largest elements of
$$ \left(\,
   \left(u_s\invsqrtn\left({\logk\over\logNon}\right)^\beta\right)^\pp :
   1\le s\le S,1\le n\le N \right) .$$
So in considering condition~(ii${}''$),
we will concentrate on the quantity
$(6.3)$.
 
\tpreludetostep 5: Attempting to Establish Condition (ii${}''$)
 
So consider the case when
$u_1=u_2=\ldots=u_S=\invsqrtS$. For
sufficiently large $n$\ (depending only on
$\beta$), the quantity $\sqrt n (\logNon)^\beta
$\ increases as $n$\ increases.
Thus it is easy to see that $M_k$ is dominated
by
$$ \eqalignno{
   &\phantom{=} c_\beta\, S\, \sum_{n=1}^{N/S} \left(\invsqrtS \invsqrtn
   \left({\logk\over\logNon}\right)^\beta\right)^\pp & (6.4) \cr
   &\le c_\beta N^{1-\ppotwo}
\left({\logk\over\lm S}\right)^{\beta\pp} .\cr}$$
Hence, the right hand side of
(ii${}''$) is dominated by
$$ c_\beta \sqrt N \left(\lm N\over \lm S\right)^\beta .$$
Remembering that we insist that $\beta>\half$\
(for (ii${}'$) to work), we see
that, unless $S$\ is large (a power of $N$), we do not get the desired
result.
 
We also have our first indication that
we require $p>2$. For if we had $p=2$,
then $(6.4)$\ would be dominated only by
$$ c_\beta {(\lm k)^{2\beta}\over(\lm S)^{2\beta-1}} ,$$
and so the right hand side of (ii${}''$) would be dominated by
$$ c_\beta \sqrt N {(\lm N)^\beta \over (\lm S)^{\beta-1}} .$$
Even if $S$\ were a power of $N$, this
would be too big by a factor $\sqrt{\lm
N}$.
 
\tstep 5: Attempting to Establish Condition (ii${}''$)
 
The above suggests that if $\supS u_s$\ is small, then we
should get something reasonable. This is the case, as the following result
shows.
 
\proclaim Lemma 6.4. Let $M$\ be the sum
of the $N$\ largest elements of the set
$$ \left(\, \left(u_s \invsqrtn
   \left({\logk\over\logNon}\right)^\beta\right)^\pp
   : 1\le s\le S, 1\le n\le N \right) ,$$
where $\uS\ge0$\ with $\sumS u_s^2 =1$. If $\supS u_s\le\invsqrtK$\ then
$$ M \le c\, N^{1-\ppotwo} \left({\logk\over\logK}\right)^{\beta\pp} .$$
 
\Proof First note that
$\sqrt n \, (\logNon)^\beta$\ increases with $n$, for $n$\ large enough
(depending on $\beta$). Therefore
$M$\ must have the form given by
$$ M = (\logk)^{\beta\pp} \sumS u_s^{p'} f(d_s),$$
where
$$ \eqalignno{
   f(d) &= \sum_{n=1}^d \left( {1\over\sqrt n
\bigl(\logNon\bigr)^\beta} \right)^\pp \cr
   &\le c_\beta {d^{1-\ppotwo} \over (\lm(N/d))^{\beta\pp}} \cr }$$
and $d_1$, $d_2,\ldots$, $d_S$\ are non-negative integers such that
$ \sumS d_s = N$.
(If we had $p=2$, the last line would only be $c_\beta
{1\over(\lm(N/d))^{2\beta-1}}$, which
would lose a factor $\sqrt{\lm K}$\ in
the final result.)
Also notice that, as $f$\ is approximately equal to a sum of a decreasing
sequence,
it must be approximately equal to a concave
function (here the constants of approximation depend on $\beta$\ only).
 
From the duality described in Proposition~1A:2.8 we have
$$ \sumS u_s^\pp f(d_s) \le
   J\Bigl( (u_s^\pp) ,K^\ppotwo,
\normdot_{2\over \pp}, \normdot_\infty \Bigr)
   \cdot K\Bigl( (f(d_s)) ,K^{-\ppotwo}, \normdot_r, \normdot_1 \Bigr), $$
where ${1\over r}+\ppotwo = 1$.
The first term is easy, as the hypotheses of the lemma say
$$ J\Bigl( (u_s^{p'}), K^\ppotwo,
\normdot_{2\over\pp}, \normdot_\infty \Bigr)
   \le 1.$$
For the second term, suppose without loss of generality that
$ d_1\ge d_2\ge\ldots\ge d_S$.
Then
$$ K\Bigl( (f(d_s)), K^{-\ppotwo}, \normdot_r, \normdot_1 \Bigr)
   \le K^{-\ppotwo} \normo{(f(d_s))_{s=1}^K}_1
   + \normo{(f(d_s))_{s=K+1}^S}_r .$$
By Jensen's inequality we have
$$ \normo{(f(d_s))_{s=1}^K}_1 \le K f(N/K)
   \le c\, K^\ppotwo {N^{1-\ppotwo} \over (\lm K)^{\beta\pp}} .$$
Also, a simple argument shows that if $s>K$ then $d_s\le N/K$. Hence
$$ \eqalignno{
   \normo{(f(d_s))_{s=K+1}^S}_r^r
   &\le c_\beta \sum_{s=K+1}^S
   \left( {d_s^{1-\ppotwo} \over (\lm(N/d_s))^{\beta\pp} }\right)^r \cr
   &\le {1\over (\lm K)^{\beta rp'}} \sumS d_s \cr
   &= {N\over(\lm K)^{\beta rp'}} . \cr } $$
The result follows.
\endproof
 
So, if $\supS u_s \le \invsqrtK$, then
$$ N^\invp \sumkN W_k M_k^\invp \le \sqrt N
   \left({\lm N\over\logK}\right)^\beta ,$$
and we have established a weaker form of condition~(ii${}''$). Thus
for $\beta>\half$, we have
$$ \E \Bernwalk \ge \invc_\beta \left(\lm\lm N + \left({\lm N\over\lm
   K}\right)^\beta \right)^{-1} \rmsxsLtwoone .$$
 
\tstep 6: Our First Non-trivial Result about Rademacher Cotype
 
We now have sufficient to obtain our first non-trivial result about the
Rade\-macher cotype of bounded linear operators from $C(K)$.
 
\proclaim Theorem 6.5. Let $T$\ be the formal identity $l_\infty^N
\hookrightarrow L_{2,1}^N$. Then for $\beta>\half$, we have
$$ R^2(T) \le c_\beta \left(\sqrt{\lm K} \lm\lm N +
   \left({\lm N\over\lm K}\right)^\beta \right) .$$
In particular, if we set $K=N^{(\log N)^{1/2}}$, we obtain
$$ R^2(T) \le C_\delta (\lm N)^{\quarter+\delta} ,$$
where $C_\delta$\ depends on $\delta>0$\ only.
 
\Proof Let $[S]=\cS_1\cup\cS_2$, where
$$ \eqalignno{
   \cS_1 &= \{\,s\in[S]:u_s\le\invsqrtK\} , \cr
   \cS_2 &= \{\,s\in[S]:u_s>  \invsqrtK\} . \cr } $$
From the above, we see that
$$ \E\lnorm\sum_{s\in\cS_1} \varepsilon_s x_s \rnorm_\infty
   \ge \invc_\beta \left(\lm\lm N + \left({\lm N\over \lm K}\right)^\beta
   \right)^{-1} \left(\sum_{s\in\cS_1} \lnorm x_s \rnorm^2_{L_{2,1}^N}
   \right)^\half .$$
Also, by Proposition~1C:4.2(ii) and
Theorem~0.3 (and noting that $\lmod\cS_2\rmod \le K$) we have
$$ \eqalignno{
   \E\lnorm\sum_{s\in\cS_2} \varepsilon_s x_s \rnorm_\infty
   &\ge \invc {1\over\sqrt{\lm\lmod\cS_2\rmod}}
   \E\lnorm\sum_{s\in\cS_2} \gamma_s x_s \rnorm_\infty \cr
   &\ge \invc {1\over\sqrt{\lm K}}
   \invloglogN
   \left(\sum_{s\in\cS_2} \lnorm x_s
\rnorm_{L_{2,1}^N}^2 \right)^\half .\cr}$$
Now we argue as follows.
$$ \eqalignno{
   \E\Bernwalk
   &= \half\left(
   \E\lnorm\sum_{s\in\cS_1} \varepsilon_s x_s
           +\sum_{s\in\cS_2} \varepsilon_s x_s \rnorm_\infty
      \right. \cr
   &\phantom{=\half}\left. +
   \E\lnorm\sum_{s\in\cS_1} \varepsilon_s x_s
           -\sum_{s\in\cS_2} \varepsilon_s x_s \rnorm_\infty
      \right) \cr } $$
$$ \ge \half \max\left\{
   \E\lnorm\sum_{s\in\cS_1} \varepsilon_s x_s \rnorm_\infty ,
   \E\lnorm\sum_{s\in\cS_2} \varepsilon_s x_s \rnorm_\infty \right\} $$
$$ \eqalign{
   \ge \invc
   & \left( \sqrt{\lm K} \lm\lm N + \left({\lm N\over\lm K}\right)^\beta
   \right)^{-1} \cr
   & \quad\quad \max\left\{
   \left( \sum_{s\in\cS_1} \lnorm x_s \rnorm_{L_{2,1}^N}^2 \right)^\half ,
   \left( \sum_{s\in\cS_2} \lnorm x_s \rnorm_{L_{2,1}^N}^2 \right)^\half
   \right\} \cr}$$
$$ \ge \invc
   \left( \sqrt{\lm K} \lm\lm N + \left({\lm N\over\lm K}\right)^\beta
   \right)^{-1}
   \rmsxsLtwoone $$
as desired.
\endproof
 
This result is certainly good enough to show Corollary~1C:5.2a.
 
\tstep 7: The Second Guess at $(w^\nu)$
 
However, we can do better than this. Suppose
in equation $(6.1)$\ that we could say
that $\rho_{n,k} \subseteq \{\,s:u_s\le\invsqrtk\}$.
Then Lemma~6.4 would give
$M_k\le c N^{1-\ppotwo}$, which would easily be sufficient. This could be
achieved by insisting that $w^{(k)}_s(n) = 0$\ if
$u_s>\invsqrtK$. However, we then have to modify the other values of
$w^{(k)}_s(n)$\ so that (i) still holds.
Let
$$ w^{(k)}_s(n) = \cases{
   \ds{w_s(n) W_k \invkoNmNk
\logkologNopiwinvust^\beta} &f $u_s\le\invsqrtk$ \cr
                                                         & \cr
   0
                 & otherwise, \cr } $$
and define $w^\nu$\ from $w^{(k)}$\ as before:
$$ w^\nu_s(n) = \cases{
   w_s^{(k)}(n) &if $s\in\sigma_n(\nu)$ \cr
                &                       \cr
   0            &otherwise.             \cr }$$
 
\tstep 8: Establishing Conditions (i) and (ii${}''$)
 
The argument for showing (i) is almost exactly as in
the proof of Proposition~4.9:
$$ \eqalignno{
   &\phantom{=} \sumkN \sumNk w_s^\nu(n) \cr
   &= w_s(n) \sum_{k=1}^{N\w(\invust)} W_k \invkoNmNk \cr
   &\quad\quad \logkologNopiwinvust^\beta \mnuinsigma \cr
   &\ge w_s(n)
   \sum_{k=1}^{(N/\pi_s(n))\w(\invust)}W_k\logkologNopiwinvust^\beta \cr
   &\approx \invc_\beta w_s(n) . \cr } $$
Also condition~(ii${}''$) follows very much as in Step 4.
We see that the quantity
$$ \sumkN \sumNk k \left( \AvokN \normwnusigmanunn_\infty^\pp
   \right)^\invpp $$
is dominated by
$$ N^\invp \sumkN W_k M_k^\invpp , $$
where $M_k$\ is the sum of the $N$\ largest elements of
$$ \left(\, \left( u_s \invsqrtn \logkologNonwinvust^\beta\right)^\pp
   : 1\le s\le S, 1\le n\le N, u_s\le\invsqrtk \right). $$
Then condition~(ii${}''$) follows from the next lemma.
 
\proclaim Lemma 6.6. Let $M_k$\ be the quantity just described. Then
$$ M_k \le c_\beta N^{1-\ppotwo} .$$
 
\Proof This follows as Lemma~6.4, with only a very few changes.
\endproof
 
\tstep 9: Setting the Scene for Condition (ii${}'$)
 
However condition~(ii${}'$) is now much
more difficult to prove. First let us
establish the preliminary inequalities,
so that we may identify more easily
where the difficulties lie. The quantity
$$ \sumkN \sumNk \kosqrtlogk \left( \AvokN \normwnusigmanunn_2^\pp
   \right)^\invpp $$
is, by H\"older's inequality, less than
$$ \sumkN \kosqrtlogk \mNk \left( \AvNk \AvokN \normwnusigmanunn_2^\pp
   \right)^\invpp $$
$$ = N \sumkN W_k \invsqrtlogk \left( \AvNk \AvokN \left(
   \sumss{s\in\sigma_n(\nu)}{u_s\le\invsqrtk} V(s,n,k)^2 \right)^\ppotwo
   \right)^\invpp ,$$
where $ V(s,n,k) = w_s(n)
\ds{\logkologNopiwinvust^\beta} $. This in turn is
dominated by
$$ N \sumkN W_k \invsqrtlogk \left( \AvN \left( \sum_{s\in\sigma_{n,k}}
   V(s,n,k)^2 \right)^\ppotwo \right)^\invpp , \eqno (6.5) $$
where $\sigma_{n,k} = \{\,s:\pi_s(n)\le
N/k \hbox{ and } u_s\le\invsqrtk \}$.
It is the quantity $(6.5)$ that we will concentrate on.
 
\tpreludetostep 10: Establishing Condition (ii${}'$)
 
We illustrate the
arguments required in the case
$u_1=u_2=\ldots=u_S=\invsqrtS$. Now quantity
$(6.5)$\ becomes
$$ N \sumkNwS W_k \invsqrtlogk \left( \AvN \left( \sumpis V(s,n,k)^2
   \right)^\ppotwo \right)^\invpp . \eqno (6.6) $$
Now, this quantity is
the sum of a $L_\pp$\ average of a $l_2$\ sum. Our first attempt is to
dominate this by a sum of a $L_2$\ average of
a $l_2$\ sum, to get
$$ N \sumkNwS W_k \invsqrtlogk \left(
\AvN \sumpis V(s,n,k)^2 \right)^\half $$
$$ \approx \sqrt N \sumkNwS W_k \invsqrtlogk \left( \sumS u_s^2 \sumNok
   \invn \left({\logk\over\lm((N/n)\w S)}\right)^{2\beta} \right)^\half,
   \eqno (6.7) $$
where $\sumS u_s^2 = 1$. Now, the innermost sum evaluates to
$$ \sum_{n=1}^{N/S} \invn \left({\logk\over\lm S}\right)^{2\beta}
   + \sum_{n=N/S+1}^{N/k} \invn
\left({\logk\over\logNon}\right)^{2\beta} $$
$$ \labelledapprox{c_\beta} (\lm N/S)
\left({\logk\over\lm S}\right)^{2\beta}
   + (\logk)^{2\beta}
   - (\lm S) \left({\logk\over\lm S}\right)^{2\beta} .$$
If $S$\ is, for example, $1$, then this
is approximately equal to $\sqrt{\lm N}$,
and the quantity $(6.7)$\ is dominated
only by $\sqrt N \sqrt{\lm N}$, and the
attempt has failed. (Thus we
have another indication that we need $p>2$).
 
The solution is to dominate the $L_\pp$\ average of the $l_2$\ sum by an
$L_\qk$\ average of an $l_\qk$\ sum,
where $\qk$\ depends on $k$\ only, and
$\pp\le\qk\le2$. Then $(6.6)$\ becomes
$$ N^{\ominvqk} \sumkNwS W_k \invsqrtlogk \left( \sumS u_s^\qk \sumNok
   \invnqkotwo \left({\logk\over\lm((N/n)\w S)}\right)^{\qk\beta}
   \right)^\invqk .$$
Now it is sufficient to note that
\item{a)} for $n\le N/k$\ we have $\lm((N/n)\w S) \ge \lm k$;
\item{b)} by H\"older's inequality we have
$$ \left(\sumS u_s^\qk\right)^\invqk \le S^{\invqkmhalf} \left(\sumS u_s^2
   \right)^\half \le S^{\invqkmhalf} ;$$
\ditem{c)}$ \sumNok \invnqkotwo \le c \left(\invqk-\half\right)^{-1}
            (N/k)^{\omqkotwo}$.
 
\noindent
Thus the above is dominated by
$$ c \sqrt N \sumkNwS W_k \invsqrtlogk (S/k)^{\invqkmhalf}
   \left(\invqk-\half\right)^{-\invqk} . $$
Now let $\qk$\ be such that
$\invqk-\half\approx{1\over\lm S}$. Then this is
approximately less than
$$ \sqrt N \sqrt{\lm S} \sumkNwS W_k \invsqrtlogk
   \le c \sqrt N \left({\lm S\over\lm(N\w S)}\right)^\half ,$$
and we are done in the case when all
the $u_s$s are the same, and $S\le N$.
 
\tstep 10: Establishing Condition (ii${}'$)
 
Now we come to what is probably the most difficult part of the thesis.
We give the complete argument for when the $u_s$s are different.
This argument is essentially batching
together the $u_s$s that are roughly the
same size. Our starting point is the
quantity $(6.5)$. To save space, we will
write
$$ V'(s,n) = {V(s,n,k) \over (\lm k)^\beta }
           = w_s(n) {1\over(\logNopiwinvust)^\beta} .$$
First, we split the outer sum of $(6.5)$\ to get
$$ \eqalignno{
   &
   N \sumlloglogN \sum_{m=e^{l-1}}^{e^l-1} \sum_{k=e^{m-1}}^{e^m-1}
   W_k \invsqrtlogk
   \left( \AvN \left( \sum_{s\in\sigma_{n,k}}
   V(s,n,k)^2 \right)^\ppotwo \right)^\invpp \cr
   &=
   N \sumlloglogN \sum_{m=e^{l-1}}^{e^l-1} \sum_{k=e^{m-1}}^{e^m-1}
   {(\logk)^{(\beta-\half-1)} \over k}
   \left( \AvN \left( \sum_{s\in\sigma_{n,k}}
   V'(s,n)^2 \right)^\ppotwo \right)^\invpp \cr
   &\le
   c \,N \sumlloglogN \sum_{m=e^{l-1}}^{e^l-1} m^{(\beta-\half-1)}
   \left( \AvN \left( \sum_{s\in\sigma_{n,e^{m-1}}}
V'(s,n)^2 \right)^\ppotwo
   \right)^\invpp \cr
   &\le
   c_\beta\, N \sumlloglogN e^{l(\beta-\half)} \left( \AvN \left(
   \sum_{s\in\sigma_{n,\exp(e^{l-1}-1)}} V'(s,n)^2 \right)^\ppotwo
   \right)^\invpp .\cr}$$
Now, let $\tau_{n,l}=\sigma_{n,\exp(e^{l-1}-1)} \setminus
\sigma_{n,\exp(e^l-1)}$, so that $\sigma_{n,\exp(e^{l-1}-1)} =
\bigcup_{l'=l}^{\lm\lm N} \tau_{n,l'} $.
Then by the triangle inequality for the
$L_\pp$\ and $l_2$\ norms, the above is approximately less than
$$ N \sumlloglogN e^{l(\beta-\half)}
\sum_{l'=l}^{\lm\lm N} \left( \AvN \left(
   \sum_{s\in\tau_{n,l'}} V'(s,n)^2 \right)^\ppotwo \right)^\invpp $$
which, rearranging sums, is the same as
$$ N \sum_{l'=1}^{\lm\lm N}
\sum_{l=1}^{l'\w\log(1+\log(1+N))} e^{l(\beta-\half)}
   \left( \AvN \left( \sum_{s\in\tau_{n,l'}} V'(s,n)^2 \right)^\ppotwo
   \right)^\invpp . \eqno (6.8) $$
The inner sum is given by
$$ \sum_{l=1}^{l'\w\log(1+\log(1+N))} e^{l(\beta-\half)}
   \labelledapprox {c_\beta} e^{l'(\beta-\half)} . \eqno(6.9)$$
So now we will concentrate on the term
$$ \left( \AvN \left( \sum_{s\in\tau_{n,l'}} V'(s,n)^2 \right)^\ppotwo
   \right)^\invpp . \eqno(6.10) $$
First note that if $s\in \tau_{n,l'}$, then
$$ \logNopiwinvust \ge \invc e^{l'} ,$$
and so $(6.10)$\ is dominated by
$$ c_\beta e^{-\beta l'}
   \left( \AvN \left( \sum_{s\in\tau_{n,l'}}
   \bigl(w_s(n)\bigr)^2 \right)^\ppotwo
   \right)^\invpp . $$
Now
$$ \eqalignno{
   & \left( \AvN \left( \sum_{s\in\tau_{n,l'}}
   \bigl(w_s(n)\bigr)^2 \right)^\ppotwo
   \right)^\invpp \cr
   \le & \left( \AvN \left( \sum_{s\in\tau'_{n,l'}}
   \bigl(w_s(n)\bigr)^2 \right)^\ppotwo
   \right)^\invpp & (6.11) \cr
   &+ \left( \AvN \left( \sum_{s\in\tau''_{n,l'}}
   \bigl(w_s(n)\bigr)^2 \right)^\ppotwo
   \right)^\invpp , & (6.12) \cr} $$
where
$$ \tau'_{n,l'}
   = \left\{\, s :
   \matrix{
   \ds{{N \over \exp(e^{l'}-1)} \le
\pi_s(n) \le {N \over \exp(e^{l'-1}-1)}}
   \cr
   \hbox{and }
   \ds{u_s^2 \le {1 \over \exp(e^{l'-1}-1)}} \cr}
   \right\} , $$
and
$$ \tau''_{n,l'}
   = \left\{\, s :
   \matrix{
   \ds{\pi_s(n) \le {N \over \exp(e^{l'-1}-1)}}
   \hbox{ and} \cr
   \ds{{1 \over \exp(e^{l'}-1)} \le u_s^2
\le {1 \over \exp(e^{l'-1}-1)}} \cr}
   \right\} , $$
so that $\tau_{n,l'} = \tau'_{n,l'} \cup \tau''_{n,l'} $.
 
First we estimate $(6.11)$. We dominate
the $L_\pp$\ average of the $l_2$\ sum
by a $L_2$\ average of a $l_2$\ sum:
$$ \eqalignno{
   &\phantom{=} \left( \AvN \sum_{s\in\tau'_{n,l'}}
   u_s^2 \invpi \right)^\half \cr
   &= \left( \invN \sumS u_s^2
   \sum_{n\colon s\in\tau'_{n,l'}} \invpi \right)^\half \cr
   &\le \left( \invN \int_{N/\exp(e^{l'}-1)}^{N/\exp(e^{l'-1}-1}
   (1/t) \,dt \right)^\half \cr
   & \cr
   &\le \ts\invsqrtN e^{\half l'} .\cr}$$
 
Next, we dominate $(6.12)$\ by a $L_q$\
average of a $l_q$\ sum, where $q$,
depending on $l'$\ only, is such that $p'\le q\le2$, to get
$$ \eqalignno{
   &\phantom{=} \left( \AvN \sum_{s\in\tau'_{n,l'}}
   u_s^q {1\over\bigl(\pi_s(n)\bigr)^\qotwo} \right)^\invq \cr
   &\le \left( \invN
   \ds{\left( \sumss{s=1}{u_s^2\ge\invexpexplp}^S u_s^q \right)}
   \left( \sumN {1\over n^\qotwo} \right)
   \right)^\invq \cr
   &\le \ts{\left( \invN
   \left( \exp(e^{l'}-1) \right)^{\left(1-\qotwo\right)}
   \ds{\left( \sumS u_s^2 \right)}
   \left(1-\qotwo\right)^{-1}
   (N+1)^{\left(1-\qotwo\right)}
   \right)^\invq} \cr
   &\le \ts{c \invsqrtN
   \exp\left(\left(\invq-\half\right)e^{l'}\right)
   \left(1-\qotwo\right)^{\left(\half-\invq\right)}
   \left(1-\qotwo\right)^{-\half}} .\cr}$$
Now choose $q$ so that $\invq-\half =
e^{-l'}$\ (and note that $q\approx2$).
Then this is dominated by
$$ \ts{ c \invsqrtN e \left(e^{-l'}\right)^{-e^{-l'}} e^{\half l'}
   \approx \invsqrtN e^{\half l'}} .$$
Hence $(6.10)$\ is dominated by $ c e^{l'(\half - \beta)} $.
 
Now we substitute this estimate for
$(6.10)$, and also $(6.9)$, into $(6.8)$,
and we see that $(6.8)$\ is approximately less than
$$ \sqrt N \sum_{l'=1}^{\lm\lm N} 1 \approx \sqrt N \lm\lm N ,$$
as desired. Hence condition~(ii${}'$) follows.
 
\tstep 11: Cry Victory!
 
Thus Proposition~6.3 is proved. Now we
will recap the main steps, picking out
the `correct' argument. First of all, in
Step~1, we establish three conditions,
called (i), (ii${}'$) and (ii${}''$), that a suitable sequence
$\bigl(w^\nu\in\CNS\bigr)$\ has to
satisfy. We choose the sequence in Step~7.
Condition~(i) is easily shown in Step~8.
Condition~(ii${}''$) is established in
Steps~4 and~8 (with the help of Step~5).
Finally condition~(ii${}'$) is proved
in Steps~9 and~10.
\endproof
 
\vfill
\eject
 
\beginsection Chapter 2B --- A Discussion of the Methods of Chapter
2A
 
In this chapter, we look at the various methods used in Chapter~2A,
and see to
what extent they are the best we can do. We also modify the methods
to
find the cotype $2$\ constant of other operators from $l_\infty^N$.
 
\beginsection 1) The Reduction to Independent Processes
 
First we look at Theorem~2A:2.1. As we pointed out before, this result
seems
to throw away a lot of information. Indeed it is surprising that
we seem to
only pick up, at worst, a $\lm\lm N$\ factor. We compare this
theorem (in the Gaussian case) to other well known results that find
lower
bounds for suprema of Gaussian processes, specifically the theorems
of Sudakov
and Fernique. (There is also a recent theorem due to Talagrand, which
we
discuss in the next chapter.)
 
We avoid a few technicalities by only quoting the theorems for finite
Gaussian
processes, since that is all we are interested in.
First we introduce some definitions.
 
\proclaim Definition. Let $\Gamma=\Gammaproc$\ be a Gaussian process.
Define
the semi-metric $d = d_\Gamma$\ on $[N]$\ by
$$ d(n,m) = \left( \E \lmod \Gamma_n-\Gamma_m \rmod^2 \right)^\half
.$$
\moreproclaim
For $\epsilon>0$, let $\cN(\epsilon)$\ be the size of the largest
collection of
disjoint $d$-balls of radius $\epsilon$. (Thus $\cN(\epsilon)$\ is
a decreasing
integer valued function of $\epsilon$.)
\moreproclaim
We say that $\Gamma$\ is {\dt stationary} if there is a group operation
$\circ$\ on
$[N]$\ (not necessarily abelian) such that for $n,m,l\in[N]$\ we
have
$$ d(n,m) = d(n\circ l,m\circ l) .$$
 
\proclaim Theorem 1.1. (Sudakov, see [F 2.3.1].) Let $\Gamma=\Gammaproc$\
be a
Gaussian process. Then for any $S\subseteq[N]$\ we have
$$ \E\supGauss \ge \invc \sqrt{\log\modo S} \inf_{n\ne m\in[S]} d(n,m)
.$$
Thus
$$ \E\supGauss \ge \invc \sup_{\epsilon>0} \epsilon \,\sqrtlogNe
.$$
 
\proclaim Theorem 1.2. (Fernique, see [F 7.2.2] or [Ka Ch.15 \S5].)
Let $\Gamma=\Gammaproc$\ be a
stationary Gaussian process. Then
$$ \E\supGauss \ge \invc \int_0^\infty \sqrtlogNe \,d\epsilon .$$
 
Clearly Fernique's theorem implies Sudakov's theorem for stationary
processes.
 
\beginsection 1.1) The Cyclic Case
 
Here we shed light on the cyclic case using Sudakov's and Fernique's
theorems.
Sudakov's theorem doesn't give us any new information, it simply
allows us to
rederive the results we have. However Fernique's theorem shows us
why the
weighting $W_k=\ds\invklogk$, used so often in Chapter~2A, is correct.
 
When $x$\ is cyclic on $a$, Theorem~2A:2.1 states that
$$ \E \supGaussx \ge \ts\quarter \supkN \E \supGausssigmakx. \eqno(1.1)
$$
In Section~2A:4.2, we bounded this below by a $L_2$\ average, with
weighting
$W_k=\ds\invklogk$:
$$ \E\supGaussx \ge \invc \left(\invloglogN \sumkN W_k \left(
   \E \supGausssigmakx \right)^2 \right)^\half ,$$
and from this we obtained our result. However, in Section~2A:4.3,
we used an even
weaker lower bound, the $L_1$\ average with the same weighting:
$$c\E\supGauss \ge \invc \invloglogN \sumkN W_k \E \supGausssigmakx
.$$
With the help of Fernique's theorem we shall be able to derive the
same result without the
$\lm\lm N$\ factor.
 
To apply Sudakov's and Fernique's theorems, we need to
calculate $\cN(\epsilon)$. This requires the following technical
lemmas.
 
\proclaim Lemma 1.3. Let $x$\ be cyclic on $a$, and $x'$\ be cyclic
on $\asubNotwo$. Then
$$ \E \Gausswalk
   \le c \E \normo{\sumS \gamma_s x'_s}_\infty.$$
 
\Proof
$$ \eqalignno{
   \E \normo{\sumS \gamma_s x'_s}_\infty
   &\le \E \left( \sup_{1\le S_1\le S_2<S_3\le S_4\le S}
   \normo{ \sum_{s=S_1}^{S_2} \gamma_s x_s
           + \sum_{s=S_3}^{S_4} \gamma_s x_s}_\infty
   \right) \cr
   &\le 2 \E\left( \sup_{1\le S_1\le S_2\le S}
   \normo{\sum_{s=S_1}^{S_2} \gamma_s x_s}_\infty
   \right) ,\cr }$$
which by Lemma~2A:2.3, is
$$ \le 8 \E \Gausswalk .$$
\endproof
 
\proclaim Lemma 1.4. Suppose $x$\ is cyclic on $a$, where $a=\asubNotwo$.
Then
for $2\le k\le N$\ we have
$$ \cN\left(\normo{\asubNok}_2\right) \ge \ts\kotwo .$$
 
\Proof First notice that for $m\le N/2$, we have
$$ \eqalignno{
   d(1,m)
   &= d\bigl((n+1)\bmod N,(m+n)\bmod N\bigr) \cr
   &= \left(\sumN \modo{a(n)-a((n+m)\bmod N)}^2 \right)^\half . \cr}$$
Therefore $d(1,m)$\ is an increasing function of $m$, and also
$d(1,m)\ge\normo{a\big|_{[m]}}_2$. Now we may observe that if $2\le
k\le N$,
then $d(1,N/k)\ge\epsilon \Rightarrow \cN(\epsilon)\ge \kotwo $,
and the result
follows.
\endproof
 
Now we show how to derive $(1.1)$ from Sudakov's result. By Lemma~1.3,
we may
assume that $a=\asubNotwo$. Hence, by Lemma~1.4, we have
$$ \eqalignno{
   \E \supGaussx &\ge \sup_{2\le k\le N} \asubNoktwo \sqrt{\log(k/2)}
\cr
   &\approx \supkN \asubNoktwo \sqrtlogk . \cr}$$
Hence $(1.1)$\ follows from Proposition~2A:3.5.
 
Applying Fernique's theorem is not much harder.
 
\proclaim Proposition 1.5. Let $x$\ be cyclic on $a$, and $W_k=\ds\invklogk$.
Then
$$ \E\supGaussx \ge \invc \sumkN W_k \E \supGausssigmakx .$$
 
\Proof By Lemma~1.3 we may assume that $a=\asubNotwo$. Furthermore,
as $x$\ is
cyclic, $\Gamma(x)$\ is stationary with respect to the group structure
of
$\Z/N\Z$. So, by Lemma~1.4, we have
$$ \eqalignno{
   \int_0^\infty \sqrtlogNe \,d\epsilon
   &\ge \sum_{k=3}^N \sqrt{\log((k-1)/2)}
   \left(\normo{a\big|_{[N/(k-1)]}}_2 - \asubNoktwo \right) \cr
   &= \sum_{k=3}^N \left(\sqrt{\log(k/2)}-\sqrt{\log((k-1)/2)}\right)
   \asubNoktwo \cr
   &\approx \sumkN {1\over k\sqrt{\lm k}} \asubNoktwo . \cr }$$
Apply Proposition~2A:3.5, and the result follows.
\endproof
 
Thus Proposition~2A:4.7 provides us with the following corollary.
 
\proclaim Corollary 1.5a. Let $x$\ be cyclic. Then
$$ \E \Gausswalk \ge \invc \rmsxsLtwoone .$$
 
This suggests that Theorem~2A:2.1 may not be the best possible result.
 
\beginsection 1.2) Lack of Unconditionality of Processes
 
Here we look at Theorem~2A:2.1 in a completely different way, and
consider what
would be a natural generalization if it were true.
 
\proclaim False Conjecture. Let $\Gamma^{(i)} = (\,\Gamma_n^{(i)}
= \sumS
\gamma_s x_s^{(i)} : n\in[N] )$, where $i=1,2$, be two Gaussian processes
such
that for all $s\in[S]$\ we have
$|x_s^{(2)}| \le |x_s^{(1)}|$. Then
$$ \E \supN |\Gamma_n^{(2)}| \le c \E \supN |\Gamma_n^{(1)}| .$$
 
\noindent {\bf Counterexample:}
Let $S=2^N$, and for $n\in[N]$\ and $s\in[S]$, let
$$ x_s^{(1)}(n) = 1
   \quad\hbox{and}\quad
   x_s^{(2)}(n) = \hbox{$(n-1)$th binary digit of $s$} .$$
Then clearly
$$ \E \supN |\Gamma_n^{(1)}| \approx \sqrt N ,$$
but it follows straight away from Theorem~1.1 that
$$ \E \supN |\Gamma_n^{(2)}| \ge \invc \sqrt{\log N} \sqrt N .$$
\endproof
 
\vfill
\eject
 
\beginsection 2) The Averaging Arguments of Sections 4 and 6
 
In Section~4, we proved that
$$ \sup_\sigma \left(\E\supGausssigmax\right)
\ge \invc \invloglogN \rmsxsLtwoone ,$$
where the outer supremum is over all systems of strips $\sigma$.
Section~6 gave a similar result for
Bernoulli random variables. Our purpose
here is to show that this is a best possible result; we cannot remove the
$\lm\lm N$\ factor. We only do this in the Gaussian case, the Bernoulli
case then follows by Proposition~1C:4.1(i).
 
We are looking for vectors
$\xS\in l_\infty^N$\ such that
$$ \sup_\sigma \left(\E\supGausssigmax\right)
\le c \invloglogN \rmsxsLtwoone. \eqno (2.1) $$
We conduct our search amongst the cyclic
$x$, and so we look for conditions
for equality in
Propositions~2A:4.2 to~2A:4.5. Proving Proposition~2A:4.5 is just a simple
application of the Cauchy--Schwartz
inequality, and equality is granted when
$$ a(n) = \invsqrtnlogNon .$$
In the proof of Proposition~2A:4.4 all the
inequalities are actually approximate
identities. In the proof of Proposition~2A:4.3, we bound
a supremum below by a $L_2$\ average, and
we have approximate equality if all the $\ds{{1\over k\sqrt{\logk}}
\asubNoktwo}$\ are approximately the
same for all $k$. This is also granted
by the same $a$ as above. Thus we know where to look.
 
\proclaim Proposition 2.1. Let $x$\ be
cyclic on $\ds{a=\left(\,\invsqrtnlogNon :
n\in[N] \right)}$. Then $(2.1)$\ holds.
 
\Proof It is immediate that the right
hand side of $(2.1)$\ is approximately
equal to $1$. As for the left hand side, $\E\supGausssigmax$\ is maximised
when $\sigma$\ is a strip such that
$$ x_{\sigma_n}(n) = \hbox{some rearrangement of }
   \left({1\over\sqrt s(\lm(N/s))}\right)_{s=1}^{d_n} ,$$
where $d_1$, $d_2,\ldots$, $d_N$\ are
non-negative integers such that $\sumN
d_n = N$. It is easy to see that $\normo{x_{\sigma_n}(n)}_2 \approx
{1\over\sqrt{\lm(N/d_n)}} $, and hence, by Proposition~2A:3.5, we
have
\goodbreak
$$ \E\supGausssigmax
   \le c\,
   \normo{\left(\,{1\over\sqrt{\lm(N/d_n)}}\right)_{n=1}^N}_{\em(T^2)}
   \approx 1 .$$
\endproof
 
\vfill\eject
 
\beginsection 3) Cotype $2$\ Constants
of Other Operators from $l_\infty^N$
 
Here we consider the effect of choosing
weightings other than $W_k=\ds\invklogk$.
 
\proclaim Theorem 3.1. Let $0<\alpha<1$. Then
$$ G^2( l_\infty^N \hookrightarrow L_{T^2(\lm T)^\alpha,2}^N )
   \le c \ts{1\over\sqrt{\alpha(1-\alpha)}} .$$
 
\Proof Follow the proof of Proposition~2A:4.6
with the single exception of changing
$W_k$\ to $\ds{1\over k(\lm k)^{2-\alpha}}$.
\endproof
 
\proclaim Proposition 3.2. Let $1<q<2$, and $\twooq-1<\alpha<2$.
Then for all $a\in\C^N$\ we have
$$ \normo{a}_{L_{2,q}^N} \le
   \ts{\left({1\over\alpha-\twooq+1}\right)^{\left(\invq-\half\right)}}
   \normo{a}_{L_{T^2(\lm T)^\alpha,2}^N} .$$
 
\Proof Let $\pi$\ be an ordering permutation for $a$, and let
$\invr+\half=\invq$. Then by H\"older's inequality, we have
$$ \eqalignno{
   \normo a_{L_{2,q}^N}
   &\approx \invsqrtN \left( \sumN (\pi(n))^{\qotwo-1} \modo{a(n)}^q
   \right)^\invq \cr
   &\le \invsqrtN \left( \sumN {1\over \pi(n) (\lm(N/\pi(n)))^{r\alpha/2}}
   \right)^\invr
   \left( \sumN (\lm(N/\pi(n)))^\alpha \modo{a(n)}^2 \right)^\half \cr
   &\le c
   \ts{\left({1\over\alpha-\twooq+1}\right)^{\left(\invq-\half\right)}}
   \normo a_{L_{T^2(\lm T)^\alpha,2}^N} .\cr}$$
\endproof
 
\proclaim Corollary 3.1a. Let $1<q\le2$.
Then the formal identity $l_\infty^N
\hookrightarrow L_{2,q}^N$\ has its
Gaussian cotype $2$\ constant uniformly
bounded for all $N$.
 
\vfill
\eject
 
\beginsection Chapter 2C --- Applications of Talagrand's Theorem
 
In this chapter we prove the following result.
 
\proclaim Theorem 0.1. Let $\xS\in l_\infty^N$. Then
$$ \E\Gausswalk \ge \invc \left(\sumS\normo{x_s}_\LTtlmTt^2\right)^\half
.$$
 
\proclaim Corollary 0.1a. Let $\mu$\ be a Radon measure on a compact
topological
space $K$. Then the formal identity map $C(K) \hookrightarrow
L_\TtlmTt(K,\mu)$\ has Gaussian cotype $2$.
 
As a digression, this raises the following question, for which I
do not know
the answer.
 
\proclaim Question. Is it true that all \blo s $\TCKY$\ with cotype
$2$\ factor
as
$$ C(K) \hookrightarrow L_{T^2 \lm T,2} (K,\mu) \tonamed U Y ,$$
where $\mu$\ is some Radon probability measure on $K$, and $U$\ is
a bounded
operator?
 
However, for our purposes the following corollary is more important,
as it is
Theorem~1C:5.2(ii) restated.
 
\proclaim Corollary 0.1b. Let $\xS\in l_\infty^N$. Then
$$ \E\Gausswalk \ge \invc \invsqrtloglogN \rmsxsLtwoone .$$
 
In Section~2, we will investigate this corollary further,
investigating whether the $\sqrt{\lm\lm N}$\ factor
is necessary, and giving other necessary and sufficient conditions
for its
existence.
 
All the work of this chapter depends on a recent result due to Talagrand.
 
\proclaim Theorem 0.2. (see [T]) Let $\Gammaproc$\ be a Gaussian
process.
\item{i)} Let $V_1=\E\supGauss$.
\item{ii)} Let $V_2$\ be the infimum of
$$ \left( \sup_{t\in\N} \sqrtlogt \left(\E\modo{Y_t}^2
   \right)^\half\right)
   \left( \supN \sum_{t=1}^\infty \modalphatn \right) $$
over all Gaussian processes
$(\,Y_t:t\in\N)$\ and all collections of numbers
$(\,\alphatn:t\in\N,n\in[N])$\ such that
$ \Gamma_n = \sum_{t=1}^\infty \alphatn Y_t$.
\moreproclaim\noindent
Then $V_1 \approx V_2$.
 
If we rewrite this result for the Gaussian process we are interested
in, that is, $\Gamma_n=\sumS \gamma_s x_s(n)$\ (and set
$Y_t=\sumS \gamma_s y_t(s)$), we obtain the following corollary.
 
\proclaim Corollary 0.2a. For $\xS\in l^T_\infty$\ we have the
following.
\item{i)} Let
$$V_1=\E\Gausswalk .$$
\item{ii)} Let $V_2$\ be the infimum of
$$ \left( \sup_{t\in\N} \sqrtlogt \normo{y_t}_{l^S_2} \right)
   \normo{\sum_{t=1}^\infty \modo{\alpha_t}}_{l^N_\infty} $$
over all collections of numbers
$(\,y_t(s) : t\in\N,s\in[S])$\ and
$(\,\alphatn : t\in\N,n\in[N])$\ such that
$ x_s(n) = \sum_{t=1}^\infty \alphatn y_t(s)$.
\moreproclaim\noindent
Then $V_1 \approx V_2$.
 
\beginsection 1) The Gaussian Cotype $2$\ Constant of $l_\infty^N
\hookrightarrow \LTtlmTt$
 
In this section we establish Theorem~0.1. To aid us, we define the
following spaces.
 
\proclaim Definition. Let $A$, $Y$, $\tY$, $X_\TtlmTt$\ and $X_\TlmTo$\
be the
vector spaces
$$ \eqalignno{
   A &= \{\,(\alpha_t\in l^N_\infty)_{t=1}^\infty:
   \alpha_t=0 \hbox{ for all but finitely many } t\}, \cr
   Y &= \{\,(y_t\in l^S_2)_{t=1}^\infty:
   y_t=0 \hbox{ for all but finitely many } t\}, \cr
   \tY &= \{\,(y_t\in l^S_1)_{t=1}^\infty:
   y_t=0 \hbox{ for all but finitely many } t\}, \cr
   X_\TtlmTt &= \{\,(x_s\in \LTtlmTt)_{s=1}^S\}, \cr
   X_\TlmTo &= \{\,(x_s\in \LTlmTo)_{s=1}^S\}, \cr}$$
with norms
$$ \eqalignno{
   \normo{(\alpha_t)}_A &=
   \normo{\sum_{t=1}^\infty \modo{\alpha_t}}_\infty, \cr
   \normo{(y_t)}_Y &=
   \sup_{t\in\N} \sqrtlogt \normo{y_t}_{l_2^S}, \cr
   \normo{(\ty_t)}_{\tY} &=
   \sup_{t\in\N} (\logt) \normo{\ty_t}_{l_1^S}, \cr
   \normo{(x_s)}_{X_\TtlmTt} &=
   \left( \sumS \normo{x_s}_\LTtlmTt \right)^\half,  \cr
   \normo{(\tx_s)}_{X_\TlmTo} &=
   \left( \sumS \normo{\tx_s}_\LTlmTo \right)^\half . \cr }$$
For each $T\in\N$, define the subspaces of $Y$\ and $\tY$:
$$ \eqalignno{
     Y_T &= \{\, (  y_t)\in   Y :   y_t = 0 \hbox{ for $t>T$} \},
\cr
   \tY_T &= \{\, (\ty_t)\in \tY : \ty_t = 0 \hbox{ for $t>T$} \}.
\cr }$$
 
\proof of Theorem 0.1:
 
\Step 1 Let $m\colon A\times Y\to X_\TtlmTt$\ be the bilinear map
$$m((\alpha_t),(y_t)) = (x_s),$$
where $x_s = \left(\,\sum_{t=1}^\infty
\alphatn
y_t(s) : n\in[N] \right) $. Then by Corollary~0.2a, it follows that
Theorem~0.1
holds if and only if $m$\ is a bounded map for all $S$\ and $N$.
 
\Step 2 By Proposition~2A:2.10 it follows that, in order to calculate
$\normo
m$, it is sufficient to consider only those $(\alpha_t)$\ of the
form
$\alpha_t=\chi_{I_t}$, where $\IT$\ are disjoint subsets of $[N]$.
Put another
way, $\normo m$\ is the smallest number $C$\ such that for all disjoint
subsets
$\IT$\ of $[N]$, if $(y_t)\in Y_T$, $\normo{(y_t)}_Y \le 1$, then
$\normo{(x_s)}_{X_\TtlmTt} \le C$, where $x_s(n) = y_t(s)$\ if $n\in
I_t$\ for
some $t\in[T]$, and $x_s(n)=0$\ otherwise.
 
\Step 3 So now let us fix $\IT$ as disjoint subsets of $[N]$. For
each
$(y_t)\in Y_T$, let $(\ty_t)\in \tY_T$\ be defined by
$\ty_t(s)=\modo{y_t(s)}^2$. Thus $ \normo{(y_t)}_Y^2 =
\normo{(\ty_t)}_{\tY}$. Notice that the extreme points of the unit
ball of
$\tY_T$\ are vectors of the form
$$ y_t(s) = \invlogt \delta_{s_t}(s) \qquad (t\le T),$$
where $\delta_{s_t}(s) = 1$\ if $s=s_t$\ and $0$\ otherwise, and
$s_t\in[S]$\
depends upon $t$\ only. For convenience later on, we write $J_s =
\{\,t\in[T]:s_t=s\}$, so that $\JS$ are disjoint subsets of $[T]$.
 
\Step 4 Now let $\tx_s(n)=\modo{x_s(n)}^2$\ so that $\tx_s(n) = \ty_t(s)$\
if
$n\in I_t$\ for some $t\in[T]$, and $x_s(n)=0$\ otherwise, and also
so that $
\normo{(x_s)}^2_{X_\TtlmTt} \approx \normo{(\tx_s)}_{X_\TlmTo} $.
We see that
to show Theorem~0.1, we need only show that the map $\tilde m\colon\tY\to
X_\TlmTo$, $(\ty_t)\mapsto(\tx_s)$\ is bounded.
 
\Step 5 Since $\normdot_{X_\TlmTo}$\ is a norm, it follows by the
Krein--Milman
theorem (See [Ru 3.2.1]) that in order to calculate
$\normo{\tilde m}$, we need only look at $\normo{\tilde
m((\ty_t))}_{X_\TlmTo}$\ where $(\ty_t)$\ is an extreme point of
the unit ball
of $\tY_T$. So let $(\ty_t)$\ have the form given in Step~3, and
notice that
then
$$ \tx_s = \sum_{t\in J_s} \invlogt \chi_{I_t} .$$
Hence, by the triangle inequality for $\normdot_\TlmTo$, we have
$$ \eqalignno{
   \normo{(\tx_s)}_{X_{\TlmTo}}
   &= \sumS \normo{\tx_s}_\LTlmTo \cr
   &\le \sumS \sum_{t\in J_s} \invlogt \normo{\chi_{I_t}}_\LTlmTo
\cr
   &\le c \sumT \invlogt \mItoN \Bigg/ \lm\left(\mItoN\right) \cr
   &\le c \normo{\left(\, \mItoN \Bigg/ \lm\left(\mItoN\right)
            \right)}_{l_\TlmTo^T} \cr
   &\approx \normo{\left(\, \mItoN \Bigg/ \lm\left(\mItoN\right)
            \right)}_{l_{T\lm T}^T} \cr
   &\approx 1 , \cr } $$
where the second to last approximate identity is by Theorem~1A:2.7(i).
The result
follows.
\endproof
 
\vfill
\eject
 
\beginsection 2) The Gaussian Cotype $2$\ Constant of $l_\infty^N
\hookrightarrow L^N_{2,1}$
 
In this section we investigate the necessity of the $\sqrt{\lm\lm
N}$\ factor
in Corollary~0.1b. Although we do not come to any conclusions, we
do find
directions in which to search, and conclude that it is a hard problem.
The
method is to find functions of $N$\ equivalent to, or bounding the
function
$N \mapsto G^2( l_\infty^N \hookrightarrow L_{2,1}^N)$.
 
First we define some spaces.
 
\proclaim Definition. Let $A$\ and $Y$\ be defined as in Section~1,
and let
$Y'$\ and $X_{2,1}$\ be the vector spaces defined by
$$ \eqalignno{
   Y' &= \{\,(\xi_t\in l^S_2)_{t=1}^\infty:
   \xi_t=0 \hbox{ for all but finitely many } t\}, \cr
   X_{2,1} &= \{\,(x_s\in L^N_{2,1})_{s=1}^S\},}$$
with norms
$$\eqalignno{
  \normo{(\xi_n)}_{Y'} &=
  \sum_{t=1}^\infty \invsqrtlogt \normo{\xi_t}_{l_2^S}, \cr
  \normo{(x_s)}_{X_{2,1}} &=
  \rmsxsLtwoone . }$$
 
\proclaim Definition. If $\mu$\ is a probability measure on $S_N$,
let
$Z_\mu$\ be\/ $\C^N$\ with norm
$$ \normo{\alpha}_{Z_\mu} =
   \left( \int_{S_N} \left( \invsqrtN \sumN \invsqrtpin \modo{\alpha(n)}
   \right)^2 \,d\mu(\pi) \right)^\half .$$
 
Now we define several functions of $N$, and show relationships between
them.
Our first function, $C_1(N)$, is the function that we are investigating.
 
\proclaim Definition. Let $C_1(N) = G^2( l_\infty^N \hookrightarrow
L_{2,1}^N
)$, that is, $C_1(N)$\ is the least number $C$\ such that for all
$\xS\in
l_\infty^N$\ we have
$$ \E \Gausswalk \ge {1\over C} \rmsxsLtwoone .$$
 
\proclaim Definition. Let $m_{S,N}$\ be the bilinear map
$$ \eqalign{
   A\times Y        &\to     X_{2,1} \cr
   (\alpha_t),(y_t) &\mapsto (x_s) ,\cr}$$
where
$$ x_s(n) = \sum_{t=1}^\infty \alphatn y_t(s) .$$
Let $C_2(N) = \sup_{S\in\N} \normo{m_{S,N}}$.
 
\proclaim Proposition 2.1. For all $N\in\N$\ we have $C_1(N) \approx
C_2(N)$.
 
\Proof This follows straight away from Corollary~0.2a.
\endproof
 
\proclaim Definition. Let $C_3(N)$\ be the least number $C$\ such
that for all
probability measures $\mu$\ on $S_N$\ and for all $\alphaT\in l_\infty^N$,
we
have
$$ \sumT \invsqrtlogt \normo{\alpha_t}_{Z_\mu}
   \le C \normo{\sumT \modo{\alpha_t}}_\infty .$$
 
\proclaim Definition. Let $C_4(N)$\ be the least number $C$\ such
that for any
probability measure $\mu$\ on $S_N$, there is a probability measure
$\lambda$\
on $[N]$\ such that for all $\alpha\in l_\infty^N$\ we have
$$ \normo{\alpha}_{Z_\mu} \le C \normo\alpha_{L_{T\sqrt{\lm T}}(\lambda)}
.$$
 
\proclaim Definition. Let $C_5(T)$\ be the least constant $C$\
such that the following holds. For any $T\in\N$, let $\bar\mu$\
be a probability measure on $S_T$. Then for any positive natural
numbers $\iT$\ such that $\sumT i_t = N$\ we have
$$ \invsqrtN \sumT \invsqrtlogt
   \left( \int_{S_T} \itoversumuptosigmat
   \,d\bar\mu(\sigma) \right)^\half
   \le C .$$
 
\proclaim Proposition 2.2. For all $N\in\N$\ we have
\item{i)} $C_2(N) = C_3(N)$;
\item{ii)} $C_3(N) \approx C_4(N)$;
\item{iii)} $C_3(N) \approx C_5(N)$.
 
\proof of i):
We use two elementary duality results.
$$ \normo {(x_s)}_{X_{2,1}} =
   \sup \left\{ \invsqrtN \sumS \sumN
   u_s \invsqrtpi \modo{x_s(n)} \right\},
   \leqno{\rm a)} $$
where the supremum is over all $\piS\in S_N$\
and all $\uS\ge0$\ such that $\sumS u_s^2=1$.
 
$$ \normo {(y_t)}_Y =
   \sup \left\{\, \sum_{t=1}^\infty \sumS
   \xi_t(s) y_t(s) : (\xi_t) \in Y' \right\}.
   \leqno{\rm b)} $$
 
Now
$C_2(N)$\ is the least number $C$\ such that for all
$S\in\N$,
$(\alpha_t)\in A$\ with $\alpha_t\ge 0$, and
$(y_t)\in Y$\ with $y_t\ge 0$,
we have
$$ \normo{ \left( \sum_{t=1}^\infty \alpha_t y_t(s) \right) }_{X_{2,1}}
   \le K \normo{(y_t)}_Y \normo{(\alpha_t)}_A. $$
So by (a),
$C_2(N)$\ is the least number $C$\ such that for all
$S\in\N$,
$(\alpha_t)\in A$\ with $\alpha_t\ge 0$,
$(y_t)\in Y$\ with $y_t\ge 0$,
$\piS\in S_N$, and
$\uS\ge0$\ with $\sumS u_s^2=1$,
we have
$$ \invsqrtN \sum_{t=1}^\infty \sumS \sumN
   u_s \invsqrtpi \alphatn y_t(s) \le
   K \normo{(y_t)}_Y \normo{(\alpha_t)}_A .$$
Thus by (b) we see that
$C_2(N)$\ is the least number $C$\ such that for all
$S\in\N$,
$(\alpha_t)\in A$\ with $\alpha_t\ge 0$,
$\piS\in S_N$, and
$\uS\ge0$\ with $\sumS u_s^2=1$,
we have
$$ \invsqrtN \sum_{t=1}^\infty \invsqrtlogt
   \normo{ \left( \sumN u_s \invsqrtpi
   \alphatn \right)_{s\in[S]} }_{l_2^S} \le
   K \normo{(\alpha_t)}_A . $$
So if we put the measure $\mu$\ defined by
$ \mu(\{\pi\})=\sum_{s\colon\pi_s=\pi} u_s^2 $\ on $S_N$,
we have that
$$ \normo{ \left( \sumN u_s \invsqrtpi
   \alphatn \right)_{s\in[S]} }_{l_2^S} =
   \left( \int_{S_N} \left( \sumN \invsqrtpi
   \alphatn \right)^2 \,d\mu(\pi) \right)^\half ,$$
and the result follows.
\endproof
 
\proof of ii):
By Theorem~1A:2.7(i) we have
$$ C_3(N) \approx \inf \{\, \pi_{T\sqrt{\lm T},1} (l_\infty^N \hookrightarrow
   Z_\mu) : \hbox{$\mu$\ is a probability measure on $S_N$} \} .$$
The result follows immediately from Theorem~1D:4.1.
\endproof
 
\proof of iii):
Here we make use of the approximation
$$ \sum_{n=n_1}^{n_2} \invsqrtn \approx {n_2-n_1 \over \sqrt{n_2}}
.$$
 
First, we show that $C_5(N) \ge \invc C_2(N)$.
Let $\epsilon>0$. From Proposition~1A:2.10, we see that there are
$(y_t)\in Y$\ and $\alphaT\in l_\infty^N$, with $|\alpha_t|\wedge
|\alpha_u|=0$\ for $t\ne u \in[T]$ and $\normo{\alpha_t}_\infty
\le 1$\ for $t\in[T]$, such that
$$ \normo{(x_s)}_{X_{2,1}} \ge \normo{m_{S,T}} \normo{(y_t)}_Y
   -\epsilon,$$
where
$$ x_s(n) = \sumT \alphatn y_t(s).$$
Without loss of generality, we suppose that $y_t\ge0$\ and that
$\alpha_t = \chi_{I_t}$\ where $\IT$\ are
disjoint sets whose union is $[T]$. We note that
$x_s(n)=y_t(s)$\ whenever $n\in I_t$. Thus $x_s$\ is
constant on each $I_t$. Hence
$$ \normo{(x_s)}_{X_{2,1}} \approx \invsqrtN \sumS
   \sumN u_s \invsqrtpi x_s(n) $$
for some $\uS\ge0$\ with $\sumS u_s^2 =1$,
and some $\piS\in S_N$\ with the property that
$\pi_s(I_t)$\ is an interval in $[N]$. Write $i_t$\
for $|I_t|$, and let $\sigmaS\in S_T$\ be such that
$$ \pi_s(I_t) = \left[
   \sum_{u=1}^{\sigma_s(t)-1} i_{\sigma_s^{-1}(u)} +1,
   \sumuptosigmat \right] . $$
To save space, write
$$ M_{s,t} = \sum_{n\in I_t} \invsqrtpi $$
so that by the observation above we have
$$ M_{s,t} \approx {i_t \over \left( \sumuptosigmat \right)^\half
} . $$
Then
$$ \eqalignno{
   \normo{(x_s)}_{X_{2,1}}
   &= \invsqrtN \sumS \sumT u_s M_{s,t} y_t(s) \cr
   &\le \invsqrtN \sumT \invsqrtlogt
        \left( \sumS u_s^2 M_{s,t}^2 \right)^\half
        \normo{(y_t)}_Y. \cr } $$
Now let $\epsilon\to 0$. We deduce that
$$ \normo{m_{S,T}} \le
   \invsqrtN \sumT \invsqrtlogt
   \left( \sum^S u_s^2 M_{s,t}^2 \right)^\half . $$
If we now define a probability measure $\bar\mu$\ on $S_T$\ by
$ \bar\mu(\{\sigma\}) = \sum_{s\colon\sigma_s=\sigma} u_s^2 $,
we see that the right hand side of the above equation is dominated
by
$$ \half \invsqrtN \sumT \invsqrtlogt
   \left(\int_{S_T} \itoversumuptosigmat
   \,d\bar\mu(\sigma) \right)^\half .$$
Therefore $\normo{m_{S,T}} \le c C_5(N)$.
 
Now we show that $ C_5(N)\le c C_3(N)$.
Suppose we are given $T\in\N$, a probability measure $\bar\mu$\
on $S_T$, and positive natural numbers $\iT$\
such that $\sumT i_t=N$. For each $t\in[N]$, let
$$ I_t = \left[ \sum_{u=1}^{t-1} i_u +1, \sum_{u=1}^t i_u \right]
,$$
and $\alpha_t=\chi_{I_t}$. For each $\sigma\in S_T$, choose
$\pi_\sigma \in S_N$\ such that
$$ \pi_\sigma(I_t) = \left[
   \sum_{u=1}^{\sigma(t)-1} i_{\sigma^{-1}(u)} +1,
   \sumuptosigmat
   \right] , $$
and define a probability measure $\mu$\ on $S_N$\ by setting
$\mu(\{\pi_\sigma\})=\bar\mu(\{\sigma\})$\ and $\mu(\{\pi\})=0$\
if $\pi\ne\pi_\sigma$\ for any $\sigma\in S_T$. It is easily seen
that
$$ {i_n \over \left( \sumuptosigmat \right)^\half}
   \le c \sum_{n\in I_t} {1\over\sqrt{\pi_\sigma(n)}} \alphatn .
$$
Therefore
$$ \left( \int_{S_T} \itoversumuptosigmat
   \,d\bar\mu(\sigma) \right)^\half
   \le c \normo{\alpha_t}_{Z_\mu} . $$
The result follows.
\endproof
 
Now we consider trying to find good bounds for $C_1(N)$, and we concentrate
our
attention on the quantity $C_5(N)$. First, we will
look for lower bounds.
 
\proclaim Question 2.3. Is $C_5(N) \ge \invc \sqrt{\lm\lm N}$, or
at least, is
it the case that $C_5(N)$\ is not uniformly bounded in $N$. Put another
way,
for each $N\in\N$, can we find a $T\in\N$, a probability measure
$\bar\mu$\ on
$[T]$, and positive natural numbers $\iT$\ with $\sumT i_t = N$,
such that
$$ \invsqrtN \sumT \invsqrtlogt
   \left( \int_{S_T} \itoversumuptosigmat
   \,d\bar\mu(\sigma) \right)^\half $$
is large?
 
\noindent
I have not been able to answer this question.
 
If we are looking for lower bounds for $C_5(N)$, the following may
help.
 
\proclaim Definition. Let $C_6(N)$\ be the least constant $N$\
such that the following holds.
For any positive natural
numbers $\iT$\ such that $\sumT i_t = N$\ there are
positive real numbers $\nuT$\ such that
$$ \invN \left( \sumT \nutologt \right)
   \left( \sup_{\sigma\in S_T} \sumT \invnut
   \itoversumuptosigmat \right)
   \le C^2.$$
 
\proclaim Proposition 2.4. For all $N\in\N$\ we have $C_5(N) \le
C_6(N)$.
 
\Proof
Suppose we are given $T\in\N$, a probability measure $\bar\mu$\ on
$S_T$, and positive natural numbers $\iT$\ such
that $\sumT i_t = N$. Then for any positive real numbers
$\nuT$\
we have by the Cauchy-Schwartz inequality that
$$ \eqalignno{
   & \invN \left( \sumT \invsqrtlogt
     \left( \int_{S_T} \itoversumuptosigmat
     \,d\bar\mu(\sigma) \right)^\half
     \right)^2 \cr
\le& \invN \left( \sumT \nutologt \right)
     \left( \sumT \int_{S_T} \invnut
     \itoversumuptosigmat
     \,d\bar\mu(\sigma) \right) \cr
=  & \invN \left( \sumT \nutologt \right)
     \left( \int_{S_T} \sumT \invnut
     \itoversumuptosigmat
     \,d\bar\mu(\sigma) \right) \cr
\le& \invN \left( \sumT \nutologt \right)
     \left( \sup_{\sigma\in S_T} \sumT \invnut
     \itoversumuptosigmat
     \right) . \cr } $$
The result follows.
\endproof
 
Thus we can formulate the following question.
 
\proclaim Question 2.5. Is $C_6(N)$\ uniformly bounded in $N$, or
at least, is
$C_6(N) = o\bigl(\sqrt{\lm\lm N}\bigr)$?
 
Now all choices of $\iT$\ that I have tried indicate a positive answer.
For example, if $i_1=i_2=\ldots=i_T = {N\over T}$, then choose
$\nu_1=\nu_2=\ldots=\nu_T=1$, and see that
$$ \eqalignno{
   \invN \left( \sumT \nutologt \right)
   \left( \sup_{\sigma\in S_T} \sumT \invnut \itoversumuptosigmat
\right)
   &\approx \invN {T\over\lm T} {N\over T} \sumT \invt \cr
   &\approx 1 . \cr } $$
This example has further applications. For
we have shown that if $\IT$\ are equal sized disjoint subsets of
$[N]$\
and if $\mu$\ is any probability measure on $S_N$, then
$$ \sumT \invsqrtlogt \normo{\chi_{I_t}}_{Z_\mu} \le c .\eqno(2.1)$$
Now we can prove the following result, which is similar to
Corollary~2B:1.5a.
 
\proclaim Proposition 2.6. Let $a\in l_\infty^N$, and enumerate $S_N$\
as
$\{\piS\}$. Let $x_s(n) = a(\pi_s(n))$. Then
$$ \E \Gausswalk \ge \invc \rmsxsLtwoone .$$
 
\Proof If $x$\ has the above form, then following through all the
previous
definitions and proofs, we see that in the definition of $C_3(N)$\
that the only
$\mu$\ on $S_N$\ that we need to consider is the counting measure
on $S_N$. But
then $\normdot_{Z_\mu}$\ is a $1$-symmetric norm on $\C^N$. Thus
we deduce from
$(2.1)$\ that
$$ \normo{\chi_I}_{Z_\mu} \le c {\sqrt{\lm T}\over T} $$
whenever $\modo I = N/T$. But then by Lemma~1D:4.2, this is sufficient
to
show that for all $\alpha\in l_\infty^N$\ we have
$$ \normo{\alpha}_{Z_\mu} \le c \normo{\alpha}_{T\sqrt{\lm T},1}
,$$
and the result follows by Proposition~2.2(ii).
\endproof
 
But at least I can show the next result, although not easily. (This
gives
another proof of Theorem~1C:5.2(ii).)
 
\proclaim Proposition 2.7. For all $N\in\N$, we have $C_6(N) \le
c \sqrt{\lm\lm
N}$.
 
\Proof
First, without loss of generality, we may assume that $N\ge3$.
Suppose we are given
$T\in\N$, and positive natural numbers $\iT$\
such that $\sumT i_t = N$. Let
$$ \nu_t = i_t (\lm(N/i_t)).$$
Then, since $\lm x \le 2\sqrt x$\ for all $x>0$, we see
that $\nu_t\le 2\sqrt{Ni_t}$. Hence
$$ \eqalignno{
   \sumT {\nu_t \over 2N(\lm(2N/\nu_t))}
   &\le \sumT {\nu_t \over 2N(\lm\sqrt{N/i_t})} \cr
   &\le \sumT {\nu_t \over N(\lm(N/i_t))} \cr
   &= 1 . \cr } $$
Therefore $\normo{(\nu_t)}_{T\lm T} \le 2N$. So by Theorem~1A:2.7(i),
we have
$$ \sumT \nutologt \le cN . $$
Now fix $\sigma\in S_T$. Split $[T]$\ into the following
$\lceil \log\log N\rceil +1$\ subsets:
 
\centerline{\vbox{
\openup1\jot\halign{\hfill#\hfil&#\hfil&\quad#\hfill \cr
   $A_k$&$= \left\{\, t: N^{1-e^{1-k}} \le i_t < N^{1-e^{-k}} \right\}
     $&for $1\le k\le \lceil \log\log N\rceil $;\cr
   $A_k$&$= \left\{\, t: N^{1-e^{1-k}} \le i_t \le N          \right\}
     $&for $k=\lceil \log\log N\rceil +1 $.\cr }
}}
 
\noindent
(Note that $N<e N^{1-e^{-k}}$\ for $k=\lceil \log\log N\rceil +1$.)
Now, for each $k$, let $i'_k$\ be the element of $A_k$\ such
that $\sigma(i'_k)$\ is smallest, and let
$B_k=A_k\setminus\{i'_k\}$.
Then since ${x-y \over x} \le \log x - \log y$\ for $x\ge y>0$,
we have for each $k$\ that
$$ \eqalignno{
&
   \sum_{t\in A_k} \invnut \itoversumuptosigmat \cr
=&
   \sum_{t\in A_k} {1\over \lm(N/i_t)} {i_t \over \sumuptosigmat
} \cr
\le&
   {1\over 1+\log(e^{-1}N^{e^{-k}}) } \sum_{t\in A_k} \left( i_t
\Bigg/
   \sumsslimits{u=1}{\sigma^{-1}(u)\in A_k}^{\sigma(t)}
   i_{\sigma^{-1}(u)} \right) \cr
\le&
   {e^k\over\log N} \left( 1+ \sum_{t\in B_k}
   \log\left(
   \sumss{u=1}{\sigma^{-1}(u)\in A_k}^{\sigma(n)}
   i_{\sigma^{-1}(u)}
   \Bigg /
   \sumss{u=1}{\sigma^{-1}(u)\in A_k}^{\sigma(n)-1}
   i_{\sigma^{-1}(u)}
   \right) \right) \cr
\le&
   {e^k\over\log N} \left( 1+ \log\left( {\sum_{t\in A_k} i_t \over
   \inf_{t\in A_k} i_t} \right) \right) \cr
\le&
   {e^k\over\log N} \left( 1+
   \log\left( {N\over N^{1-e^{1-k}} } \right)\right) \cr
\le&
   e^2+e . \cr } $$
Therefore
$$ \sumT \invnut \itoversumuptosigmat
   \le (e^2+e) (\lceil \log\log N \rceil +1) . $$
The result follows.
\endproof
 
\vfill
\eject
 
\beginsection Chapter 2D --- Comparison of Gaussian and Rademacher
Cotype
 
In this chapter we prove Theorems~1C:5.3 and~1C:5.4.
 
\proclaim Theorem 1. Let $2\le p<q<\infty$. Then for sufficiently
large $N$\ (depending on $p$\ and $q$) we have
$$ G^p (l_\infty^N \hookrightarrow l_{q,p}^N) \le
   c \sqrt p \invsqrtlogN N^\invp.$$
 
\proclaim Corollary 1a. Let $2\le p<q<\infty$. Then for sufficiently
large $N$\ (depending on $p$\ and $q$) there is a \blo\ $T$\ from
$l_\infty^N$
to $L_q$\ such that
$$ R^p(T) \ge \invc \invsqrtp \sqrt{\lm N}\, G^p(T) .$$
 
\proclaim Corollary 1b. Let $2<q<\infty$. Then for sufficiently
large $N$\ (depending on $p$\ and $q$) there is a \blo\ $T$\ from
$l_\infty^N$
to $L_q$\ such that
$$ \pi_{2,1}(T) \ge \invc \sqrt{\lm N}\, G^2(T) .$$
 
\proof of Corollaries 1a and 1b: The obvious example is $T\colon
l_\infty^N
\hookrightarrow l_q^N$, as it factors through both $l_{q,p}^N$\ and
$l_{q,2}^N$. By considering the unit vectors we immediately see that
$R^p(T)\ge
N^\invp$, and $\pi_{2,1}(T) \ge N^\half$.
 
\proof of Theorem 1:
We follow the proof of Proposition~2A:4.6 almost identically. First
we
take the $L_p$\ average of systems of strips of size $k$.
$$ \E\Gausswalk \ge \smallquarter \left( \AvNk \left( \E \supGausssigmanu
   \right)^p \right)^\invp ,$$
which, by Proposition~2A:3.1, is approximately greater than
$$ \invsqrtp \left( \AvNk (\logk)^\potwo \AvokN
   \normo{x_{\sigma_n}(n)}_2^p \right)^\invp ,$$
which, since $\normdot_2 \ge \normdot_p$\ for $p\ge2$, is greater
than
$$ \invsqrtp \left( \AvNk (\logk)^\potwo \AvokN
   \normo{x_{\sigma_n}(n)}_p^p \right)^\invp ,$$
$$ \approx \invsqrtp \left( {(\logk)^\potwo \over k}
   \sumS \sumN \modo{x_s(n)}^p {\mnuinsigma \over \mNk} \right)^\invp
,$$
which, by Proposition~2A:2.2, is approximately greater than
$$ \invsqrtp \left( {(\logk)^\potwo \over N} \sumN \sumpis
   \modo{x_s(n)}^p \right)^\invp .$$
 
Now we average over $k$\ with weighting $G_k$, to be chosen later,
and write
$G=\sumkN G_k$.
$$ \eqalignno{
   \E\Gausswalk
   &\ge \invc \invsqrtp \left( {1\over G} \sumkN {G_k (\logk)^\potwo
\over N}
   \sumN \sumpis \modo{x_s(n)}^p \right)^\invp \cr
   &= \invc \invsqrtp {1\over(GN)^\invp} \left( \sumN \sumkNopi G_k
   (\logk)^\potwo \modo{x_s(n)}^p \right)^\invp . \cr}$$
Now let
$$ G_k={1\over(\logk)^\potwo} {k^{1-\poq}-(k-1)^{1-\poq} \over
   N^{1-\poq} } ,$$
and observe that $G\approx(\lm N)^{-\potwo}$\ for sufficiently
large $N$\ (depending on $p$\ and $q$). Then we see that the above
is bounded
above by
$$ \invc \invsqrtp {\sqrt{\lm N} \over N^\invp} \left( \sumN \pi_s(n)^{\poq-1}
   \modo{x_s(n)}^p \right)^\invp $$
which, by Proposition~1A:2.6(i), is at least
$$ \invc \invsqrtp {\sqrt{\lm N} \over N^\invp} \left( \sumN
   \normo x_{l_{q,p}^N}^p \right)^\invp $$
as desired.
\endproof
 
\vfill
\eject
 
\def \invF {F^{-1}}
\def \invG {G^{-1}}
\def \invH {H^{-1}}
\def \invL {L^{-1}}
\def \invPhi {\Phi^{-1}}
\def \tF {\tilde F}
\def \tG {\tilde G}
\def \tH {\tilde H}
\def \tL {\tilde L}
\def \tPhi {\tilde\Phi}
\def \invtF {\tF^{-1}}
\def \invtG {\tG^{-1}}
\def \invtH {\tH^{-1}}
\def \invtL {\tL^{-1}}
\def \invtPhi {\tPhi^{-1}}
\def \sF {F^*}
\def \sH {H^*}
\def \invsF {{\sF}^{-1}}
\def \tsH {\tH^*}
\def \invtsH {{\tsH}{}^{-1}}
 
\def \norminvGG {\normo{1\over\invtG}_G}
\def \norminvsHsH {\normo{1\over{\invtsH}}_{\sH}}
\def \norminvLL {\normo{1\over\invtL}_L}
 
\def \Gtr {G_t^\rho}
\def \Gto {G_t^1}
\def \invGtr {(\Gtr)^{-1}}
\def \invGto {(\Gto)^{-1}}
 
\def \invC {C^{-1}}
 
\def \Ftot {{F(t)\over t}}
\def \Ftuou {{F_t(u)\over u}}
 
\def \labelledprec#1{\buildrel{#1}\over\prec}
\def \labelledsucc#1{\buildrel{#1}\over\succ}
\def \labelledasymp#1{\buildrel{#1}\over\asymp}
 
\def \itemi {\item{i)}}
\def \itemii {\item{ii)}}
\def \itemiii {\item{iii)}}
\def \itemiv {\item{iv)}}
\def \itemv {\item{v)}}
\def \itemvi {\item{vi)}}
\def \itemvii {\item{vii)}}
 
\def \Ibasms {$I$\ be a standard measure space}
\def \onI {\ on $I$}
\def \onIzi {\ on $I_{0,\infty}$}
\def \onIAi {\ on $I_{A,\infty}$}
\def \onIzB {\ on $I_{0,B}$}
\def \onIAB {\ on $I_{A,B}$}
 
\def \fullrif {rearrangement invariant positive homogeneous functional}
\def \rif {r.i.\ functional}
\def \fullris {\fullrif\ Banach space}
\def \ris {r.i.\ space}
 
\def \Xbaris {$X$\ be a \ris}
\def \Xbanris {$X$\ be a normal \ris}
 
\def \af {admissible function}
\def \Fbaaf {$F$\ be an \af}
\def \Fbanaf {$F$\ be a normal \af}
 
\beginsection Part 3 --- Generalized Lorentz Spaces
 
\beginsection Contents
 
\contents{%
Chapter&3A & Definitions and Elementary Properties         \dotfill
92 \cr
\ns
Section&1  & Rearrangement Invariant Spaces                \dotfill
92 \cr
&1.1       & Quasi-Norms                                   \dotfill
93 \cr
&1.2       & Dilatory Factors                              \dotfill
95 \cr
Section&2  & Admissible Functions                          \dotfill
97 \cr
&2.1       & Quasi-Orlicz Functions                        \dotfill
98 \cr
&2.2       & Admissible Functions that Satisfy the $\Delta_2$-Condition
                                                           \dotfill
99 \cr
&2.3       & Families of Admissible Functions              \dotfill
99 \cr
Section&3  & Functions from Spaces and Spaces from Functions
                                                           \dotfill
100 \cr
&3.1       & The Fundamental Function                      \dotfill
100 \cr
&3.2       & The Orlicz Functional                         \dotfill
100 \cr
&3.3       & The Weak Orlicz Functional                    \dotfill
101 \cr
&3.4       & Families of Admissible Functions              \dotfill
102 \cr
Section&4  & Un-$L_\infty$\ and Normal Spaces and Functions
                                                           \dotfill
103 \cr
Section&5  & Generalized Lorentz Spaces                    \dotfill
104 \cr
\nm
Chapter&3B & Inequalities                                  \dotfill
106 \cr
\ns
Section&1  & H\"older's Inequality Generalized             \dotfill
106 \cr
&1.1       & Complementary Functions and Dual Spaces       \dotfill
106 \cr
&1.2       & H\"older's Inequality Generalized             \dotfill
107 \cr
&1.3       & Families of Admissible Functions
                                                           \dotfill
107 \cr
Section&2  & The Second Index of Generalized Lorentz Functions
                                                           \dotfill
108 \cr
&2.1       & Inequalities Between $L_{F,{G_1}}$\ and $L_{F,{G_2}}$
                                                           \dotfill
108 \cr
&2.2       & Inequalities Between $L_{F,G}$\ and $L_{F,\infty}$
                                                           \dotfill
110 \cr
&2.3       & Applications of these Inequalities            \dotfill
110 \cr
Section&3  & A Result about Orlicz Spaces                  \dotfill
112 \cr
\nm
Chapter&3C & Boyd Indices of Generalized Lorentz Spaces    \dotfill
113 \cr
\ns
Section&1  & Introduction                                  \dotfill
113 \cr
Section&2  & The Boyd Indices of $L_{1,G}$                 \dotfill
115 \cr
&2.1       & Equivalent Quantities Describing the Boyd Indices
                                                           \dotfill
116 \cr
}
 
\beginsection Introduction to Part 3
 
This part is really an appendix to the rest of the thesis. Its main
purpose is
to prove some of the results of Sections~1A:2.3 and~1A:2.4, but it
also
discusses some new problems in Chapter~3C.
 
We start in Chapter~3A by giving the basic definitions, that is,
of the
\fullris s (\ris s) (in Section~1), and the \af s (in Section~2).
The \ris s
are an extension of the well known idea of normed rearrangement invariant
spaces, and the \af s generalize the notion of Orlicz functions.
For both of
these, I define many convexity constants (and a few concavity constants).
Then
Section~3 describes Orlicz spaces and weak Orlicz spaces, and Section~4
describes the technical notion of normal spaces and functions. Finally,
in
Section~5, we define the main objects of our interest in this part,
the
generalized Lorentz spaces.
 
Chapter~3B gives some inequalities. Section~1 looks at the generalized
H\"older's inequality,
giving a different approach to that usually taken. These results
are then used
to prove the results of Section~2, which looks at changes in the
second index
of the generalized Lorentz functional. This section culminates in
good formulae
for calculating certain Orlicz functionals. (This extends results
of
Bennett and Rudnick.) Section~3 gives a single proposition that is
required in Parts~1
and~2.
 
Chapter~3C looks at the surprisingly non-trivial problem of whether
the
generalized Lorentz spaces are quasi-normed. It also considers the
Boyd indices
of these spaces, and relates these to complicated conditions on the
second
index.
 
\vfill
\eject
 
\beginsection Chapter 3A --- Definitions and Elementary Properties
 
\beginsection 1) Rearrangement Invariant Spaces
 
We start off by defining \fullris s. Although these definitions may
seem rather
long, they are only extensions of the well known notion of normed
rearrangement
invariant spaces (see
[L--T2 Ch.2] or [B--S Ch.4 \S2]).
 
\proclaim Definition 1.1. A measure space $I$\ is a {\dt standard
measure space} if
$I$\ is one of the following.
\itemi $I = I_{0,\infty} = [0,\infty)$\ with Lebesgue measure $\lambda$.
\itemii $I = I_{0,B} = [0,B]$\ with Lebesgue measure $\lambda$, where
$0<B<\infty$.
\itemiii $I = I_{A,\infty} = A\N = \{\,An:n\in\N\}$\ with measure
$\lambda\{An\}=A$, where $0<A<\infty$.
\itemiv $I = I_{A,B} = A\N\cap[0,B]$\ with measure $\lambda\{An\}=A$,
where
$0<A\le B<\infty$.
 
\proclaim Definition 1.2. Let $I$\ be a measure space. Define $L_0
= L_0(I)$\ be
the set of equivalence classes of measurable functions $f\colon I\to\C$,
where
the equivalence relation is equality almost everywhere. Give $L_0(I)$\
the {\dt
measure topology}, that is, the neighbourhoods of zero are sets of
the
form $\{\, f : \lambda\{\,t\in I:\modo{f(t)}>\epsilon\} < \epsilon\}$,
where
$\epsilon>0$.
 
\proclaim Definition 1.3. Let \Ibasms. A {\dt \fullrif\onI}\ is a
function
$\normdot\colon L_0(I)\to[0,\infty]$\ satisfying
\itemi if $f\in L_0(I)$, then $\normo f=0\Leftrightarrow f=0$;
\itemii if $f\in L_0(I)$\ and $\alpha\in\C$, then $\normo{\alpha
f}=\modo\alpha
\normo f$;
\itemiii if $f,g\in L_0(I)$, then $\modo f\le\modo g \Rightarrow
\normo f\le
\normo g$;
\itemiv if $f_n,f\in L_0(I)$\ for $n\in\N$, then $\modo{f_n}\nearrow\modo
f \Rightarrow \normo{f_n}\to\normo f$, as $n\to\infty$;
\itemv if $f_n\in L_0(I)$\ for $n\in\N$, then $\normo{f_n}\to0
\Rightarrow f_n\to0$\ in the measure topology, as $n\to\infty$;
\itemvi if $\tau\colon I\to I$\ is a measure preserving map and $f\in
L_0(I)$,
then $\normo f = \normo{f\circ\tau}$.
\moreproclaim\noindent
A {\dt \fullris\onI}\ is a pair $(X,\normdot)$, where $\normdot$\
is a
\fullrif\onI, and $X=\{f\in L_0(I):\normo f <\infty\}$. We abbreviate
the
phrase `\fullrif' to {\dt \rif}, and `\fullris' to {\dt \ris}. We
always refer to a \ris\ by a single letter, $X$\ say, which also
denotes its subset of $L_0(I)$, and we denote its norm by $\normdot_X$.
 
\proclaim Definition 1.4. Let \Ibasms, and $f\in L_0(I)$. Define
the {\dt
decreasing rearrangement} of $f$\ to be the function
$I_{0,\infty}\to\R_+$\ given by
$$ f^*(x) = \sup \{\, t:\lambda\{\modo f>t\} >x\} .$$
 
Sometimes, with an abuse of notation, we will write $f^*$\ for $f^*\big|_I$.
If $0<A\le B<\infty$, then $(\,f^*(x):x\in I_{A,B})$\ is the sequence
$(\,\modo{f(x)}:x\in I_{A,B})$\ rearranged in decreasing order. If
$X$\ is a
\ris, then $\normo f_X = \normo{f^*}_X$.
 
\proclaim Definition 1.5. Let $X$\ and $Y$\ be \ris s, and $C<\infty$.
We say that
$X$\ and $Y$\ are {\dt approximately equal, with constant of approximation
$C$}\ (in symbols $X \labelledapprox C Y$), if $\normdot_X \labelledapprox
C
\normdot_Y$.
If $X \labelledapprox c Y$, then we simply say that $X$\ and $Y$\
are
{\dt approximately equal} (in symbols $X\approx Y$).
 
\beginsection 1.1) Quasi-Norms
 
Here we give various convexity constants.
 
\proclaim Definition 1.6. Let \Ibasms, and \Xbaris\onI.
\itemi We say that $X$\ is {\dt quasi-normed} if there is a $C<\infty$\
such
that for all $f,g\in L_0(I)$\ we have
$$ \normo{f+g}_X \le C(\normo f_X + \normo g_X) ,$$
and we define the {\dt quasi factor} of $X$\ to be
$$Q(X) = \inf\{\,C:\hbox{the above holds}\} .$$
\itemii Let $0<p<\infty$, $p\le q\le \infty$. We say that $X$\ is
{\dt $(p,q)$-convex} if there is a $C<\infty$\ such that for all
$f_1$, $f_2,\ldots$, $f_N\in L_0(I)$\ we have
$$ \normo{\left(\sumN\modo{f_n}^q\right)^\invq}_X
   \le C \left(\sumN\normo{f_n}_X^p\right)^\invp
   \quad\hbox{for $q<\infty$} ,$$
$$ \normo{\supN\modo{f_n}}_X
   \le C \left(\sumN\normo{f_n}_X^p\right)^\invp
   \quad\hbox{for $q=\infty$} ,$$
and we define the {\dt $(p,q)$-convexity constant} of $X$\ to be
$$C_{p,q}(X) = \inf\{\,C:\hbox{the above holds}\} .$$
If $p=q$, we say that $X$\ is {\dt $p$-convex}
if the above holds, and call the $(p,q)$-convexity constant the {\dt
$p$-convexity constant} and denote it by $C_p(X)$.
\endit
 
We have the following result.
 
\proclaim Proposition 1.7. Let \Xbaris. Then there is a $0<p\le1$\
such that
$X$\ is $(p,1)$-convex if and only if $X$\ is quasi-normed.
 
\Proof See [K--P--R Thm.1.2].
\endproof
 
However I do not know the answer to the following question.
 
\proclaim Question. Let $X$\ be a quasi-normed \ris. Is there a $0<p<\infty$\
such that $X$\ is $p$-convex?
 
\proclaim Proposition 1.8. Let $0<p<\infty$, $p\le q\le\infty$, and
$X$\ be a
$(p,q)$-convex \ris. Then there is a \ris\ $X_1$\ such that
$C_{p,q}(X_1) = 1$\ and
$$ \normdot_{X_1} \le \normdot_X \le C_{p,q}(X) \normdot_{X_1} .$$
 
\Proof Suppose that $q<\infty$\ (the argument is the same if $q=\infty$).
Define $\normdot_{X_1}$\ to be
$$ \normo f_{X_1}
   = \inf \left\{\, \left( \sumN \normo{f_n}_X^p \right)^\invp
   : \modo f = \left( \sumN \modo{f_n}^q \right)^\invq \right\} .$$
Clearly $ \normdot_{X_1} \le \normdot_X \le C_{p,q}(X) \normdot_{X_1}
$, and
clearly $X_1$\ satisfies (i) to (iii), (v) and (vi) of Definition~1.3.
We
check (iv) of Definition~1.3. Suppose $f_n\nearrow f$. Let $\epsilon>0$,
and
choose $g_1$, $g_2,\ldots,$\ $g_M$\ such that
$$ \modo f = \left( \sumM \modo{g_m}^q \right)^\invq ,$$
and
$$ \left( \sumM \normo{g_m}_X^p \right)^\invp \ge \normo f_{X_1}
- \epsilon .$$
Let $g_m^{(n)} = \ds{f_n \over f} g_m$. Then $g_m^{(n)} \nearrow
g_m$\ as $n\to
\infty$, and
$$ \modo{f_n} = \left( \sumM \modo{g_m^{(n)}}^q \right)^\invq .$$
Therefore, as $n\to \infty$\ we have
$$ \eqalignno{
   \normo{f_m}_{X_1}
   &\ge \left( \sumM \normo{g_m^{(n)}}_X^p \right)^\invp \cr
   &\to \left( \sumM \normo{g_m}_X^p \right)^\invp \cr
   &\ge \normo f_{X_1} -\epsilon .\cr}$$
Since $\epsilon$\ was arbitrary, we are done, and $X_1$\ is a \ris.
 
Now we check that $C_{p,q}(X_1) = 1$. Let $\epsilon>0$, and suppose
that
$$ \modo f = \left( \sumN \modo{f_n}^q \right)^\invq .$$
For each $n\in[N]$, choose $g_1^{(n)}$, $g_2^{(n)},\ldots,$\ $g_M^{(n)}$\
such
that
$$ \modo{f_n} = \left( \sumM \modo{g_m^{(n)}}^q \right)^\invq $$
and
$$ (1+\epsilon) \normo{f_n}_{X_1} \ge \left( \sumM \normo{g_m{(n)}}_X
   \right)^\invp .$$
Then
$$ \modo{f} = \left( \sumM \sumN \modo{g_m^{(n)}}^q \right)^\invq
,$$
and so
$$ \eqalignno{
   \normo f_{X_1}
   &\le \left( \sumM \sumN \normo{g_m^{(n)}}_X^p \right)^\invp \cr
   &\le (1+\epsilon) \left( \sumN \normo{f_n}_{X_1}^p \right)^\invp
.\cr}$$
\endproof
 
\beginsection 1.2) Dilatory Factors
 
Here we give some other numbers that describe \ris s.
 
\proclaim Definition 1.9. Let \Ibasms, $0<A\le B<\infty$, and $0<\rho<\infty$.
Define the map $d_\rho\colon I\to I$\ by
\openup1\jot\halign{\hfil#\ &#\hfil&\quad\quad\quad#\hfil\cr
i)&$ x \mapsto \rho x $& for $I=I_{0,\infty}$;\cr
ii)&$ x \mapsto \cases{
      \rho x &if $\rho x\le B$\cr
      B      &if $\rho x >  B$\cr}$& for $I=I_{0,B}$;\cr
iii)&$ x \mapsto A\lfloor\rho x/A\rfloor $& for $I=I_{A,\infty}$;\cr
iv)&$ x \mapsto \cases{
      A\lfloor\rho x/A\rfloor &if $\rho x\le B$\cr
      A\lfloor B      \rfloor &if $\rho x >  B$\cr}$& for $I=I_{A,B}$.\cr}
Let $D_\rho\colon L_0(I)\to L_0(I)$\ be the map $f\mapsto f\circ
d_\rho$.
\endit
 
\proclaim Definition 1.10. Let \Xbaris.
\itemi If $0<\rho<\infty$, then the {\dt $\rho$-dilatory factor}
of $X$\ is the
number
$$ D_\rho(X) = \sup\left\{\, {\normo{D_\rho(f)}_X \over \normo f_X}
:
   0 < \normo f_X < \infty \right\}.$$
\itemii We say that $X$\ is {\dt dilatory} if $D_\rho(X)<\infty$\
for all
$0<\rho<\infty$.
\itemiii Let $0<p<\infty$. We say that $X$\ is {\dt $p$-lower Boyd}
if there
is a number $C\le\infty$\ such that
$$ D_\rho(X) \le C\rho^{-\invp} \quad\hbox{for all $0<\rho\le1$}
.$$
The {\dt $p$-lower Boyd constant} of $X$ is
$$ B_p(X) = \inf\{\,C:\hbox{the above holds}\} .$$
The {\dt lower Boyd index} of $X$\ is
$$ p_X=\sup\{\,p:B_p(X)<\infty\} .$$
\itemiv Let $0<q<\infty$. We say that $X$\ is {\dt $q$-upper Boyd}
if there
is a number $C\le\infty$\ such that
$$ D_\rho(X) \le C\rho^{-\invq} \quad\hbox{for all $1\le\rho<\infty$}
.$$
The {\dt $q$-upper Boyd constant} of $X$ is
$$ B^q(X) = \inf\{\,C:\hbox{the above holds}\} .$$
The {\dt upper Boyd index} of $X$\ is
$$ q_X=\inf\{\,q:B^q(X)<\infty\} .$$
\endit
 
We have the following simple results.
 
\proclaim Proposition 1.11. Let \Xbaris. The following are equivalent.
\itemi $X$\ is dilatory.
\itemii There is a $\rho<1$\ such that $D_\rho(X)<\infty$.
\itemiii $p_X>0$.
 
\Proof (iii)$\Rightarrow$(i)$\Rightarrow$(ii) is clear. We show
(ii)$\Rightarrow$(iii). Let $X$\ be a \ris\ on the standard measure
space $I$.
Let $\rho<1$\ be such that $D_\rho(X)<\infty$. Notice that
for all $x\in I$\ and $n\in\N$\ we have $(d_\rho)^n(x) \le d_{\rho^n}(x)$,
and
so $D_{\rho^n}(f^*) \le (D_\rho)^n(f^*)$\ for all $f\in L_0(I)$.
Hence
$D_{\rho^n}(X) \le (D_\rho(X))^n$, and therefore $D_\sigma(X) \le
D_\rho(X)
\sigma^q$\ for all $\sigma<1$, where $q = \log D_\rho(X) \Big/ \log
\rho$.
\endproof
 
\proclaim Proposition 1.12. Let $0<p\le q\le\infty$, and \Xbaris.
If $X$\ is
quasi-normed, then it is dilatory. If $X$\ is $(p,q)$-convex, then
$p_X\ge p$.
 
\Proof Let \Xbaris\onIAB. Given $f\in L_0(I_{A,B})$, and $\rho=\invN$,
where
$N\in\N$, let $f_1$, $f_2\ldots,$\ $f_N \in L_0(I_{A,B})$\ be disjoint
functions
each of which has the same distribution as $f\big|_{[0,B/N]}$. Then
for any
$0<q<\infty$, we have
$$ \eqalignno{
   D_\rho(f^*)
   &= \left( \left(\sumN \modo{f_n}^q \right)^\invq \right)^* \cr
   & =\left( \supN \modo{f_n} \right)^* .\cr}$$
Thus $\normo{D_\half(f)}_X \le Q(X) \normo f_X$, and $\normo{D_\invN(f)}_X
\le
C_{p,q}(X) N^{-\invp} \normo f_X$. The results follow.
\endproof
 
\vfill
\eject
 
\beginsection 2) Admissible Functions
 
In this section we define the notion of \af s. Again, the long definitions
disguise simple ideas, which are only meant to provide elementary
extensions to
the idea of Orlicz functions (see [B--S Ch.4 \S8], [K--R], L--T1
Ch.4] or
[Mu]).
 
\proclaim Definition 2.1. A function $F\colon[0,\infty]\to[0,\infty]$\
is called
{\dt admissible} if
\itemi $F$\ is increasing;
\itemii $F(0)=0$;
\itemiii $F$\ is left continuous;
\itemiv $F$\ is continuous at $0$;
\itemv $F(t) \to \infty$\ as $t\to\infty$.
\moreproclaim\noindent
If $F$\ satisfies only (i), (ii) and (iii), we say that $F$\ is {\dt
almost
admissible}.
 
\proclaim Definition 2.2. Let $F$\ be an almost \af. Then we define
$\invF$\ and
$\tF\colon[0,\infty]\to[0,\infty]$\ to be
$$ \eqalignno{
   \invF(t) &= \sup\{\, u : F(u)<t \} \cr
   \tF(u)   &= \sup\{\, 1/F(\ts\invt) : t<u \} .\cr}$$
(Here $\sup\emptyset = 0$.)
 
\proclaim Proposition 2.3. If $F$\ is an almost \af, then so are
$\tF$ and
$\invF$. If
$F$\ and $G$\ are \af s, then $F\circ G$\ is almost admissible. Furthermore,
we
have the following identities.
\itemi $(F\circ G)^{-1} = \invG\circ\invF$.
\itemii $(\invF)^{-1} = F$.
\itemiii $\widetilde{F\circ G} = \tF\circ\tG$.
\itemiv $\tilde{\tilde{{F}}} = F$.
\itemv $\widetilde{\invF} = \invtF$.
 
For comparing admissible functions we introduce the following notation.
 
\proclaim Definition 2.4. Let $F$\ and $G$\ be \af s. For $C<\infty$\
we write
$F\labelledprec C G$\ if for all $t\in[0,\infty]$\ we have $F(t)\le
G(Ct)$, and
we write $F\labelledsucc C G$\ if $G\labelledprec C F$, and $F \labelledasymp
C
G$\ if $F\labelledprec C G$\ and $G\labelledprec C F$. We write $F\prec
G$\
($F\succ G$, $F\asymp G$) if there is a $C<\infty$\ such that
$F\labelledprec C G$\ ($F \labelledsucc C G$, $F \labelledasymp C
G$).
If $F\asymp G$, we say that $F$\ {\dt is equivalent to} $G$.
 
\proclaim Proposition 2.5. Let $F$\ and $G$\ be \af s, and $0<C<\infty$.
Then
\itemi $F\le CG \Leftrightarrow \tG \le C\tF$,
\itemii $F\labelledprec C G \Leftrightarrow \tG \labelledprec C \tF$,
\itemiii $F\le CG \Leftrightarrow \invG \labelledprec C \invF$.
 
\beginsection 2.1) Quasi-Orlicz Functions
 
\proclaim Definition 2.6. Let $F$\ be an \af.
\itemi Let $0<\rho<\infty$. The {\dt $\rho$-dilatory factor} of $F$\
is defined
to be
$$ D_\rho(F) = \sup \left\{\, {\invF(\rho^{-1} t)\over\invF(t)} :
   0 < \invF(t) < \infty \right\} .$$
\itemii We say that $F$\ is {\dt dilatory} if $D_\rho(F)<\infty$\
for all
$0<\rho<\infty$.
\itemiii Let $0<p<\infty$. We say that $F$\ is {\dt $p$-quasi-Orlicz}
if there
is a number $C<\infty$\ such that $D_\rho(F) \le C\rho^{-\invp}$\
for all
$0<\rho\le1$.
\itemiv Let $0<p<\infty$. We say that $F$\ is {\dt $p$-convex}, or
{\dt
$p$-Orlicz} if $F\circ T^\invp$\ is a convex function.
\endit
 
\proclaim Proposition 2.7. Let $F$\ be an \af. The following are
equivalent.
\itemi $F$\ is dilatory.
\itemii There is a $0<\rho<1$\ such that $D_\rho(F)<\infty$.
\itemiii There are $C_1$, $C_2 > 1$\ such that for all $t\in [0,\infty]$\
we
have $F(C_1 t) \ge C_2 F(t)$.
\itemiv There is a $0<p<\infty$\ such that $F$\ is $p$-quasi-Orlicz.
\itemv There is a $0<p<\infty$\ such that $F$\ is equivalent to a
$p$-convex
\af.
\moreproclaim\noindent
Furthermore the $p$\ that satisfy (iv) are the same as the $p$\ that
satisfy
(v).
 
\Proof (iv)$\Rightarrow$(i) and (i)$\Rightarrow$(ii)
are clear. (ii)$\Leftrightarrow$(iii) is easy. (ii)$\Rightarrow$(iv)
is a
simpler version of the argument given for Proposition~1.11. (v)$\Rightarrow$(iv)
is trivial. We show (iv)$\Rightarrow$(v).
 
Let $0<p<\infty$\ and $C<\infty$\ be such that $D_\rho(F) \le C \rho^{\invp}$,
that is, for all $u\ge1$\ and $0\le t\le \infty$, we have
$$ u^p F(t) \le F(Cut) . \eqno (2.1) $$
Define the function $G\colon[0,\infty]\to[0,\infty]$\ by
$$ \eqalignno{
   G(t)
   &= \sup_{u\le t} \left\{ \left( \left({t\over u}\right)^p -1 \right)
   F(u) \right\} \cr
   &= \sup_{u\in\R} \left\{ 0\v\left( \left({t\over u}\right)^p -1
\right)
   F(u) \right\} .\cr}$$
We see that $G\circ T^\invp$\ is the supremum of convex functions,
and so is
itself convex. We also see that $ G(t) \ge ((t/2^{-\invp}
t)^p-1)F(2^{-\invp}t) = F(2^{-\invp}t)$. Further, by equation $(2.1)$,
we have
that $ ((t/u)^p-1) F(u) \le F(Ct)$. Hence $G \asymp F$.
 
That $G$\ is admissible is now trivial to check.
\endproof
 
\beginsection 2.2) Admissible Functions that Satisfy the $\Delta_2$-Condition
 
\proclaim Definition 2.8. Let \Fbaaf. We say that $F$\ satisfies
the {\dt
$\Delta_2$-condition} if $\invF$\ is a dilatory \af.
 
We see from Proposition~2.7 that this definition is the same as that
given in
Section~1A:2.3.
 
\proclaim Proposition 2.9. Let $0<p<\infty$, and \Fbaaf\ that is
$p$-quasi
Orlicz and that satisfies the $\Delta_2$-condition. Then there is
a
$p\le q<\infty$, $C<\infty$, and an \af\ $G$\ such that
\itemi $F \labelledasymp C G$;
\itemii $G\circ T^\invp$\ is convex;
\itemiii $G\circ T^\invq$\ is concave.
 
\Proof
By replacing $F$\ by $F\circ T^\invp$, we may assume that $F$\ is
$1$-quasi
Orlicz, and by Proposition~2.7, we may assume that $F$\ is a convex
function. In
particular, we may assume that ${F(t) \over t}$\ increases as $t$\
increases.
 
None of this changes the fact that $F$\ satisfies the $\Delta_2$-condition.
By
Proposition~2.7, there is a $0<q<\infty$\ such that $\invF$\ is $\invq$-quasi
Orlicz, that is, there is a number $C<\infty$\ such that for all
$0<t<\infty$\
and $u\ge1$\ we have
$$ F(ut) \le C u^q F(t) .$$
(Thus it is clear that we must have $q\ge1$\ if $F$\ is to be convex.)
Define
the function $H$\ to be
$$ H(t) = \sup_{u\ge1} {F(ut) \over u^q} .$$
Clearly $F(t) \le H(t) \le CF(t)$, and as $F$\ is convex, this implies
that
$F\labelledasymp C H$. Furthermore, ${H(t)\over t}$\ increases with
$t$, and
${H(t) \over t^q}$\ decreases with $t$.
 
Now define the function $G$\ to be
$$ G(t) = \int_0^t {H(u) \over u} \,du .$$
Since ${H(u) \over u}$\ increases with $u$, we have
$$ G(t) \le t{H(t) \over t} = H(t) ,$$
$$ G(2t) \ge \int_t^{2t} {H(u) \over u} \,du \ge H(t) ,$$
so that $G\labelledasymp 2 H$. We also have that $G$\ is convex.
Furthermore,
$$ \eqalignno{
   G(t^\invq)
   &= \int_0^{t^\invq} {H(u) \over u} \,du \cr
   &= \ts\invq \int_0^t {H(u^\invq) \over u} \,du ,\cr}$$
which, being an integral of a decreasing function, is concave. It
is
now easy to show that $H$\ is admissible
\endproof
 
\beginsection 2.3) Families of Admissible Functions
 
Finally in this section, we define the following for later use.
 
\proclaim Definition 2.10. Let \Ibasms. A {\dt family of \af s}\onI\
is a sequence
$(\,F_t:t\in I)$, where for each $t\in I$, $F_t$\ is an \af.
 
\vfill
\eject
 
\beginsection 3) Functions from Spaces and Spaces from Functions
 
\beginsection 3.1) The Fundamental Function
 
\proclaim Definition 3.1. Let \Xbaris\onIzi. Define the {\dt
fundamental function}
$\Phi_X\colon[0,\infty]\to[0,\infty]$\ to be such that
$$ \invtPhi_X(t) = \normo{\chi_{[0,t]}}_x .$$
 
\proclaim Proposition 3.2. Let \Xbaris. Then $\Phi_X$\ is an \af.
If $X$\ is
dilatory, then so is $\Phi_X$. If $p_X>0$, then $\Phi_X$\ is $p_X$-convex.
 
\Proof This is trivial.
\endproof
 
We could also define $\Phi_X$\ when $X$\ is a \ris\onIAB\ where
$(A,B)\ne(0,\infty)$, by `joining the dots'. However we never have
any need to
do this.
 
\beginsection 3.2) The Orlicz Functional
 
Some of these ideas may also be found in
[B--S Ch.4 \S8], [K--R], [L--T1 Ch.4], [L--T2 p120] and [Mu].
 
\proclaim Definition 3.3. Let \Ibasms, and \Fbaaf. Define the
{\dt $L_F$-functional} (also called the {\dt $F$-Orlicz functional})
$\normdot_F$\
on $L_0(I)$\ to be
$$ \normo f_F =
   \sup \left\{ x : \int_I F\left(\ts{\modo{f(t)}\over x}\right)
\,d\lambda(t)
   > 1 \right\} .$$
Let the {\dt $F$-Orlicz space} be $L_F = L_F(I) = \{ f\in L_0(I)
: \normo f_F < \infty \}$.
 
\proclaim Proposition 3.4. Let \Ibasms, \Fbaaf, and $f\in L_0(I)$.
Then
\ditem{i)}$ \int_I F(\modf)\,d\lambda > 1 \Rightarrow \normo f_F
\ge 1$;
\ditem{ii)}$ \int_I F(\modf)\,d\lambda \le 1 \Rightarrow \normo f_F
\le 1$;
\ditem{iii)}$ \normo f_F > 1 \Rightarrow \int_I F(\modf)\,d\lambda
> 1 $;
\ditem{iv)}$ \normo f_F < 1 \Rightarrow \int_I F(\modf)\,d\lambda
\le 1 $.
\moreproclaim\noindent
Furthermore, if $F$\ satisfies the $\Delta_2$-condition, then
$$ \normo f_F = 1 \Leftrightarrow \int_I F(\modf)\,d\lambda = 1 .$$
 
\Proof These are straightforward to check.
\endproof
 
\proclaim Proposition 3.5. Let \Ibasms, and \Fbaaf. Then $L_F(I)$\
is a \ris. If
$F$\ is dilatory then $L_F(I)$\ is quasi-normed, and if $F$\ is
$p$-Orlicz then $L_F(I)$\ is $p$-convex. If $I=I_{0,\infty}$\ then
$\Phi_{L_F} = F$.
 
\Proof First we show that $L_F(I)$\ is a \ris. The only problems
in checking
Definition~1.3 are properties~(iv) and~(v). To check (iv), suppose
that
$f_n\nearrow f$, with $\normo f_F>1$. Then we have
$$ \int_I F(\modf) \,d\lambda > 1.$$
Since $F$\ is left continuous, $F(\modo{f_n})
\nearrow F(\modf)$, and so by the monotone
convergence theorem, there is a $N\in\N$\ such that for all $n\ge
N$\ we have
$$ \int_I F(\modo{f_n}) \,d\lambda > 1.$$
But this implies that $\normo{f_n}_F \ge 1$, and we are done.
 
To check (v), let $\epsilon>0$, and set $\delta=\epsilon/\invF(\invepsilon)$\
(notice that by property~(v) of Definition~2.1 we have $\delta>0$).
If $\normo{f_n}_F\to0$\ as $n\to\infty$, then there
is a $N\in\N$\ such that for all $n\ge N$\ we have $\normo{f_n}_F
< \delta$, that
is,
$$ \int_I F\left(\ts{\modo{f_n}\over\delta}\right) \,d\lambda \le
1.$$
Let $A = \{\, t\in I : F(\modo{f_n}/\delta) \ge \invepsilon \}$.
Then
$\lambda(A) \le \epsilon$, and if $t\not\in A$, then $\modo{f_n}
\le \delta
\invF(\invepsilon) = \epsilon$. Hence $\lambda\{\, t\in I : \modo{f_n(t)}
>
\epsilon \} \le \epsilon$. Thus $f_n \to 0$\ in the measure topology.
 
Now suppose that $F$\ is $p$-Orlicz. We show that $L_F$\ is
$p$-convex. It is sufficient to show the following. If $\normo{f_1}_F$,
$\normo{f_2}_F,\ldots,$\ $\normo{f_N}_F < 1$, and $u_1$,
$u_2,\ldots,$\ $u_N \in [0,1]$\ with $\sumN u_n^p = 1$, then
$\normo{\sumN u_n \modo{f_n}} \le 1$. But then
$$ \eqalignno{
   \int_I F\left(\ts{\sumN u_n \modo{f_n}} \right) \,d\lambda
   &\le \sumN u_n^p \int_I F(\modo{f_n}) \,d\lambda \cr
   &\le 1 ,\cr}$$
and the result follows.
\endproof
 
\proclaim Proposition 3.6. Let $F$\ and $G$\ be \af s, and $0<C<\infty$.
If
$F\labelledprec C G$, then $\normdot_F\le C\normdot_G$.
 
\Proof This is trivial to check.
\endproof
 
\proclaim Definition 3.7. Let \Ibasms, \Xbaris\onI, and \Fbaaf. Define
the
{\dt $X\circ F$-functional} $\normdot_{X\circ F}$\ on $L_0(I)$\ to
be
$$ \normo f_{X\circ F} =
   \sup \left\{\, x : \normo{ F\left(\ts{\modo f\over x}\right) }_X
> 1 \right\}
   .$$
 
\proclaim Proposition 3.8. Let \Ibasms, \Xbaris\onI, and \Fbaaf.
Then
$X\circ F$\ is a \ris\onI.
 
\Proof As Proposition~3.5.
\endproof
 
\beginsection 3.3) The Weak Orlicz Functional
 
\proclaim Definition 3.9. Let \Ibasms, and \Fbaaf. Define the
{\dt $L_{F,\infty}$-functional} (also called the {\dt $F$-weak Orlicz
functional})
$\normdot_{F,\infty}$\ on $L_0(I)$\ to be
$$ \normo f_{F,\infty} =
   \sup \{ f^*(t) \invtF(t) : 0<t<\infty \} .$$
Let the {\dt $F$-weak Orlicz space} be $L_{F,\infty} = L_{F,\infty}(I)
= \{ f\in L_0(I) : \normo f_{F,\infty} < \infty \}$.
 
\proclaim Proposition 3.10. Let \Ibasms, and \Fbaaf. Then $L_{F,\infty}(I)$\
is
a \ris. If $F$\ is dilatory then $L_F(I)$\ is quasi-normed, and if
$F$\ is
$p$-quasi-Orlicz then $L_F(I)$\ is $(p,\infty)$-convex. If $I=I_{0,\infty}$\
then $\Phi_{L_F} = F$.
 
\Proof These are all elementary.
\endproof
 
\proclaim Proposition 3.11. Let $F$\ and $G$\ be \af s, and $0<C<\infty$.
If
$F\labelledprec C G$, then $\normdot_F\le C\normdot_G$.
 
\Proof This is trivial.
\endproof
 
\proclaim Proposition 3.12. Let \Xbaris\onIzi. Then $\normdot_{\Phi_X,\infty}
\le
\normdot_X$.
 
\Proof Let $f\in L_0(I)$, and $t\in I$. Then
$$f^*(t) \chi_{[0,t]} \le f^* ,$$
and the result follows by taking $\normdot_\Phi$\ of both sides.
\endproof
 
\beginsection 3.4) Families of Admissible Functions.
 
This definition is similar to what may be found in [Mu Ch.2 \S7].
 
\proclaim Definition 3.13. Let \Ibasms, and $(\,F_t:t\in I)$\ be
a family of
admissible functions. Define the {\dt $L_{(F_t)}$-functional}
$\normdot_{(F_t)}$\ on $L_0(I)$\ to be
$$ \normo f_{(F_t)} =
   \sup \left\{ x : \int_I F_t\left(\ts{\modo{f(t)}\over x}\right)
\,d\lambda(t)
   > 1 \right\} .$$
 
Note that $\normdot_{(F_t)}$\ will not necessarily be a \rif.
 
\vfill
\eject
 
\beginsection 4) Un-$L_\infty$\ and Normal Spaces and Functions
 
As far as I know, these results are new.
 
\proclaim Definition 4.1. An \af\ $F$\ is said to be {\dt un-$L_\infty$}
if
$F(t)=0$\ only if $t=0$, and $F(t)=\infty$\ only if $t=\infty$. We
say that
$F$\ is {\dt normal} if in addition, $F$\ is continuous and strictly
increasing.
\moreproclaim
If $X$\ is a \ris\onIzi\ then $X$\ is said to be {\dt un-$L_\infty$}\
({\dt
normal}) if $\Phi_X$\ is un-$L_\infty$\ (normal).
 
\proclaim Proposition 4.2. Let $X$\ be an un-$L_\infty$, $(p,q)$-convex,
\ris\onIzi, where $0<p<\infty$\ and $p\le q\le\infty$. Then there
is a normal,
quasi-normed, \ris\onIzi, $Y$, such that
$$ \smallhalf\normdot_Y \le \normdot_X \le C_{p,q}(X) \normdot_Y
.$$
 
\Proof By Proposition~1.8, there is a \ris\ $X_1$\ with $C_{p,q}(X_1)=1$\
and $\normdot_{X_1} \le \normdot_X \le C_{p,q}(X) \normdot_{X_1}$.
As
$C_{p,q}(X_1)=1$, we have
$\normo{\chi_{[0,s+t]}}_{X_1}^p \le \normo{\chi_{[0,s]}}_{X_1}^p
+
\normo{\chi_{[0,t]}}_{X_1}^p $, that is
$$ \bigl(\invtPhi_{X_1}(s+t)\bigr)^p \le \bigl(\invtPhi_{X_1}(s)\bigr)^p
                                     + \bigl(\invtPhi_{X_1}(t)\bigr)^p
.$$
Since $X$\ is un-$L_\infty$, $\invtPhi_{X_1}(t)\to0$\ as $t\to0$,
and therefore
$\invtPhi_{X_1}$\ is continuous.
 
Also, by Proposition~2.7 there is a $p$-convex \af\ $G\asymp \Phi_{X_1}$.
Since
$G$\ is un-$L_\infty$, it is continuous and strictly increasing.
So let
$$ \normdot_Y = \normdot_{X_1} + \epsilon\normdot_{G,\infty} ,$$
where $\epsilon>0$\ is such that $\epsilon\normdot_{G,\infty} \le
\normdot_X$. Then
$$ \invtPhi_Y = \invtPhi_{X_1} + \epsilon\invtG ,$$
which is continuous and strictly increasing. The result follows.
\endproof
 
\proclaim Corollary 4.2a. Let $F$\ be a un-$L_\infty$, dilatory,
\af. Then there
is an equivalent normal, dilatory, \af.
 
\Proof Let $X=L_F(I_{0,\infty})$, and choose $Y$\ as in Proposition~4.2.
Then
the desired function is $\Phi_Y$.
\endproof
 
Normal \af s have nice properties: if $F$\ and $G$\ are normal \af
s, then so
is $F\circ G$; and if $F$\ is a normal \af, then so are $\tF$\ and
$\invF$, with
$F\circ\invF=\invF\circ F=\Id_{[0,\infty]}$.
 
\vfill
\eject
 
\beginsection 5) Generalized Lorentz Spaces
 
Now we come to define the main object of interest of Part~3. The
motivation for their
definition arises as follows.
Let \Fbaaf, and \Xbaris\onIzi. We desire to define a \ris\onIzi,
called $L_{F,X}$\
such that $L_{T^p,L_q}$\ is the Lorentz space $L_{p,q}$. Thus we
would
like $\Phi_{L_{X,F}} = F$, and for $L_{X,F}$\ to `glue' together
like $X$. Two
definitions that immediately suggest themselves are the following.
\itemi Let $\omega\colon I_{0,\infty}\to\R_+$\ be such that
$\normo{\omega\chi_{[0,t]}}_X = \invtF(t)$. Define
$$ \normo f_{X,F} = \normo{\omega f^*}_X .$$
\itemii Let $\Omega\colon I_{0,\infty}\to I_{0,\infty}$\ be such
that
$\normo{\chi_{[0,t]}\circ\Omega}_X = \invtF(t)$. Define
$$ \normo f_{X,F} = \normo{f^*\circ\Omega}_X .$$
 
\noindent If $X=L_q$, then both definitions give the same space,
(with $\omega(t) = ((\Omega^{-1})'(t))^\invq$).
We also have the same space if $X=L_F$, then both definitions give
$L_{X,F}=L_F$.
 
We will make use of the second definition. This is because it is
easy to see that $\Omega$\ should be
$\tF\circ\invtPhi_X$; it is not at all clear what $\omega$\
should be.
 
\proclaim Definition 5.1. Let \Ibasms, \Xbanris\onIzi, and \Fbanaf.
Define the
{\dt $L_{F,X}$-functional} (also called the {\dt generalized $F$-Lorentz
functional})
$\normdot_{F,X}$\ on $L_0(I)$\ to be
$$ \normo f_{F,X} = \normo{f^*\circ\tF\circ\invtPhi_X}_X .$$
Let the {\dt generalized $F$-Lorentz space} be
$$ L_{F,X} = L_{F,X}(I) = \{ f\in L_0(I) : \normo f_{F,X} < \infty
\} .$$
 
\proclaim Proposition 5.2. Let \Ibasms, \Xbanris\onIzi, and \Fbanaf.
Then
$L_{X,F}(I)$\ is a \ris. Furthermore we have the following properties.
\itemi If $I=I_{0,\infty}$, then $\Phi_{L_{F,X}} = F$.
\itemii $L_{\Phi_X,X} = X$.
\itemiii $L_{F,L_F} = L_F$.
\itemiv If $G$\ is a normal \af, then $L_{F,L_{G,X}} = L_{F,X}$.
 
\Proof These are all straightforward to check.
\endproof
 
\proclaim Proposition 5.3. Let $X$\ be a normal, quasi-normed \ris\onIzi,
and
\Fbanaf. Then $L_{F,X}$\ is quasi-normed if and only if it is
dilatory.
 
\Proof If $f,g\in L_0$, then $(f+g)^* =
f^*\circ d_\half + g^*\circ d_\half$. Thus, if $L_{F,X}$\ is dilatory,
it follows straight away from
Definition~5.1 that $Q(L_{F,X}) \le D_\half(L_{F,X})Q(X)$.
The converse implication follows by Propositions~1.12 and~3.2.
\endproof
 
\proclaim Proposition 5.4. Let $X$\ and $Y$\ be normal \ris s\onIzi,
and $F$\ and
$G$\ be normal \af s. Suppose that $X$\ and $Y$\ are approximately
equal, that
$F$\ and $G$\ are equivalent, and that $L_{1,X}$\ is dilatory. Then
$L_{F,X}$\
and $L_{G,Y}$\ are approximately equal.
 
\Proof Let $C<\infty$\ be such that $X \labelledapprox C Y$, and
$F \approx C
G$. Then for all $f\in L_0$, we have
$$ \eqalignno{
   \normo f_{G,Y}
   &= \normo{f^*\circ \tG\circ\invtPhi_Y}_Y \cr
   &\le C \normo{f^*\circ\tF\circ d_{C^{-2}}\circ\invtPhi_X}_X\cr
   &\le C\, D_{C^{-2}} (L_{1,X})\, \normo f_{F,X} ,\cr}$$
and
$$ \eqalignno{
   \bigl( C D_{C^{-2}}(L_{1,X})\bigr)^{-1} \normo f_{F,X}
   &\le C^{-1} \normo{f^*\circ\tF\circ d_{C^{-2}}\circ\invtPhi_X}_X
\cr
   &\le \normo{f^*\circ\tG\circ\invPhi_Y}_Y \cr
   &= \normo f_{G,Y} .\cr}$$
\endproof
 
We consider the problem of whether $L_{F,X}$\ is dilatory in Chapter~3C.
However, we present the following simple result.
 
\proclaim Proposition 5.5. Let $X$\ be a normal, quasi-normed \ris\onIzi,
and
$F$\ be a normal \af. If $F$\ satisfies the $\Delta_2$-condition,
then $L_{F,X}$\ is
dilatory.
 
\Proof This is trivial.
\endproof
 
\proclaim Proposition 5.6. Let \Xbanris\onIzi, and $F$\ and $H$\
be normal \af s.
Then $L_{F,X}\circ H = L_{F\circ H,X\circ H}$.
 
\Proof This is easy to check.
\endproof
 
\vfill
\eject
 
\beginsection Chapter 3B --- Inequalities
 
\beginsection 1) H\"older's Inequality Generalized
 
In this section we investigate a well known generalization of H\"older's
inequality. However, our approach is quite different to that usually
presented
(see [B--S Ch.4], [K--R Ch.4 \S9], [L--T1 4.b] or [Mu Ch.2 \S13]).
 
\beginsection 1.1) Complementary Functions and Dual Spaces
 
\proclaim Definition 1.1. Let $F$, $G$\ and $H$\ be \af s. We say
that $F$\ and
$G$\ are {\dt complementary with respect to $H$}\ if there is a number
$C<\infty$\ such that
$$ \invH \labelledapprox C \invF\invG .$$
If $H=\Id_{[0,\infty]}$, we simply say that $F$\ and $G$\ are {\dt
complementary}.
\moreproclaim
If $F$\ is an \af\ such that $\Ftot$\ is increasing with $t$, we
define the
{\dt complementary function} $\sF$\ to be an \af\ such that
$$ \invF \invsF = \Id_{[0,\infty]} .$$
 
\proclaim Definition 1.2. Let $X$, $Y$\ and $Z$\ be \ris s. We say
that $X$\ and
$Y$\ are {\dt sub-dual with respect to $Z$}\ if there is a number
$C<\infty$\ such that for all $f$, $g\in L_0$\ we have
$$ \normo{fg}_Z \le C \normo f_X \normo f_Y .$$
We say that $X$\ and $Y$\ are {\dt dual with respect to $Z$}\ if
in addition we
have
\itemi given $f\in X\setminus\{0\}$\ there is a $g\in Y\setminus\{0\}$\
such
that $\normo{fg}_Z \ge \invC \normo f_X \normo f_Y$;
\itemii given $g\in Y\setminus\{0\}$\ there is a $f\in X\setminus\{0\}$\
such
that $\normo{fg}_Z \ge \invC \normo f_X \normo f_Y$.
\endit
 
\beginsection 1.2) H\"older's Inequality Generalized
 
\proclaim Theorem 1.3. Let $X$\ be a quasi-normed \ris,
$F$\ and $G$\ be normal \af s and $H$\ be a normal dilatory \af.
If $F$\ and $G$\
are complementary with respect to $H$, then $X\circ F$\ and $X\circ
G$\ are
sub-dual with respect to $X\circ H$. If, in addition, $F$\ and $G$\
satisfy the
$\Delta_2$-condition, then $X\circ F$\ and $X\circ G$\ are dual with
respect to
$X\circ H$.
 
Note that we do not need $F$, $G$\ and $H$\ to be normal, but it
does make the
proof simpler to assume that they are.
 
\Proof Let $C<\infty$\ be such that $\invH \labelledapprox C \invF
\invG$.
First we show that there is a constant $C_1<\infty$\ such that for
all
$u,v\in[0,\infty]$\ we have
$$ H(C_1^{-1}uv) \le F(u) + G(v) .$$
Let $s=F(u)$\ and $t=G(v)$. Then $ uv = \invF(s)\invG(t) \le
\invF(s\v t)\invG(s\v t) \le C \invH(s\v t) \le C \invH(s+t) $, and
we have the
result.
 
Now we show that there is a constant $C_2<\infty$\ such that for
all
$f,g\in L_0$\ we have
$$ \normo{fg}_{X\circ H} \le C_2 \normo f_{X\circ F} \normo g_{X\circ
G} ,$$
for suppose that $\normo f_{X\circ F}$, $\normo g_{X\circ G} <1$.
Then
$$ \eqalignno{
   \normo{H(C_1^{-1}\modo{fg})}_X
   &\le \normo{F(\modo f) + G(\modo g)}_X \cr
   &\le Q(X) (\normo{F(\modo f)}_X + \normo{G(\modo g)}_X ) \cr
   &\le 2Q(X) . \cr}$$
Hence
$$ \normo{ H( \ts{1\over C_1 D_{(2Q(X))^{-1}}(H)} \modo{fg} )}_X
\le 1 ,$$
and so $\normo{fg}_{X\circ H} \le C_1 D_{(2Q(X))^{-1}}(H)$, as desired.
 
Now suppose that $F$\ and $G$\ satisfy the $\Delta_2$-condition (so
that $H$\
also satisfies the $\Delta_2$-condition).
We show that there is a number $C_3<\infty$\ such that if
$f\in X\circ F\setminus\{0\}$, then there is a $g\in X\circ G\setminus\{0\}$\
with $\normo{fg}_{X\circ H} \ge C_3^{-1} \normo f_{X\circ F} \normo
g_{X\circ
G} $. For suppose that $\normo f_{X\circ F} = 1$. Let $k=F(\modo
f)$\ (so that
$\modo f = \invF(k)$) and $g=\invG(k)$. By Proposition~3A:3.4, we
have that
$\normo k_X=1$, $\normo
g_{X\circ G}=1$, and $\normo{\invH(k)}_{X\circ H} = 1$. Therefore,
$$ \normo{fg}_{X\circ H} = \normo{\invF(k)\invG(k)}_{X\circ H}
   \ge C^{-1} \normo{H^{-1}(k)}_{X\circ H}
   = C^{-1} .$$
 
Similarly, there is a number $C_4<\infty$\ such that if
$g\in X\circ G\setminus\{0\}$, then there is a $f\in X\circ F\setminus\{0\}$\
with $\normo{fg}_{X\circ H} \ge C_4^{-1} \normo f_{X\circ F} \normo
g_{X\circ
G} $.
\endproof
 
\beginsection 1.3) Families of Admissible Functions
 
\proclaim Theorem 1.4. Let \Ibasms, and $(\,F_t:t\in I)$\ be a family
of \af
s\onI\ such that for each $t\in I$\ we have that $F_t$\ is normal
and that
$\Ftuou$\ is increasing with $u$. Let $(\,\sF_t:t\in I)$\ be a family
of
admissible functions, where for each $t\in I$, $\sF_t$\ is the complementary
function of $F_t$. Then for all $f,g\in L_0(I)$\ we have
$$ \normo{fg}_1 \le c \normo{f}_{(F_t)} \normo g_{(\sF_t)} .$$
 
\Proof As Theorem~1.3.
\endproof
 
\vfill
\eject
 
\beginsection 2) The Second Index of Generalized Lorentz Functions
 
In this section we find inequalities between $L_{F,G_1}$\ and $L_{F,G_2}$,
and
between $L_{F,G}$\ and $L_{F,\infty}$, where $F$, $G$, $G_1$\ and
$G_2$\ are
normal \af s. This work extends results due to Bennett and Rudnick
(see [B--R]
or [B--S Ch.4 \S6]).
 
\beginsection 2.1) Inequalities Between $L_{F,G_1}$\ and $L_{F,G_2}$
 
In this section we are going to compare $L_{F,G}$\ with $L_{F,H\circ
G}$, where
$F$, $G$\ and $H$\ are normal \af s, and $H$\ is $1$-quasi Orlicz.
 
\proclaim Theorem 2.1. Let $F$, $G$\ and $H$\ be normal \af s such
that $G$\ is
dilatory, and $H$\ is
$1$-quasi Orlicz. Then there is a number $C<\infty$, depending on
$H$\ and
$D_\half(G)$\ only,
such that
$$ \normdot_{F,H\circ G} \le C \normdot_{F,G} .$$
 
\Proof First we show that for some number $C_1<\infty$\ that$\normdot_H
\le C_1
\normdot_{H,1}$.
 
For all $f\in L_0$\ we have
$$ \eqalignno{
   \normo f_{H,1}
   &= \int_0^\infty f^*\circ\tH(t) \,dt \cr
   &= \int_0^\infty f^*(t) \,d\invtH(t) \cr
   &= \int_0^\infty \invtH(t) \,d(-f^*(t)) \cr
   &= \int_0^\infty \normo{\chi_{[0,t]}}_H \,d(-f^*(t)) \cr}$$
and as $\normdot_H$\ is $1$-convex, there is a number $C_1<\infty$,
depending on
$H$\ only, such that the above is
$$ \eqalignno{
   \phantom{ \normo f_{H,1}}
   &\le C_1 \normo{\int_0^\infty \chi_{[0,t]} \,d(-f^*(t))}_H \cr
   &= C_1 \normo{f^*}_H . \cr}$$
Now, as $G$\ is dilatory, we have for some number $C_2<\infty$\ that
$$ \normdot_{H\circ G,H\circ G} = \normdot_{L_{H,G}}
   \le C_2 \normdot_{L_{H,1}\circ G} = C_2 \normdot_{H\circ G,G}
,$$
and hence for all $f\in L_0$\ we have
$$ \eqalignno{
   \normo f_{F,H\circ G}
   &= \normo{f\circ \tF\circ(\tH\circ\tG)^{-1}}_{H\circ G,H\circ
G} \cr
   &\le C_2 \normo{f\circ\tF\circ(\tH\circ\tG)^{-1}}_{H\circ G,G}
\cr
   &= C_2 \normo f_{F,H\circ G} .\cr}$$
\endproof
 
For the next theorem, we need an elementary definition and lemma.
 
\proclaim Definition 2.2. Suppose $F$\ is a normal \af. We denote
by $F'$\ the unique
left continuous function $(0,\infty)\to[0,\infty]$\ such that
$$ F(t) = \int_0^t F'(u) \,du . $$
 
\proclaim Lemma 2.3. Suppose $F$\ is a normal $p$-convex \af, where
$0<p<\infty$.
Then there is a number $C<\infty$, depending on $p$\ only, such that
for all
$0<t<\infty$, we have
$$ p{F(t)\over t} \le F'(t) \le C{F(Ct)\over t} .$$
 
\Proof Let $G=F\circ T^\invp$, so that $G$\ is convex. It is well
known that
$G'$\ is increasing, and that $F'(t) = pt^{p-1} G'(t^p)$.
 
First we prove the left hand inequality. For all $0<t<\infty$, we
have
$$ \eqalignno{
   F(t)
   &= p \int_0^t u^{p-1} G'(u^p) \,du \cr
   &\le p \int_0^t u^{p-1} G'(t^p) \,du \cr
   &= t^p \, G'(t^p) \cr
   &= \ts\invp \, t \, F'(t) .\cr}$$
For the right hand inequality, for all $0<t<\infty$, we have
$$ \eqalignno{
   (1-2^{-p}) \, F(2t)
   &\ge F(2t) - F(t)  \cr
   &= p \int_t^{2t} u^{p-1} G'(u^p) \,du \cr
   &\ge p \int_t^{2t} u^{p-1} G'(t^p) \,du \cr
   &= (2^p-1) \, t^p \, G'(t^p) \cr
   &= (2^p-1) \, \ts\invp \, t\,  F'(t) .\cr}$$
\endproof
 
\proclaim Theorem 2.4. Let $F$, $G$\ and $H$\ be normal \af s such
that $G$\ is
dilatory, and $H$\ is
$1$-convex. If $\norminvsHsH <\infty$, then there is a number $C<\infty$\
such
that
$$ \normdot_{F,G} \le C \normdot_{F,H\circ G} .$$
 
\Proof First we show that $ \normdot_1 \le c
\norminvsHsH \normdot_{1,H} $. Suppose that $\normo f_{1,H} < 1$.
Then
$$ \int_0^\infty H(f^*(t)) \tH'(t) \,dt
   = \int_0^\infty H\circ f^* \invtH(t) \,dt  \le 1 .$$
So, if we let $(\,H_t:t\in I_{0,\infty})$\ be the family of admissible
functions defined
by
$ H_t(u) = \tH'(t) H(u) $, then the above says that $\normo f_{(H_t)}
\le 1$.
Now it is easy to see that
$$ \sH_t(u) = \tH'(t) \sH \left(\ts{u\over\tH'(t)}\right) .$$
So by Theorem~1.4 we have
$$ \normo f_1 \le c \normo f_{(H_t)} \normo 1_{(\sH_t)}
              \le c \normo 1_{(\sH_t)} .$$
Thus we only need to show that $\normo 1_{(\sH_t)} \le \norminvsHsH
$.
This follows, as if $\normo 1_{(\sH_t)} > x $, then by
Proposition~3A:3.4, we have that
$$ \eqalignno{
   1
   &< \int_0^\infty \sH_t \left(\ts{1\over x}\right) \,dt \cr
   &= \int_0^\infty \sH \left(\ts{1\over x\tH'(t)}\right) \,d\tH(t)
.\cr}$$
By Lemma~2.3, this is
$$ \eqalignno{
   &\le \int_0^\infty \sH \left(\ts{t\over x\tH(t)}\right)
   \,d\tH(t) \cr
   &= \int_0^\infty \sH \left(\ts{\invtH(t)\over xt}\right) \,dt
\cr
   &= \int_0^\infty \sH \left(\ts{1\over x\invtsH(t)}\right) \,dt
.\cr}$$
This implies that $\norminvsHsH \ge x$, as desired.
 
Finally, the result follows as in the end of the proof of Theorem~2.1.
\endproof
 
\beginsection 2.2) Inequalities Between $L_{F,G}$\ and $L_{F,\infty}$
 
By Proposition~3A:3.12, we already know that if $F$\ and $G$\ are
normal \af s, then
$\normdot_{F,\infty} \le \normdot_{F,G}$. We also have the following
result.
 
\proclaim Theorem 2.5. Let $F$\ and $G$\ be normal \af s. Then
$$ \normdot_{F,G} \le \ts\norminvGG \normdot_{F,\infty} .$$
 
\Proof Suppose that $\normo f_{F,\infty} \le 1$. Then $f^* \le
{1\over\invtF}$, and so $\normo f_{F,G} \le \norminvGG $.
\par \endproof
 
\beginsection 2.3) Applications of these Inequalities
 
Now we prove Theorem~1A:2.7.
 
\proclaim Lemma 2.6. Let $L \asymp \em(T^\beta)$, where $\beta>0$.
Then
$\norminvLL$\ is finite.
 
\Proof It follows straight away from Definition~3A:3.3 that we need
only show that for
some $x>0$ we have
$$ \int_0^\infty \em\ts{\left(\left({1\over x(\lm t)^{\invbeta}}
\right)^\beta
   \right)} \,dt < 1.$$
Let us assume that $x\ge1$. Then
$$ \eqalignno{
   \int_0^\infty \em\ts{\left(\left({1\over x(\lm t)^\invbeta} \right)^\beta
   \right)} \,dt
   &= \int_0^\infty \em\left(\ts{1\over x^\beta \lm t} \right) \,dt
\cr
   &= \int_0^{e^{1-x^\beta}}
   \exp \left( \ts{1+\log\invt\over x^\beta} -1 \right) \,dt \cr
   &\phantom{=} + \int_{e^{1-x^\beta}}^1
   \exp \left( 1- \ts{x^\beta\over1+\log\invt} \right) \,dt \cr
   &\phantom{=} + \int_1^\infty
   \exp \left( 1- x^\beta (1+\log t) \right) \,dt \cr
   &\le e^{(1/x^\beta)-1} \int_0^{e^{1-x^\beta}} t^{-1/x^\beta} \,dt
   + (1-e^{1-x^\beta}) e^{1-x^\beta} \cr
   &\phantom{=} + e \int_1^\infty (et)^{-x^\beta}\,dt \cr
   &\le e^{(2/x^\beta)-1-x^\beta} {x^\beta\over x^\beta-1} + e^{1-x^\beta}
   + e^{2-x^\beta} {1\over x^\beta-1} ,\cr }$$
and this tends to $0$\ as $x\to\infty$.
\endproof
 
\proclaim Theorem 2.7. (Bennett and Rudnick) Let $p<0<\infty$, and
$\alpha\in\R$.
\itemi There is a number $C<\infty$, depending on $p$\ and $\alpha$,
such that
$$ \normdot_{T^p(\lm T)^\alpha}
   \labelledapprox C \normdot_{T^p(\lm T)^\alpha,p} .$$
\itemii There is a number $C<\infty$, depending on $p$\ only, such
that
$$ \normdot_{\em(T^p)}
   \labelledapprox C \normdot_{\em(T^p),\infty} .$$
 
\proof of i): First we consider the case when $\alpha>0$. Let $H=T(\lm
T^\invp)^\alpha$. Then $H$\ is $1$-quasi Orlicz, and so by Theorem~2.1,
we have
for some $C<\infty$\ that
$$ \normdot_{T^p(\lm T)^\alpha,H\circ T^p}
   \le C \normdot_{T^p(\lm T)^\alpha,T^p} .$$
Furthermore, ${H(t)\over t}$\ is increasing with $t$, and $\sH
\equiv \em(T^{1\over\alpha})$. Hence, by Theorem~2.4 and Lemma~2.6,
we have for
some $C<\infty$\ that
$$ \normdot_{T^p(\lm T)^\alpha,T^p}
   \le C \normdot_{T^p(\lm T)^\alpha,H\circ T^p} .$$
Finally, as $ \normdot_{T^p(\lm T)^\alpha,H\circ T^p} =
\normdot_{T^p(\lm T)^\alpha}$, we are done.
 
The case $\alpha<0$\ follows by a similar argument, this time using
the
function $H$\ such that $H\circ T^p(\lm T)^\alpha = T^p$.
\endproof
 
\proof of ii): This follows immediately from Proposition~3A:3.12,
Theorem~2.5 and
Lemma~2.6.
\endproof
 
Obviously, we could prove a great many more inequalities of this
form than we
have given here.
 
\vfill
\eject
 
\beginsection 3) A Result about Orlicz Spaces
 
Here we prove Proposition~1A:2.3(ii).
 
\proclaim Proposition 3.1. (See also [K--R Thm.8.1] and [L--T1 4.a.5].)
Let $F$\ and $G$\ be \af s such that $F$\ is
dilatory, and $0\le A<\infty$, $0<B\le\infty$\ with $A\le B$. Then
there is a
number $C<\infty$, depending on $D_\half(F)$\ only, such that if
$\invtF(t) \le
\invtG(t)$\ for $A\le t\le B$, then for all $f\in L_0(I_{A,B})$\
we have
$\normo f_F \le C \normo f_G$.
 
\Proof
Let $f\in L_0(I_{A,B})$\ be such that $\normo f_G <1$, so that
$$ \int_{I_{A,B}} G(\modo{f(t)}) \,d\lambda(t) \le 1.$$
First we show that $\sup_{t\in I_{A,B}} G(\modo{f(t)}) \le {1\over
A}$, and so
values of $\invtF(t)$\ and $\invtG(t)$\ for $t<A$\ are immaterial.
This is
obvious if $A=0$; otherwise the above integral becomes the sum
$$ \sum_{I_{A,B}} A G(\modo{f(t)}) \le 1 ,$$
and we are done.
 
Now, if $G(\modo{f(t)}) \ge {1\over B}$, then $F(\modo{f(t)}) \le
G(\modo{f(t)})$, and if $G(\modo{f(t)}) \le {1\over B}$, then $F(\modo{f(t)})
\le {1\over B}$. Let
$$ J = \{\, t\in I_{A,B} : G(\modo{f(t)}) \le \ts{1\over B} \}.$$
Then
$$ \int_{I_{A,B}\setminus J} F(\modo{f(t)}) \,d\lambda(t)
   \le \int_{I_{A,B}} G(\modo{f(t)}) \,d\lambda(t)
   \le 1, $$
and
$$ \int_J F(\modo{f(t)}) \,d\lambda(t) \le \ts{1\over B} \lambda(I_{A,B})
   \le 1.$$
Therefore
$$ \int_{I_{A,B}} F(\modo{f(t)}) \,d\lambda(t) \le 2,$$
and so $\normo f_F \le D_\half(F)$.
\endproof
 
\vfill
\eject
 
\beginsection Chapter 3C --- Boyd Indices of Generalized Lorentz
Spaces
 
\beginsection 1) Introduction
 
In this chapter, I present preliminary work on an important question
about the generalized Lorentz spaces.
 
\proclaim Question 1.1. Let $X$\ be a normal quasi-normed \ris\onIzi,
and
$F$\ be a normal dilatory \af. Is $L_{F,X}$\ dilatory?
 
\noindent
(We know by Proposition~3A:5.5 that this is so if $\Phi_X$\ satisfies
the
$\Delta_2$-condition.)
 
We will concentrate most of our investigation on the case when $X=L_G$,
where
$G$\ is a normal dilatory \af. We will also consider the following
questions.
 
\proclaim Question 1.2. Let $X$\ be a normal quasi-normed \ris\onIzi,
and
$F$\ be a normal dilatory \af. Is it true that $p_{L_{F,X}} = \sup\{\,p:F$\
is
$p$-quasi Orlicz$\}$?
 
\proclaim Question 1.3. Let $X$\ be a normal quasi-normed \ris\onIzi,
and
$F$\ be a normal dilatory \af. Is it true that $q_{L_{F,X}} = \inf\{\,q:F\circ
T^\invq$\ is
equivalent to a concave function$\}$?
 
Positive answers to the last two questions have many applications.
We do not go
into this, but the reader is referred to [B--S Ch.3] and [L--T2 2.b].
For
general $X$, the answer to the last two questions is negative, for
we have the
following result due to T.~Shimogaki.
 
\proclaim Theorem 1.4. (See [Sh].) There is a $1$-convex \ris\ $X$\
such that
$\Phi_X = T^2$, but $p_X=1$\ and $q_X=\infty$.
 
In considering all these questions, it is sufficient to look only
at $L_{1,X}$,
for we have the following result.
 
\proclaim Proposition 1.5. Let $X$\ be a normal quasi-normed \ris\onIzi,
and
$F$\ be a normal dilatory \af.
\itemi If $L_{1,X}$\ is dilatory, then so is $L_{F,X}$.
\itemii If $p_{L_{1,X}} = 1$, then $p_{L_{F,X}} = \sup\{\,p:F$\ is
$p$-quasi Orlicz$\}$.
\itemiii If $q_{L_{1,X}} = 1$, then $q_{L_{F,X}} = \inf\{\,q:F\circ
T^\invq$\
is equivalent to a concave function$\}$.
\endit
 
\Proof First we show that $p_{L_{F,X}} \le \sup\{\,p:F$\ is $p$-quasi
Orlicz$\}$. For if $0<\rho\le1$, then
$$ \eqalignno{
   D_\rho(L_{L,F})
   &= \sup \left\{\, {\normo{D_\rho(f)}_{F,X} \over \normo{f}_{F,X}}
   : 0 < \normo{f}_{F,X} < \infty \right\} \cr
   &\ge \sup \left\{\, {\normo{D_\rho(\chi_{[0,t]})}_{F,X} \over
   \normo{\chi_{[0,t]}}_{F,X}}
   : 0 < t < \infty \right\} \cr
   &= \sup \left\{\, {\invtF(\rho t) \over \invtF(t)}
   : 0 < t < \infty \right\} \cr
   &= \sup \left\{\, {\invF(\rho t) \over \invF(t)}
   : 0 < t < \infty \right\} \cr
   &= D_\rho(F) .\cr}$$
The result follows.
 
Now we note that
$$ \eqalignno{
   D_\rho(L_{F,X})
   &= \sup \left\{\, {\normo{D_\rho(f)}_{F,X} \over \normo{f}_{F,X}}
   : 0 < \normo{f}_{F,X} < \infty \right\} \cr
   &= \sup \left\{\, {\normo{f^*\circ d_\rho\circ\tF}_{1,X} \over
   \normo{f^*\circ\tF}_{1,X}}
   : 0 < \normo{f}_{F,X} < \infty \right\} .\cr}$$
However $d_\rho\circ\tF \le \tF\circ d_{D_\rho(F)} $, and hence the
above is
bounded by
$$ = \sup \left\{\, {\normo{f^*\circ\tF\circ d_\rho}_{1,X} \over
   \normo{f^*\circ\tF}_{1,X}}
   : 0 < \normo{f}_{F,X} < \infty \right\} ,$$
and this is bounded by $D_{D_\rho(F)} (L_{1,X})$.
 
Hence we have (i). Furthermore, it is now easy to deduce (ii), for
suppose that
$F$\ is $p$-quasi Orlicz, so that there is a $C<\infty$\ such that
$D_\rho(F) <
C \rho^{-\invp}$\ for $0<\rho\le1$. If $p_{L_{F,X}} = 1$, then for
each
$\epsilon>0$\ there is a $C_\epsilon <\infty$\ such that $D_\rho(L_{F,X})
\le
C_\epsilon \rho^{1+\epsilon}$\ for $0<\rho\le1$. Hence
$$ D_\rho(L_{F,X}) \le D_{D_\rho(F)} (L_{1,X})
   \le C_\epsilon (C \rho^{-\invp})^{1+\epsilon} ,$$
and the result follows.
 
The proof of (iii) is entirely similar (note that, by a similar argument
to
that presented in the proof of Proposition~3A:2.7,  $F\circ T^\invq$\
is
equivalent to a concave function if and only if there is a number
$C<\infty$\
such that $D_\rho(F) \le C\rho^{-\invq}$\ for all $1\le\rho<\infty$.)
\endproof
 
\vfill
\eject
 
\beginsection 2) The Boyd Indices of $L_{1,G}$
 
In this section we attempt to find the Boyd indices of $L_{1,G}$\ where
$G$\ is a normal dilatory \af. We do not
solve this problem, but we do indicate
that this problem is difficult. We try to tackle this problem by finding
sufficient conditions on $G$\ to calculate the Boyd indices.
But first we give an example to show that we
cannot rely on $D_\rho(L_{1,G})$\ being proportional to $\rho^{-1}$.
 
\proclaim Proposition 2.1. Suppose that
$0<p,q<\infty$. Let $G$\ be the normal
dilatory \af\ given by
$$ G(t) = \cases{ t^p &if $t\le1$ \cr
                  t^q &if $t\ge1$.\cr}
$$
Then there is a number $C<\infty$,
depending on $p$\ and $q$\ only, such that
$D_\rho(L_{1,G}) \ge \rho^{-1} (\lm\rho^{-1})^{\invp-\invq} $\
for $0<\rho<\infty$.
 
\noindent{\bf Sketch Proof:}
If $0<\rho\le1$, then let $f\in L_0(I_{0,\infty})$\ be defined by
$$ f(t) = \cases{
   \rho^{-1} &if $t\le\rho$\cr
   \invt     &if $\rho<t\le1$\cr
   0         &if $1<t$.\cr}$$
Then
$$ \normo{f}_{1,G} \approx \normo{f}_{1,q}
   \approx \left(\invq \lm \rho^{-1} \right)^\invq ,$$
whereas
$$ \normo{D_\rho(f)}_{1,G}
   \approx \rho^{-1} \left(1\v\left(\invq \lm \rho^{-1} \right)^\invq
   \right) ,$$
and hence $ D_\rho(L_{1,G}) \ge {q^\invq\over p^\invp} \rho^{-1}
(\lm\rho)^{\invp-\invq}$, as desired.
 
The argument for $1\le\rho<\infty$\ is very similar.
\endproof
 
\beginsection 2.1) Equivalent Quantities Describing the Boyd Indices
 
Now we define another quantity that is approximately greater than
$D_\rho(L_{1,G})$.
 
\proclaim Definition 2.2. Let $G$\ be a normal \af, and $0<\rho<\infty$.
Define $E_\rho(G)$\ to be the infimum over all $E$\ such that there is a
function $u\colon I_{0,\infty}\to\R_+$\
with $\int_0^\infty u(t)\,dt\le1$, and
$$ {\invG\left({u(t)\over\tG'(t)}\right) \over
   \invG\left({u(t)\over\rho\tG'(\rho t)}\right)} \le E
   \quad\hbox{for all $0<t<\infty$} .$$
 
\proclaim Theorem 2.3. Let $G$\ be a normal
dilatory \af. Then there is a number
$C<\infty$, depending on $D_\half(G)$\
only, such that for all $0<\rho<\infty$\
we have that $D_\rho(L_{1,G}) \le C \,E_\rho(G)$.
 
\Proof First we note that
$$ \normo{D_\rho f}_{1,G} = \normo{f^*}_{(\Gtr)} ,$$
where $\Gtr(u) = \rho \tG'(\rho t) G(u)
$. If we could find a family of \af s
$(\,H_t:t\in I_{0,\infty})$\ such that
for some $C_1<\infty$\ we had $\invGtr
\labelledapprox {C_1} \invH_t \cdot \invGto$,
then we could say by something like
Theorem~3B:1.3 that there was a number $C_2<\infty$\ such that
$\normo{D_\rho f}_{1,G} \le C_2 \normo 1_{(H_t)} \normo{f}_{1,G} $.
We produce a rigorous version of this argument, and show that
$D_\rho(L_{1,G}) \le 2\bigl(D_\half(G)\bigr)^2E_\rho(G)$, as follows.
 
Define the functions $(\,L_t:t\in I_{0,\infty})$\ by
$$ L_t(u) = {\invGtr(u) \over \invGto(u)}
\quad\hbox{for $u\in[0,\infty]$} .$$
It is easy to see that $ L_t(u) \cdot\invGto(v) \le \invGtr(u+v) $\ for
$u,v\in[0,\infty]$.
Now, by the definition of $E_\rho(G)$, there is a function
$u\colon I_{0,\infty}\to\R_+$\
such that
$ \int_0^\infty u(t) \,dt \le 1$,
and
$$ L_t(u(t)) \ge {1\over 2E_\rho(G)} .$$
Suppose that $\normo f_{1,G} < 1$, so that if
$v(t) = \Gto\bigl(f^*(t)\bigr)$\ then
$\int_0^\infty v(t) \,dt \le 1$. Then
$$ \eqalignno{
   \int_0^\infty
   \Gtr \left({f^*(t)\over
2\bigl(D_\half(G)\bigr)^2\cdot E_\rho(G)}\right) \,dt
   &\le \smallquarter \int_0^\infty
   \Gtr\Bigl(L\bigl(u(t)\bigr)\cdot\invGto\bigl(v(t)\bigr)\Bigr) \,dt \cr
   &\le \smallquarter \int_0^\infty \bigl(u(t) + v(t)\bigr) \,dt \cr
   &\le \smallhalf , \cr}$$
and the result follows.
\endproof
 
Thus Questions~1.1,~1.2 and~1.3 have positive answers if the following do.
 
\proclaim Question 2.4. Let $G$\ be a normal dilatory \af. Is there a
$0<\rho<1$\ such that that $E_\rho(G)$\ is finite?
 
\proclaim Question 2.5. Let $G$\ be a normal
dilatory \af. Is it true that for all
$p<1$\ there is a number $C<\infty$\ such that for all
$0<\rho<1$\ we have $E_\rho(G) \le C \rho^{-\invp}$?
 
\proclaim Question 2.6. Let $G$\ be a normal
dilatory \af. Is it true that for all
$q>1$\ there is a number $C<\infty$\ such that for all
$1<\rho<\infty$\ we have $E_\rho(G) \le C \rho^{-\invq}$?
 
These are somewhat difficult conjectures
to check. However, if $G$\ satisfies
the $\Delta_2$-condition, then we can write these conjectures in terms of
sequences rather than functions. Obviously
Question~1.1 then has a positive
answer, and it is not hard to see that Question~2.4 also has a positive
answer. However we still have the Boyd indices to contend with.
 
The technique is to see that the problem is simplified by
considering only the values that $G$\ takes at $2^n$\ ($n\in\Z$).
 
\proclaim Definition 2.7. Suppose $G$\ is a normal \af. Define the
function $\alpha_G\colon\Z\to\Z$\ to be
such that $2^{\alpha_G(n)} \le G(2^n)
< 2^{\alpha_G(n)+1}$.
 
\proclaim Definition 2.8. If
$\alpha\colon\Z\to\Z$\ is an increasing function,
define $\alpha^{-1}\colon\Z\to\Z$\ to be
$$ \alpha^{-1} (n) = \sup\{\, m : m\le \alpha(n) \} .$$
 
\proclaim Proposition 2.9. Let $G$\ be a
normal dilatory \af\ that satisfies the
$\Delta_2$-condition. Then there is a number $C<\infty$\ such that
$$ \modo{\Id_\Z - \alpha\circ\alpha^{-1}} \hbox{ and }
   \modo{\Id_\Z - \alpha^{-1}\circ\alpha} \le C .$$
 
\Proof As $G$\ is dilatory and satisfies
the $\Delta_2$-condition, there are
numbers $C_1<\infty$\ and $0<p\le
q<\infty$\ such that for all $0<t<\infty$\
and $u\ge 1$\ we have
$$ C_1^{-1} \,u^p\, G(t) \le G(ut) \le C_1\,u^q\,G(t) .$$
Hence there is a number $C_2<\infty$\
such that for all $n\in\Z$\ and $m\in\N$\
we have
$$ -C_2 + \alpha_G(n) + pm \le \alpha_G(n+m)
\le C_2 + \alpha_G(n) + qm .$$
It is now easy to see the result.
\endproof
 
\proclaim Definition 2.10. Let $G$\ be a normal \af, and $r\in\Z$. Define
$F_r(G)$\ to be the infimum over all $F$\ such that there is a function
$\upsilon\colon\Z\to\Z$, with $\sumnii 2^{\upsilon(n)} \le 1$, and
$$ \alpha_G^{-1}\bigl(\upsilon(n) + \alpha_G(-n)\bigr)
   - \alpha_G^{-1}\bigl(\upsilon(n) + \alpha_G(-n-r)\bigr)
   \le F
   \quad\hbox{for all $n\in\Z$} .$$
 
\proclaim Theorem 2.11. Let $G$\ be a
normal dilatory \af that satisfies the
$\Delta_2$-condition. Then there is a number $C<\infty$, depending on $G$\
only, such that for all $r\in\Z$\ we have
$$ E_{2^r}(G) \le C\, 2^{F_r(G)} .$$
 
\Proof Choose $\upsilon\colon\Z\to\Z$\
with $\sumnii 2^{\upsilon(n)} \le 1$,
and
$$ \alpha_G^{-1}\bigl(\upsilon(n) + \alpha_G(-n)\bigr)
   - \alpha_G^{-1}\bigl(\upsilon(n) + \alpha_G(-n-r)\bigr)
   \le 1+F_r(G) .$$
Let $u\colon I_{0,\infty}\to\R_+$\ be defined to be
$$ u\big|_{[2^n,2^{n+1})} = 2^{\upsilon(n)-n} ,$$
so that $\int_0^\infty u(t)\,dt = \sumnii 2^{\upsilon(n)} \le 1$. By
Lemma~ 3B:2.3, there is a number $C_1<\infty$\ such that
$$ { \invG \left( { u(t) \over \tG'(t) } \right) \over
     \invG \left( { u(t) \over \tG'(2^r t) } \right) }
   \le
   { \invG \left( C_1 { t u(t) \over \tG(t) } \right) \over
     \invG \left( C_1^{-1} { t u(t) \over \tG(C_1 2^r t) } \right) } ,$$
and as $G$\ satisfies the $\Delta_2$-condition, we have for some
$C_2<\infty$\ that this is
$$ \le
   { \invG \left( C_1 { t u(t) \over \tG(t) } \right) \over
     \invG \left( C_2^{-1} { t u(t) \over \tG(2^r t) } \right) } .$$
Now, if $t\in[2^n,2^{n+1})$, then $u(t) = 2^{\upsilon(n)-n}$, and $\tG(t)
\labelledapprox 2 2^{-\alpha_G(-n)}$. Hence the above is
$$ \le
   { \invG \left( 2 C_1 \,2^{1+\upsilon(n)-\alpha_G(-n)} \right) \over
     \invG \left( \half C_2^{-1}
\,2^{\upsilon(n)-\alpha_G(-n-r)} \right) } .$$
As $G$\ is dilatory and satisfies the
$\Delta_2$-condition, we have for some
$C_3<\infty$\ that the above is
$$ \le C_3
   { \invG \left( 2^{\upsilon(n)-\alpha_G(-n)} \right) \over
     \invG \left( 2^{\upsilon(n)-\alpha_G(-n-r)} \right) } .$$
Now, by Proposition~2.9, we have for some $C_4<\infty$\ that $\invG(2^n)
\labelledapprox{C_4} 2^{\alpha_G^{-1}(n)}$, and hence the above is
$$ \eqalignno{
   &\le C_3 \, C_4^2 \,
   2^{\bigl(\alpha_G^{-1}\bigl(\upsilon(n)-\alpha_G(-n)\bigr)
            \alpha_G^{-1}\bigl(\upsilon(n)-\alpha_G(-n-r)\bigr)\bigr)} \cr
   &\le C_3 \, C_4^2 \, 2^{1+F_r(G)} ,\cr}$$
as desired.
\endproof
 
Thus Questions~2.5 and~2.6 become the following.
 
\proclaim Question~2.12. Let $G$\ be a
normal dilatory function satisfying the
$\Delta_2$-con\-di\-tion. Is it true that for all $p<1$\ there is a number
$C<\infty$\ such that for all $r\in\Z$\
with $r<0$, we have $F_r(G) \le C -
\invp r$.
 
\proclaim Question~2.13. Let $G$\ be a
normal dilatory function satisfying the
$\Delta_2$-con\-di\-tion. Is it true that for all $q>1$\ there is a number
$C<\infty$\ such that for all $r\in\Z$\
with $r>0$, we have $F_r(G) \le C -
\invq r$.
 
I have not made much headway in answering these questions. Part of the
difficulty lies in that, as a consequence
of the work of Section~3B:2, simpler
normal dilatory \af s, $G$, that one might
consider, satisfy $L_{1,G} = L_{1,p}$\
for some $0<p\le \infty$.
 
\bigskip
To recap, we are interested in characterizing the Boyd indices of the
$L_{F,G}$\ spaces purely in terms of $F$,
where $F$\ and $G$\ are normal dilatory
\af s. We reduce this to showing that
the Boyd indices of $L_{1,G}$\ are $1$,
and
this is tackled by considering new quantities that depend on $G$, which we
call $E_\rho(G)$\ and $F_r(G)$\ ($0<\rho<\infty$, $r\in\Z$).
 
\vfill
\eject
 
\frenchspacing
 
\beginsection References
 
\halign{\rm#\hfil & \quad\vtop{\hsize=5.7 true in\parindent=0pt\hangindent=0em
\strut\rm#\strut\smallskip}\cr
B--R & C.~Bennett and K.~Rudnick,\rm\ On Lorentz--Zygmund spaces,\sl\
Dissert.\
Math.\ {\bf 175} (1980), 1--72\cr
B--S & C.~Bennett and R.~Sharpley,\sl\ Interpolation of Operators,\rm\
Academic
Press.\cr
B--L & J.~Bergh and J. L\"ofstr\"om,\sl\ Interpolation Spaces,\rm\
Springer-Verlag.\cr
Bo & C.~Borel,\rm\ The Brunn--Minkowski inequality in Gauss Space,\sl\
Invent.\
Math.\ {\bf 30} (1975) 207--216.\cr
Ch & K.L.~Chung,\sl\ A Course in Probability Theory (2nd.~Ed.),\rm\
Academic
Press.\cr
Cr & J.~Creekmore,\rm\ Type and cotype in Lorentz $L_{p,q}$\ spaces,\sl\
Indag.\ Math.\ {\bf 43} (1981), 145--152.\cr
F & X.M.~Fernique, J.P.~Conze and J.~Gani,\sl\ Ecole d'Et\'e de Probabilit\'es
de Saint-Flour IV--1974,\rm\ Lecture Notes in Maths.\ 480.\cr
H & R.A.~Hunt,\rm\ On $L(p,q)$\ spaces,\sl\ L'Enseignement Math.\
(2) {\bf 12}
(1966), 249--275.\cr
J1 & G.J.O.~Jameson,\rm\ Relations between summing norms of mappings
on
$l_\infty^n$,\sl\ Math.\ Z.\ {\bf 194} (1987), 89--94.\cr
J2 & G.J.O.~Jameson,\sl\ Summing and Nuclear Norms in Banach Space
Theory,\rm\
London Math.\ Soc., Student Texts 8.\cr
Ka & J-P.~Kahane,\sl\ Some Random Series of Functions,\rm\ Cambridge
studies
in advanced mathematics 5.\cr
K--P--R & N.J.~Kalton, N.T.~Peck and J.W.~Roberts,\sl\ An $F$-space
Sampler,\rm\
Cambridge University Press.\cr
K--R & M.A.~Krasnosel'ski\u\i\ and Ya.B.~Ruticki\u\i\ (Trans.\ L.F.~Boron),\sl\
Convex Functions and
Orlicz Spaces,\rm\ P.~Noodhoff Ltd.\cr
L--T1 & J.~Lindenstrauss and L.~Tzafriri,\sl\ Classical Banach Spaces
I---Se\-qu\-ence
Spa\-ces,\rm\ Springer-Verlag.\cr
L--T2 & J.~Lindenstrauss and L. Tzafriri,\sl\ Classical Banach Spaces
II---Fu\-nc\-t\-ion
Spa\-ces,\rm\ Springer-Verlag.\cr
Lo & G.G.~Lorentz,\rm\ Some new function spaces,\sl\ Ann.\ of Math.\
{\bf 51}
(1950), 37--55.\cr
Ma1 & B.~Maurey,\rm\ Une nouvelle caract\'erisation des applications
$(p,q)$-sommantes,\sl\ Seminaire Maurey-Schwartz 1973--74, Expos\'e~12.\cr
Ma2 & B.~Maurey,\rm\ Type et cotype dans les espaces munis de structures
locales
inconditionelles,\sl\ Seminaire Maurey-Schwartz 1973--74, Expos\'es~24--25.\cr
Ma--P & B.~Maurey and G.~Pisier,\rm\ S\'eries de variables al\'eatoires
vectorielles
ind\-\'ep\-end\-antes et propri\'et\'es g\'eom\'etriques des espaces
de
Banach,\sl\ Studia Math.\ {\bf 58} (1976), 45--90.\cr
Me & P-A.~Meyer,\sl\ Martingales and Stochastic Integrals I,\rm\
Springer-Verlag 284.\cr
Mi--Sr & V.D.~Milman and M.~Sharir,\rm\ A new proof of the Maurey--Pisier
theorem,\sl\ Israel J.\ Math.\ {\bf 33} (1979), 73--87.\cr
Mi--Sn & V.D.~Milman and G.~Schechtman,\sl\ Asymptotic Theory of
Finite Dimensional
Normed Spaces,\rm\ Lecture Notes in Maths.\ 1200.\cr
Mo1 & S.J.~Montgomery-Smith,\rm\ On the cotype of operators
from $l_\infty^n$,\sl\ submitted.\cr
Mo2 & S.J.~Montgomery-Smith,\rm\ An inequality involving random walks
in
$l_\infty$,\sl\ un\-publ\-ished.\cr
Mu & J.~Musielak,\sl\ Orlicz Spaces and Modular Spaces,\rm\ Springer-Verlag
1034.\cr
Pt & A.~Pietsch,\sl\ Operator Ideals,\rm\ North-Holland.\cr
P1 & G.~Pisier,\sl\ Factorization of Linear Operators and Geometry
of Banach
Spaces,\rm\ Amer.\ Math.\ Soc.\cr
P2 & G.~Pisier,\sl\ Probabilistic Methods in the Geometry of Banach
Spaces,\rm\
un\-publ\-ished.\cr
P3 & G.~Pisier,\rm\ Factorisation des op\'erateurs $(q,p)$-sommantes
sur les
$C^*$-algebres,\sl\ C.R.\ Acad.\ Sci.\ Paris A {\bf 301} (1985),
403--405.\cr
P4 & G.~Pisier,\rm\ Factorization of operators through $L_{p\infty}$\
or $L_{p1}$\ and non-com\-mut\-at\-ive generalizations,\sl\ Math.\
Ann.\
{\bf 276} (1986), 105--136.\cr
Ru & W.~Rudin,\sl\ Functional Analysis,\rm\ McGraw--Hill.\cr
Sh & T.~Shimogaki,\rm\ A note on norms of compression operators on
function
spaces,\sl\ Proc.\ Japan Acad.\ {\bf 46} (1970), 239--242.\cr
T & M.~Talagrand,\rm\ Regularity of Gaussian processes,\sl\ Acta
Math. {\bf
159} (1987), 99--149.\cr
}
 
\bye
